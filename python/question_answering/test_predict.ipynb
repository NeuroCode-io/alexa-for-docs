{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime import InferenceSession\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict.squad_utils import predict_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./model/\"\n",
    "fast_tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "session1 = InferenceSession( \"./onnx/onnx-optimized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Versioning Process Managers 119 state things that will be needed by the new version of the process. In the previous case there was an identifier on a message that the old version did not care about but the new one does. When the new version gets replayed, it will see that message and be able to take whatever it wants out of it to apply to its own state. Unfortunately everything is not puppies and rainbows. There is inherent complexity in bringing a new version of a Process Manager to continue from an old version of the Process Manager. The new version must be able to understand all the possible event streams that result from the previous version, or at least what it cares about. Often times this is not a huge problem but it depends how different the processes are between the two versions. This can result in a large amount of conditional logic for how to handle continuing on the new process where the old process had left off. This versioning of Event Sourced Process Managers is often used in conjunction with the Takeover pattern. The old version is signaled that it is to terminate. It can still do anything that it wants as part of its termination and it then raises the 'TakeoverRequested' message that will start the new version. The main difference with Event Sourced Process Managers and the pattern is that they do not send state when they ask the new version to Takeover. Warning When versioning Process Managers there are many options. The majority of this chapter however is focused on difficult edge con- ditions. Situations where a running process is changed while it is running should be avoided. All of the cases where a running process is changed while running are niche scenarios, they are included as the topic of the book is versioning. In most circumstances if you are trying to version running Process Managers, you are doing it wrong . Stop and think why it is needed, likely you have a modelling issue. Why does the business want to upgrade the processes in place? Whoops, I Did It Again 58 Depending on how you handle subscriptions, you can either send over a Cancelled event with a link back to the original event or you can include the body of the original event in the Cancelled event. These are just semantic differences, as the consumer can get the event data for 54@mystream if it wants to anyway. Both are valid implementations. This is advertising to the consumers that any event can possibly be cancelled and if they really care about the cancellation of a previous event beyond notifying someone, they really should handle the Cancelled event. How Do I Find What Needs Fixing? This is one of the biggest struggles for people in Event Sourced systems, especially those who may be new to Event Sourcing. We can send a compensating action, but how do we figure out which streams need it sent? A commonly heard approach is to bring up a one-off instance of the domain model that will iterate through all of the possibly affected aggregates one by one, emitting the compensation as it finds domain objects that may be affected. This strategy is not a terrible one, but it can run into a few issues. How, for one, does your code know what the IDs of all of the streams of that type are? Assuming that you found a problem in accounts, how do you know all the streams that are accounts? There are ways of working around this, such as using an Announcement Stream that tracks all of the account streams, but this must be in place already. If not, it can be a hurdle. Does your domain object have enough data in it at the moment to actually identify if it is currently having a problem? It is common in Event Sourced systems to have the domain state/aggregate contain only the things requires to maintain the invariants it protects.\"\n",
    "\n",
    "question = \"How do you version events?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_dict = {\"context\": context, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'score': 0.007,\n",
       "  'answer': 'include the body of the original event in the Cancelled event'},\n",
       " {'score': 0.0078,\n",
       "  'answer': 'send over a Cancelled event with a link back to the original event'}]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "result1 = predict_qa(session1, fast_tokenizer, examples_dict)\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "session2 = InferenceSession(\"./onnx/onnx-optimized-quantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'score': 0.0128,\n",
       "  'answer': 'send over a Cancelled event with a link back to the original event or you can include the body of the original event in the Cancelled event'},\n",
       " {'score': 0.0128,\n",
       "  'answer': 'send over a Cancelled event with a link back to the original event or you can include the body of the original event in the Cancelled event'}]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "result2 = predict_qa(session2, fast_tokenizer, examples_dict)\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'score': 0.007,\n",
       "  'answer': 'include the body of the original event in the Cancelled event'},\n",
       " {'score': 0.0078,\n",
       "  'answer': 'send over a Cancelled event with a link back to the original event'}]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "session3 = InferenceSession(\"./onnx/onnx\")\n",
    "result3 = predict_qa(session3, fast_tokenizer, examples_dict)\n",
    "result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}