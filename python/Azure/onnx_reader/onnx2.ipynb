{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit ('.venv')",
   "metadata": {
    "interpreter": {
     "hash": "4037c546effa33586e051666d7d74862170a63a04006db20983879415d1a70a6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime import InferenceSession\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from pathlib import Path\n",
    "from transformers.convert_graph_to_onnx import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_name=\"./onnx_model/roberta-base-squad2.onnx\"\n",
    "model_name=\"deepset/roberta-base-squad2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_for_onnx(model_path, onnx_model_name, tokenizer):\n",
    "    if Path(onnx_model_name).exists():\n",
    "        print(\"ONNX input exists\")\n",
    "        return\n",
    "    convert(\n",
    "        framework=\"pt\",\n",
    "        model=model_path,\n",
    "        tokenizer=tokenizer,\n",
    "        output=Path(onnx_model_name),\n",
    "        pipeline_name=\"question-answering\",\n",
    "        opset=12\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ONNX input exists\n"
     ]
    }
   ],
   "source": [
    "convert_for_onnx(model_path=model, onnx_model_name=onnx_model_name, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need example.context_text and example.question_text\n",
    "example_dict={\"context\": \"In its early years, the new convention center failed to meet attendance and revenue expectations.[12] By 2002, many Silicon Valley businesses were choosing the much larger Moscone Center in San Francisco over the San Jose Convention Center due to the latter's limited space. A ballot measure to finance an expansion via a hotel tax failed to reach the required two-thirds majority to pass. In June 2005, Team San Jose built the South Hall, a $6.77 million, blue and white tent, adding 80,000 square feet (7,400 m2) of exhibit space\", \"question\": \"where is the businesses choosing to go?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding=\"longest\"\n",
    "max_seq_len=384\n",
    "doc_stride=128\n",
    "max_question_len=64\n",
    "max_answer_len=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.data.processors import squad_convert_examples_to_features\n",
    "from transformers.pipelines import QuestionAnsweringArgumentHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_arg_parser=QuestionAnsweringArgumentHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples= _arg_parser(example_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.data.processors import SquadFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "device=torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = []\n",
    "for example in examples:\n",
    "    # Define the side we want to truncate / pad and the text/pair sorting\n",
    "    question_first = bool(tokenizer.padding_side == \"right\")\n",
    "    encoded_inputs = tokenizer(\n",
    "        text=example.question_text if question_first else example.context_text,\n",
    "        text_pair=example.context_text if question_first else example.question_text,\n",
    "        padding=padding,\n",
    "        truncation=\"only_second\" if question_first else \"only_first\",\n",
    "        max_length=max_seq_len,\n",
    "        stride=doc_stride,\n",
    "        return_tensors=\"np\",\n",
    "        return_token_type_ids=True,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        return_special_tokens_mask=True,\n",
    "    )\n",
    "    \n",
    "    num_spans = len(encoded_inputs[\"input_ids\"])\n",
    "    p_mask = np.asarray(\n",
    "        [\n",
    "            [tok != 1 if question_first else 0 for tok in encoded_inputs.sequence_ids(span_id)]\n",
    "            for span_id in range(num_spans)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # keep the cls_token unmasked (some models use it to indicate unanswerable questions)\n",
    "    if tokenizer.cls_token_id:\n",
    "        cls_index = np.nonzero(encoded_inputs[\"input_ids\"] == tokenizer.cls_token_id)\n",
    "        p_mask[cls_index] = 0\n",
    "\n",
    "    features = []\n",
    "    for span_idx in range(num_spans):\n",
    "        features.append(\n",
    "            SquadFeatures(\n",
    "                input_ids=encoded_inputs[\"input_ids\"][span_idx],\n",
    "                attention_mask=encoded_inputs[\"attention_mask\"][span_idx],\n",
    "                token_type_ids=encoded_inputs[\"token_type_ids\"][span_idx],\n",
    "                p_mask=p_mask[span_idx].tolist(),\n",
    "                encoding=encoded_inputs[span_idx],\n",
    "                # We don't use the rest of the values - and actually\n",
    "                # for Fast tokenizer we could totally avoid using SquadFeatures and SquadExample\n",
    "                cls_index=None,\n",
    "                token_to_orig_map={},\n",
    "                example_index=0,\n",
    "                unique_id=0,\n",
    "                paragraph_len=0,\n",
    "                token_is_max_context=0,\n",
    "                tokens=[],\n",
    "                start_position=0,\n",
    "                end_position=0,\n",
    "                is_impossible=False,\n",
    "                qas_id=None,\n",
    "                )\n",
    "            )\n",
    "        features_list.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, example in zip(features_list, examples):\n",
    "    model_input_names = tokenizer.model_input_names + [\"input_ids\"]\n",
    "    fw_args = {k: [feature.__dict__[k] for feature in features] for k in model_input_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'attention_mask': [array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])],\n",
       " 'input_ids': [array([    0,  8569,    16,     5,  1252,  8348,     7,   213,   116,\n",
       "             2,     2,  1121,    63,   419,   107,     6,     5,    92,\n",
       "          8825,  1312,  1447,     7,   972,  6856,     8,   903,  2113,\n",
       "         31274,  1092,   742,   870,  5241,     6,   171, 10087,  1739,\n",
       "          1252,    58,  8348,     5,   203,  2514,  8033, 33666,   824,\n",
       "            11,   764,  2659,    81,     5,   764,  3071,  9127,   824,\n",
       "           528,     7,     5,  5442,    18,  1804,   980,     4,    83,\n",
       "          5250,  2450,     7,  2879,    41,  2919,  1241,    10,  2303,\n",
       "           629,  1447,     7,  1338,     5,  1552,    80,    12, 10224,\n",
       "          1647,     7,  1323,     4,    96,   502,  4013,     6,  2711,\n",
       "           764,  3071,  1490,     5,   391,  1631,     6,    10,    68,\n",
       "           401,     4,  4718,   153,     6,  2440,     8,  1104, 10178,\n",
       "             6,  1271,  1812,     6,   151,  3925,  1730,    36,   406,\n",
       "             6,  4017,   475,   176,    43,     9,  8483,   980,     2])]}"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "fw_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = InferenceSession(onnx_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NodeArg(name='input_ids', type='tensor(int64)', shape=['batch', 'sequence'])\nNodeArg(name='attention_mask', type='tensor(int64)', shape=['batch', 'sequence'])\n"
     ]
    }
   ],
   "source": [
    "for inp in session.get_inputs():\n",
    "    print(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(start: np.ndarray, end: np.ndarray, topk: int, max_answer_len: int) -> Tuple:\n",
    "    \"\"\"\n",
    "    Take the output of any :obj:`ModelForQuestionAnswering` and will generate probabilities for each span to be the\n",
    "    actual answer.\n",
    "    In addition, it filters out some unwanted/impossible cases like answer len being greater than max_answer_len or\n",
    "    answer end position being before the starting position. The method supports output the k-best answer through\n",
    "    the topk argument.\n",
    "    Args:\n",
    "        start (:obj:`np.ndarray`): Individual start probabilities for each token.\n",
    "        end (:obj:`np.ndarray`): Individual end probabilities for each token.\n",
    "        topk (:obj:`int`): Indicates how many possible answer span(s) to extract from the model output.\n",
    "        max_answer_len (:obj:`int`): Maximum size of the answer to extract from the model's output.\n",
    "    \"\"\"\n",
    "    # Ensure we have batch axis\n",
    "    if start.ndim == 1:\n",
    "        start = start[None]\n",
    "\n",
    "    if end.ndim == 1:\n",
    "        end = end[None]\n",
    "\n",
    "    # Compute the score of each tuple(start, end) to be the real answer\n",
    "    outer = np.matmul(np.expand_dims(start, -1), np.expand_dims(end, 1))\n",
    "\n",
    "    # Remove candidate with end < start and end - start > max_answer_len\n",
    "    candidates = np.tril(np.triu(outer), max_answer_len - 1)\n",
    "\n",
    "    #  Inspired by Chen & al. (https://github.com/facebookresearch/DrQA)\n",
    "    scores_flat = candidates.flatten()\n",
    "    if topk == 1:\n",
    "        idx_sort = [np.argmax(scores_flat)]\n",
    "    elif len(scores_flat) < topk:\n",
    "        idx_sort = np.argsort(-scores_flat)\n",
    "    else:\n",
    "        idx = np.argpartition(-scores_flat, topk)[0:topk]\n",
    "        idx_sort = idx[np.argsort(-scores_flat[idx])]\n",
    "\n",
    "    start, end = np.unravel_index(idx_sort, candidates.shape)[1:]\n",
    "    return start, end, candidates[0, start, end]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_qa(model_type, features_list, examples):\n",
    "    all_answers = []\n",
    "    for features, example in zip(features_list, examples):\n",
    "        model_input_names = tokenizer.model_input_names + [\"input_ids\"]\n",
    "        fw_args = {k: [feature.__dict__[k] for feature in features] for k in model_input_names}\n",
    "        if model_type==\"onnx\":\n",
    "            session = InferenceSession(onnx_model_name)\n",
    "            output = session.run(None, fw_args)\n",
    "            start=output[0]\n",
    "            end=output[1]\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                fw_args = {k: torch.tensor(v, device=device) for (k, v) in fw_args.items()}\n",
    "                # On Windows, the default int type in numpy is np.int32 so we get some non-long tensors.\n",
    "                fw_args = {k: v.long() if v.dtype == torch.int32 else v for (k, v) in fw_args.items()}\n",
    "                start, end = model_type(**fw_args)[:2]\n",
    "                start, end = start.cpu().numpy(), end.cpu().numpy()\n",
    "\n",
    "\n",
    "        min_null_score = 1000000  # large and positive\n",
    "        answers = []\n",
    "        for (feature, start_, end_) in zip(features, start, end):\n",
    "            # Ensure padded tokens & question tokens cannot belong to the set of candidate answers.\n",
    "            undesired_tokens = np.abs(np.array(feature.p_mask) - 1) & feature.attention_mask\n",
    "    \n",
    "            # Generate mask\n",
    "            undesired_tokens_mask = undesired_tokens == 0.0\n",
    "\n",
    "            # Make sure non-context indexes in the tensor cannot contribute to the softmax\n",
    "            start_ = np.where(undesired_tokens_mask, -10000.0, start_)\n",
    "            end_ = np.where(undesired_tokens_mask, -10000.0, end_)\n",
    "\n",
    "            # Normalize logits and spans to retrieve the answer\n",
    "            start_ = np.exp(start_ - np.log(np.sum(np.exp(start_), axis=-1, keepdims=True)))\n",
    "            end_ = np.exp(end_ - np.log(np.sum(np.exp(end_), axis=-1, keepdims=True)))\n",
    "\n",
    "            # Mask CLS\n",
    "            start_[0] = end_[0] = 0.0\n",
    "            starts, ends, scores = decode(start=start, end=end,topk=1, max_answer_len=max_answer_len)\n",
    "            if not tokenizer.is_fast:\n",
    "                char_to_word = np.array(example.char_to_word_offset)\n",
    "                answers += [\n",
    "                    {\n",
    "                        \"score\": score.item(),\n",
    "                        \"start\": np.where(char_to_word == feature.token_to_orig_map[s])[0][0].item(),\n",
    "                        \"end\": np.where(char_to_word == feature.token_to_orig_map[e])[0][-1].item(),\n",
    "                        \"answer\": \" \".join(\n",
    "                            example.doc_tokens[feature.token_to_orig_map[s] : feature.token_to_orig_map[e] + 1]\n",
    "                            ),\n",
    "                    }\n",
    "                    for s, e, score in zip(starts, ends, scores)\n",
    "                ]\n",
    "            else:\n",
    "                question_first = bool(tokenizer.padding_side == \"right\")\n",
    "                enc = feature.encoding\n",
    "                # Sometimes the max probability token is in the middle of a word so:\n",
    "                # - we start by finding the right word containing the token with `token_to_word`\n",
    "                # - then we convert this word in a character span with `word_to_chars`\n",
    "                answers += [\n",
    "                    {\n",
    "                        \"score\": score.item(),\n",
    "                        \"start\": enc.word_to_chars(\n",
    "                        enc.token_to_word(s), sequence_index=1 if question_first else 0 )[0],\n",
    "                        \"end\": enc.word_to_chars(enc.token_to_word(e), sequence_index=1 if question_first else 0)[1],\n",
    "                        \"answer\": example.context_text[\n",
    "                            enc.word_to_chars(enc.token_to_word(s), sequence_index=1 if question_first else 0)[0] : enc.word_to_chars(enc.token_to_word(e), sequence_index=1 if question_first else 0)[1]],\n",
    "                    }\n",
    "                    for s, e, score in zip(starts, ends, scores)\n",
    "                ]\n",
    "            answers = sorted(answers, key=lambda x: x[\"score\"], reverse=True)[: 1]\n",
    "            all_answers += answers\n",
    "        if len(all_answers) == 1:\n",
    "            return all_answers[0]\n",
    "        return all_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_onnx=predict_qa(model_type=\"onnx\", features_list=features_list, examples=examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model=predict_qa(model_type=model, features_list=features_list, examples=examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'score': 96.2432861328125, 'start': 438, 'end': 443, 'answer': ', a $'}"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "pred_onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'score': 96.2432861328125, 'start': 438, 'end': 443, 'answer': ', a $'}"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "pred_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, example in zip(features_list, examples):\n",
    "    model_input_names = tokenizer.model_input_names + [\"input_ids\"]\n",
    "    fw_args = {k: [feature.__dict__[k] for feature in features] for k in model_input_names}\n",
    "    with torch.no_grad():\n",
    "        fw_args = {k: torch.tensor(v, device=device) for (k, v) in fw_args.items()}\n",
    "        # On Windows, the default int type in numpy is np.int32 so we get some non-long tensors.\n",
    "        fw_args = {k: v.long() if v.dtype == torch.int32 else v for (k, v) in fw_args.items()}\n",
    "        start, end = model(**fw_args)[:2]\n",
    "        start, end = start.cpu().numpy(), end.cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, example in zip(features_list, examples):\n",
    "    model_input_names = tokenizer.model_input_names + [\"input_ids\"]\n",
    "    fw_args = {k: [feature.__dict__[k] for feature in features] for k in model_input_names}\n",
    "    session = InferenceSession(onnx_model_name)\n",
    "    output = session.run(None, fw_args)\n",
    "    start_onnx=output[0]\n",
    "    end_onnx=output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[ 2.5174756 , -9.336974  , -9.503601  , -9.283567  , -9.2332    ,\n",
       "         -9.0281725 , -9.042689  , -8.827452  , -9.803331  , -9.7623415 ,\n",
       "         -9.869641  , -7.7731953 , -8.48362   , -8.002133  , -9.462732  ,\n",
       "         -9.973475  , -7.5483236 , -6.3274603 , -4.1583757 , -7.7243757 ,\n",
       "         -8.653463  , -9.206422  , -9.023609  , -8.492439  , -9.467815  ,\n",
       "         -8.710339  , -9.111895  , -8.046997  , -6.6119637 , -6.567126  ,\n",
       "         -1.41188   , -4.6289377 , -7.875642  ,  0.84093297,  2.0125396 ,\n",
       "         -4.012975  , -2.4589577 , -4.748082  , -0.12348899,  3.4789903 ,\n",
       "          1.2759614 , -0.641837  ,  5.559165  , -2.6643484 , -2.3954556 ,\n",
       "         -1.4975166 ,  3.0133183 , -1.9406399 , -3.4758637 ,  0.09910806,\n",
       "          1.7524412 , -3.6651056 , -3.6433187 , -5.0818367 , -6.8084307 ,\n",
       "         -8.037044  , -4.3071117 , -6.0028043 , -8.769691  , -4.5208206 ,\n",
       "         -5.7817235 , -6.567108  , -7.3898325 , -7.8200207 , -9.358879  ,\n",
       "         -9.039545  , -8.446899  , -8.516021  , -7.73948   , -9.078333  ,\n",
       "         -8.125771  , -4.2110476 , -8.829175  , -8.516272  , -9.129426  ,\n",
       "         -8.821354  , -8.72036   , -8.557966  , -7.5532303 , -8.9368515 ,\n",
       "         -8.840754  , -8.893118  , -9.133942  , -8.861573  , -6.567112  ,\n",
       "         -8.45829   , -7.938081  , -8.596102  , -9.636076  , -4.6033783 ,\n",
       "         -3.3609974 , -6.817756  , -8.804229  , -6.1083922 , -3.2125845 ,\n",
       "         -7.5067654 , -9.879027  , -8.594452  , -7.412553  , -8.120377  ,\n",
       "         -8.768551  , -8.927557  , -9.583794  , -9.734432  , -8.622596  ,\n",
       "         -9.418198  , -9.272104  , -8.973139  , -9.8824    , -9.090474  ,\n",
       "         -7.641445  , -9.076637  , -9.154347  , -8.882855  , -9.768173  ,\n",
       "         -9.353025  , -8.509659  , -9.071119  , -9.264717  , -9.197414  ,\n",
       "         -9.71453   , -9.848179  , -9.353427  , -8.232941  , -9.57499   ,\n",
       "         -9.825842  ]], dtype=float32),\n",
       " array([[ 2.5174766 , -9.336975  , -9.503601  , -9.28357   , -9.233203  ,\n",
       "         -9.028175  , -9.042686  , -8.827454  , -9.803336  , -9.762342  ,\n",
       "         -9.869639  , -7.773194  , -8.4836235 , -8.002134  , -9.46273   ,\n",
       "         -9.973476  , -7.5483284 , -6.327465  , -4.1583743 , -7.7243795 ,\n",
       "         -8.653461  , -9.206419  , -9.023605  , -8.492443  , -9.467815  ,\n",
       "         -8.710339  , -9.111895  , -8.047     , -6.6119604 , -6.5671234 ,\n",
       "         -1.4118862 , -4.6289515 , -7.8756447 ,  0.84093106,  2.0125406 ,\n",
       "         -4.012974  , -2.4589589 , -4.7480907 , -0.12349087,  3.4789922 ,\n",
       "          1.2759652 , -0.641834  ,  5.5591707 , -2.6643503 , -2.3954527 ,\n",
       "         -1.4975181 ,  3.0133193 , -1.9406375 , -3.4758646 ,  0.0991131 ,\n",
       "          1.7524452 , -3.6651032 , -3.6433127 , -5.0818334 , -6.8084345 ,\n",
       "         -8.037051  , -4.3071094 , -6.002809  , -8.769695  , -4.5208273 ,\n",
       "         -5.7817297 , -6.567108  , -7.3898396 , -7.8200226 , -9.358882  ,\n",
       "         -9.039547  , -8.4468975 , -8.516016  , -7.739476  , -9.078334  ,\n",
       "         -8.125769  , -4.211049  , -8.829178  , -8.51628   , -9.129431  ,\n",
       "         -8.821358  , -8.720365  , -8.557971  , -7.5532293 , -8.936848  ,\n",
       "         -8.840754  , -8.893123  , -9.133943  , -8.861576  , -6.567111  ,\n",
       "         -8.458286  , -7.9380817 , -8.596102  , -9.636078  , -4.6033764 ,\n",
       "         -3.360996  , -6.8177595 , -8.804231  , -6.1083846 , -3.2125823 ,\n",
       "         -7.5067663 , -9.879028  , -8.59445   , -7.4125547 , -8.120378  ,\n",
       "         -8.768551  , -8.927558  , -9.583793  , -9.73443   , -8.622599  ,\n",
       "         -9.4182    , -9.272104  , -8.973139  , -9.882404  , -9.090472  ,\n",
       "         -7.641442  , -9.076635  , -9.154342  , -8.8828535 , -9.768169  ,\n",
       "         -9.353024  , -8.509654  , -9.071123  , -9.264717  , -9.197414  ,\n",
       "         -9.714533  , -9.848185  , -9.35343   , -8.232945  , -9.574991  ,\n",
       "         -9.825838  ]], dtype=float32))"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "start, start_onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[ 2.8266854 , -8.526317  , -8.608975  , -8.922647  , -8.779562  ,\n",
       "         -8.767787  , -8.910081  , -8.093397  , -8.119008  , -8.366886  ,\n",
       "         -8.068167  , -9.368933  , -9.19462   , -9.218822  , -7.867637  ,\n",
       "         -7.989144  , -9.538399  , -9.151335  , -7.176478  , -3.3620288 ,\n",
       "         -9.053052  , -8.856573  , -8.985335  , -8.094151  , -8.784493  ,\n",
       "         -8.71572   , -7.2514143 , -5.2117157 , -5.2346363 , -0.91592056,\n",
       "         -7.121268  , -3.8923995 , -3.0051386 , -5.377213  , -4.2859216 ,\n",
       "          1.814283  , -1.9127815 , -6.796349  , -3.922427  , -3.5612164 ,\n",
       "         -5.677236  , -1.9109424 , -2.496266  , -0.76523185,  5.523105  ,\n",
       "         -2.8118653 , -2.6718936 ,  5.498702  , -1.9994283 , -5.6354527 ,\n",
       "         -5.228826  , -0.06761378, -3.9976761 ,  3.1309412 , -3.9512823 ,\n",
       "         -6.956884  , -7.705128  , -5.520048  , -7.4978147 , -7.50962   ,\n",
       "         -2.060118  , -0.91590536, -9.25655   , -8.93781   , -7.879832  ,\n",
       "         -9.095184  , -9.046648  , -9.228343  , -7.1305027 , -8.816588  ,\n",
       "         -9.4512    , -5.307779  , -6.990697  , -8.735123  , -8.706623  ,\n",
       "         -8.794823  , -9.046509  , -8.727938  , -9.15955   , -8.906582  ,\n",
       "         -7.685301  , -7.5620947 , -8.795603  , -6.679308  , -0.915909  ,\n",
       "         -9.430837  , -9.536483  , -7.4434376 , -8.445795  , -9.250657  ,\n",
       "         -7.1366057 , -0.9161452 , -8.580761  , -9.086011  , -6.319841  ,\n",
       "         -2.5211995 , -7.5302796 , -9.318058  , -9.742183  , -9.322398  ,\n",
       "         -9.221669  , -8.647196  , -7.5349317 , -8.26656   , -9.195983  ,\n",
       "         -8.948723  , -8.754266  , -7.225926  , -8.310894  , -9.067228  ,\n",
       "         -9.471379  , -9.146086  , -8.886301  , -8.951288  , -7.3062744 ,\n",
       "         -8.898514  , -9.4080715 , -9.131721  , -8.559364  , -8.835064  ,\n",
       "         -8.0405    , -8.083435  , -8.954958  , -9.078505  , -7.6248446 ,\n",
       "         -8.330037  ]], dtype=float32),\n",
       " array([[ 2.8266861 , -8.526315  , -8.608976  , -8.922648  , -8.779564  ,\n",
       "         -8.767786  , -8.910082  , -8.093401  , -8.119011  , -8.366884  ,\n",
       "         -8.068161  , -9.368931  , -9.19462   , -9.218823  , -7.867637  ,\n",
       "         -7.9891467 , -9.538402  , -9.151337  , -7.176474  , -3.3620293 ,\n",
       "         -9.053053  , -8.85657   , -8.985334  , -8.094152  , -8.784493  ,\n",
       "         -8.715722  , -7.251414  , -5.211718  , -5.234632  , -0.9159179 ,\n",
       "         -7.1212673 , -3.8924098 , -3.0051398 , -5.3772187 , -4.2859263 ,\n",
       "          1.8142835 , -1.9127835 , -6.7963533 , -3.9224293 , -3.5612152 ,\n",
       "         -5.6772346 , -1.9109379 , -2.4962647 , -0.76522696,  5.523108  ,\n",
       "         -2.811867  , -2.6718936 ,  5.4987087 , -1.9994303 , -5.635449  ,\n",
       "         -5.228825  , -0.06761555, -3.9976752 ,  3.130942  , -3.9512815 ,\n",
       "         -6.956885  , -7.7051315 , -5.5200543 , -7.497815  , -7.509629  ,\n",
       "         -2.060125  , -0.91590095, -9.256552  , -8.937813  , -7.8798347 ,\n",
       "         -9.095185  , -9.046643  , -9.22834   , -7.130497  , -8.81659   ,\n",
       "         -9.451199  , -5.3077817 , -6.9906993 , -8.735127  , -8.706626  ,\n",
       "         -8.794824  , -9.046513  , -8.72794   , -9.159544  , -8.906576  ,\n",
       "         -7.6852984 , -7.562101  , -8.795605  , -6.6793094 , -0.91590476,\n",
       "         -9.430839  , -9.536487  , -7.443438  , -8.445799  , -9.250656  ,\n",
       "         -7.1366076 , -0.91614205, -8.580765  , -9.086012  , -6.31984   ,\n",
       "         -2.5211928 , -7.5302777 , -9.318062  , -9.742182  , -9.322397  ,\n",
       "         -9.221668  , -8.647197  , -7.5349345 , -8.266555  , -9.195984  ,\n",
       "         -8.94872   , -8.754266  , -7.225928  , -8.310898  , -9.067224  ,\n",
       "         -9.47138   , -9.14609   , -8.886299  , -8.951287  , -7.306273  ,\n",
       "         -8.898516  , -9.408068  , -9.131723  , -8.559364  , -8.835066  ,\n",
       "         -8.040502  , -8.083436  , -8.95496   , -9.078508  , -7.624845  ,\n",
       "         -8.330032  ]], dtype=float32))"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "end, end_onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1]]),\n",
       " 'input_ids': tensor([[    0,  8569,    16,     5,  1252,  8348,     7,   213,   116,     2,\n",
       "              2,  1121,    63,   419,   107,     6,     5,    92,  8825,  1312,\n",
       "           1447,     7,   972,  6856,     8,   903,  2113, 31274,  1092,   742,\n",
       "            870,  5241,     6,   171, 10087,  1739,  1252,    58,  8348,     5,\n",
       "            203,  2514,  8033, 33666,   824,    11,   764,  2659,    81,     5,\n",
       "            764,  3071,  9127,   824,   528,     7,     5,  5442,    18,  1804,\n",
       "            980,     4,    83,  5250,  2450,     7,  2879,    41,  2919,  1241,\n",
       "             10,  2303,   629,  1447,     7,  1338,     5,  1552,    80,    12,\n",
       "          10224,  1647,     7,  1323,     4,    96,   502,  4013,     6,  2711,\n",
       "            764,  3071,  1490,     5,   391,  1631,     6,    10,    68,   401,\n",
       "              4,  4718,   153,     6,  2440,     8,  1104, 10178,     6,  1271,\n",
       "           1812,     6,   151,  3925,  1730,    36,   406,     6,  4017,   475,\n",
       "            176,    43,     9,  8483,   980,     2]])}"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "fw_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 2.5175, -9.3370, -9.5036, -9.2836, -9.2332, -9.0282, -9.0427, -8.8275,\n",
       "          -9.8033, -9.7623, -9.8696, -7.7732, -8.4836, -8.0021, -9.4627, -9.9735,\n",
       "          -7.5483, -6.3275, -4.1584, -7.7244, -8.6535, -9.2064, -9.0236, -8.4924,\n",
       "          -9.4678, -8.7103, -9.1119, -8.0470, -6.6120, -6.5671, -1.4119, -4.6289,\n",
       "          -7.8756,  0.8409,  2.0125, -4.0130, -2.4590, -4.7481, -0.1235,  3.4790,\n",
       "           1.2760, -0.6418,  5.5592, -2.6643, -2.3955, -1.4975,  3.0133, -1.9406,\n",
       "          -3.4759,  0.0991,  1.7524, -3.6651, -3.6433, -5.0818, -6.8084, -8.0370,\n",
       "          -4.3071, -6.0028, -8.7697, -4.5208, -5.7817, -6.5671, -7.3898, -7.8200,\n",
       "          -9.3589, -9.0395, -8.4469, -8.5160, -7.7395, -9.0783, -8.1258, -4.2110,\n",
       "          -8.8292, -8.5163, -9.1294, -8.8214, -8.7204, -8.5580, -7.5532, -8.9369,\n",
       "          -8.8408, -8.8931, -9.1339, -8.8616, -6.5671, -8.4583, -7.9381, -8.5961,\n",
       "          -9.6361, -4.6034, -3.3610, -6.8178, -8.8042, -6.1084, -3.2126, -7.5068,\n",
       "          -9.8790, -8.5945, -7.4126, -8.1204, -8.7686, -8.9276, -9.5838, -9.7344,\n",
       "          -8.6226, -9.4182, -9.2721, -8.9731, -9.8824, -9.0905, -7.6414, -9.0766,\n",
       "          -9.1543, -8.8829, -9.7682, -9.3530, -8.5097, -9.0711, -9.2647, -9.1974,\n",
       "          -9.7145, -9.8482, -9.3534, -8.2329, -9.5750, -9.8258]],\n",
       "        grad_fn=<SqueezeBackward1>),\n",
       " tensor([[ 2.8267, -8.5263, -8.6090, -8.9226, -8.7796, -8.7678, -8.9101, -8.0934,\n",
       "          -8.1190, -8.3669, -8.0682, -9.3689, -9.1946, -9.2188, -7.8676, -7.9891,\n",
       "          -9.5384, -9.1513, -7.1765, -3.3620, -9.0531, -8.8566, -8.9853, -8.0942,\n",
       "          -8.7845, -8.7157, -7.2514, -5.2117, -5.2346, -0.9159, -7.1213, -3.8924,\n",
       "          -3.0051, -5.3772, -4.2859,  1.8143, -1.9128, -6.7963, -3.9224, -3.5612,\n",
       "          -5.6772, -1.9109, -2.4963, -0.7652,  5.5231, -2.8119, -2.6719,  5.4987,\n",
       "          -1.9994, -5.6355, -5.2288, -0.0676, -3.9977,  3.1309, -3.9513, -6.9569,\n",
       "          -7.7051, -5.5200, -7.4978, -7.5096, -2.0601, -0.9159, -9.2565, -8.9378,\n",
       "          -7.8798, -9.0952, -9.0466, -9.2283, -7.1305, -8.8166, -9.4512, -5.3078,\n",
       "          -6.9907, -8.7351, -8.7066, -8.7948, -9.0465, -8.7279, -9.1595, -8.9066,\n",
       "          -7.6853, -7.5621, -8.7956, -6.6793, -0.9159, -9.4308, -9.5365, -7.4434,\n",
       "          -8.4458, -9.2507, -7.1366, -0.9161, -8.5808, -9.0860, -6.3198, -2.5212,\n",
       "          -7.5303, -9.3181, -9.7422, -9.3224, -9.2217, -8.6472, -7.5349, -8.2666,\n",
       "          -9.1960, -8.9487, -8.7543, -7.2259, -8.3109, -9.0672, -9.4714, -9.1461,\n",
       "          -8.8863, -8.9513, -7.3063, -8.8985, -9.4081, -9.1317, -8.5594, -8.8351,\n",
       "          -8.0405, -8.0834, -8.9550, -9.0785, -7.6248, -8.3300]],\n",
       "        grad_fn=<SqueezeBackward1>))"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "model(**fw_args)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(*args, **kwargs):\n",
    "    kwargs.setdefault(\"padding\", \"longest\")\n",
    "    kwargs.setdefault(\"topk\", 1)\n",
    "    kwargs.setdefault(\"doc_stride\", 128)\n",
    "    kwargs.setdefault(\"max_answer_len\", 15)\n",
    "    kwargs.setdefault(\"max_seq_len\", 384)\n",
    "    kwargs.setdefault(\"max_question_len\", 64)\n",
    "    kwargs.setdefault(\"handle_impossible_answer\", False)\n",
    "    examples = _args_parser(*args, **kwargs)\n",
    "\n",
    "    features_list = [squad_convert_examples_to_features(\n",
    "        examples=[example],\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=kwargs[\"max_seq_len\"],\n",
    "        doc_stride=kwargs[\"doc_stride\"],\n",
    "        max_query_length=kwargs[\"max_question_len\"],\n",
    "        padding_strategy=PaddingStrategy.MAX_LENGTH.value,\n",
    "        is_training=False,\n",
    "        tqdm_enabled=False)\n",
    "        for example in examples]"
   ]
  }
 ]
}