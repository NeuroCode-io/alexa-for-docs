{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit ('.venv')",
   "metadata": {
    "interpreter": {
     "hash": "5bdca235408bc63495fd8719d073449338626e85bb6ce08bacdb45b63101d775"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.file_converter.pdf import PDFToTextConverter\n",
    "converter = PDFToTextConverter(remove_numeric_tables=True, valid_languages=[\"en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/home/elena/Projects/neurocode/alexa-for-docs'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = converter.convert(file_path=\"/home/elena/Downloads/9781839217579-THE_DEEP_LEARNING_WITH_KERAS_WORKSHOP_SECOND_EDITION.pdf\", meta=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(dict, 2, dict_keys(['text', 'meta']), 577807)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "type(book), len(book), book.keys(), len(book[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "type(book[\"meta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' Learning with Keras\\n\\nMatthew Moocarme\\nMahla Abdolahnejad\\nRitesh Bhagwat\\n\\nThe Deep Learning with Keras Workshop\\nSecond Edition\\nCopyright Â© 2020 Packt Publishing\\nAll rights reserved. No part of this book may be reproduced, stored in a retrieval system,\\nor transmitted in any form or by any means, without the prior written permission of the\\npublisher, except in the case of brief quotations embedded in critical articles or reviews.\\nEvery effort has been made in the preparation of this book to ensure the accuracy of\\nthe information presented. However, the information contained in this book is sold\\nwithout warranty, either express or implied. Neither the authors, nor Packt Publishing,\\nand its dealers and distributors will be held liable for any damages caused or alleged to\\nbe caused directly or indirectly by this book.\\nPackt Publishing has endeavored to provide trademark information about all of the\\ncompanies and products mentioned in this book by the appropriate use of capitals.\\nHowever, Packt Publishing cannot guarantee the accuracy of this information.\\nAuthors: Matthew Moocarme, Mahla Abdolahnejad, and Ritesh Bhagwat\\nReviewers: Vikraman Karunanidhi, Asheesh Mehta, Bernard Ong, and Anuj Shah\\nManaging Editor: Bhavesh Bangera\\nAcquisitions Editors: Kunal Sawant, Archie Vankar, and Karan Wadekar\\nProduction Editor: Samita Warang\\nEditorial Board: Shubhopriya Banerjee, Bharat Botle, Ewan Buckingham,\\nMegan Carlisle, Mahesh Dhyani, Manasa Kumar, Alex Mazonowicz, Bridget Neale,\\nDominic Pereira, Shiny Poojary, Abhishek Rane, Brendan Rodrigues, Mugdha Sawarkar,\\nErol Staveley, Ankita Thakur, Nitesh Thakur, and Jonathan Wray\\nFirst published: April 2019\\nSecond edition: February 2020\\nProduction reference: 1270220\\nPublished by Packt Publishing Ltd.\\nLivery Place, 35 Livery Street\\n\\nTable of Contents\\nPreface\\u202f\\t\\u202fi\\nChapter 1: Introduction to Machine Learning with Keras\\u202f\\t\\u202f1\\nIntroduction ..................................................................................................... 2\\nData Representation ...................................................................................... 4\\nTables of Data ........................................................................................................ 4\\nLoading Data ......................................................................................................... 5\\nExercise 1.01: Loading a Dataset from\\nthe UCI Machine Learning Repository ................................................................ 7\\n\\nData Preprocessing ....................................................................................... 10\\nExercise 1.02: Cleaning the Data ....................................................................... 12\\nAppropriate Representation of the Data ......................................................... 22\\nExercise 1.03: Appropriate Representation of the Data ................................ 23\\n\\nLife Cycle of Model Creation ........................................................................ 26\\nMachine Learning Libraries ............................................................................... 26\\n\\nscikit-learn ..................................................................................................... 27\\nKeras ............................................................................................................... 29\\nAdvantages of Keras...................................................................................... 30\\nDisadvantages of Keras................................................................................. 30\\nMore than Building Models ............................................................................... 31\\n\\nModel Training .............................................................................................. 32\\nClassifiers and Regression Models ................................................................... 32\\nClassification Tasks ............................................................................................. 34\\nRegression Tasks ................................................................................................. 35\\nTraining Datasets and Test Datasets ................................................................ 35\\nModel Evaluation Metrics .................................................................................. 36\\n\\nExercise 1.04: Creating a Simple Model ........................................................... 38\\n\\nModel Tuning ................................................................................................. 42\\nBaseline Models .................................................................................................. 42\\nExercise 1.05: Determining a Baseline Model ................................................. 42\\nRegularization ..................................................................................................... 44\\nCross-Validation .................................................................................................. 45\\nActivity 1.01: Adding Regularization to the Model .......................................... 46\\n\\nSummary ........................................................................................................ 48\\n\\nChapter 2: Machine Learning versus Deep Learning\\u202f\\t\\u202f51\\nIntroduction ................................................................................................... 52\\nAdvantages of ANNs over Traditional Machine Learning Algorithms .......... 54\\nAdvantages of Traditional Machine Learning Algorithms over ANNs .......... 56\\nHierarchical Data Representation .................................................................... 56\\n\\nLinear Transformations ............................................................................... 58\\nScalars, Vectors, Matrices, and Tensors ........................................................... 58\\nTensor Addition ................................................................................................... 59\\nExercise 2.01: Performing Various Operations\\nwith Vectors, Matrices, and Tensors ................................................................ 60\\nReshaping ............................................................................................................ 63\\nMatrix Transposition .......................................................................................... 64\\nExercise 2.02: Matrix Reshaping and Transposition ....................................... 65\\nMatrix Multiplication .......................................................................................... 68\\nExercise 2.03: Matrix Multiplication ................................................................. 70\\nExercise 2.04: Tensor Multiplication ................................................................. 71\\n\\nIntroduction to Keras ................................................................................... 73\\nLayer Types .......................................................................................................... 74\\nActivation Functions ........................................................................................... 76\\nModel Fitting ........................................................................................................ 77\\n\\nActivity 2.01: Creating a Logistic Regression Model Using Keras .................. 79\\n\\nSummary ........................................................................................................ 80\\n\\nChapter 3: Deep Learning with Keras\\u202f\\t\\u202f83\\nIntroduction ................................................................................................... 84\\nBuilding Your First Neural Network ........................................................... 84\\nLogistic Regression to a Deep Neural Network .............................................. 85\\nActivation Functions ........................................................................................... 88\\nForward Propagation for Making Predictions ................................................. 90\\nLoss Function ....................................................................................................... 92\\nBackpropagation for Computing Derivatives of Loss Function .................... 93\\nGradient Descent for Learning Parameters .................................................... 94\\nExercise 3.01: Neural Network Implementation with Keras ......................... 97\\nActivity 3.01: Building a Single-Layer Neural Network\\nfor Performing Binary Classification ............................................................. 103\\n\\nModel Evaluation ........................................................................................ 105\\nEvaluating a Trained Model with Keras ........................................................ 106\\nSplitting Data into Training and Test Sets .................................................... 107\\nUnderfitting and Overfitting ........................................................................... 109\\nEarly Stopping .................................................................................................. 114\\nActivity 3.02: Advanced Fibrosis Diagnosis with Neural Networks ........... 115\\n\\nSummary ...................................................................................................... 118\\n\\nChapter 4: Evaluating Your Model\\nwith CrossâValidation Using Keras Wrappers\\u202f\\t\\u202f121\\nIntroduction ................................................................................................. 122\\nCross-Validation .......................................................................................... 122\\nDrawbacks of Splitting a Dataset Only Once ................................................ 123\\nK-Fold Cross-Validation ................................................................................... 125\\n\\nLeave-One-Out Cross-Validation ...................................'"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "book[\"text\"][100:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /home/elena/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from haystack.preprocessor.preprocessor import PreProcessor\n",
    "\n",
    "processor = PreProcessor(clean_empty_lines=True,\n",
    "                         clean_whitespace=True,\n",
    "                         clean_header_footer=True,\n",
    "                         split_by=\"passage\",\n",
    "                         split_respect_sentence_boundary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = processor.process(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(list, 2, 2, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "type(doc), len(doc), len(doc[0]), len(doc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(dict, dict, dict_keys(['text', 'meta']), dict_keys(['text', 'meta']))"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "type(doc[0]), type(doc[1]), doc[0].keys(), doc[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(369553, 206464)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "len(doc[0][\"text\"]), len(doc[1][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Learning with Keras Matthew Moocarme\\nMahla Abdolahnejad\\nRitesh Bhagwat The Deep Learning with Keras Workshop\\nSecond Edition\\nCopyright Â© 2020 Packt Publishing\\nAll rights reserved. No part of this book may be reproduced, stored in a retrieval system,\\nor transmitted in any form or by any means, without the prior written permission of the\\npublisher, except in the case of brief quotations embedded in critical articles or reviews.\\nEvery effort has been made in the preparation of this book to ensure the accuracy of\\nthe information presented. However, the information contained in this book is sold\\nwithout warranty, either express or implied. Neither the authors, nor Packt Publishing,\\nand its dealers and distributors will be held liable for any damages caused or alleged to\\nbe caused directly or indirectly by this book.\\nPackt Publishing has endeavored to provide trademark information about all of the\\ncompanies and products mentioned in this book by the appropriate use of capitals.\\nHowever, Packt Publishing cannot guarantee the accuracy of this information.\\nAuthors: Matthew Moocarme, Mahla Abdolahnejad, and Ritesh Bhagwat\\nReviewers: Vikraman Karunanidhi, Asheesh Mehta, Bernard Ong, and Anuj Shah\\nManaging Editor: Bhavesh Bangera\\nAcquisitions Editors: Kunal Sawant, Archie Vankar, and Karan Wadekar\\nProduction Editor: Samita Warang\\nEditorial Board: Shubhopriya Banerjee, Bharat Botle, Ewan Buckingham,\\nMegan Carlisle, Mahesh Dhyani, Manasa Kumar, Alex Mazonowicz, Bridget Neale,\\nDominic Pereira, Shiny Poojary, Abhishek Rane, Brendan Rodrigues, Mugdha Sawarkar,\\nErol Staveley, Ankita Thakur, Nitesh Thakur, and Jonathan Wray\\nFirst published: April 2019\\nSecond edition: February 2020\\nProduction reference: 1270220\\nPublished by Packt Publishing Ltd.\\nLivery Place, 35 Livery Street Table of Contents\\nPreface\\u202f\\t\\u202fi\\nChapter 1: Introduction to Machine Learning with Keras\\u202f\\t\\u202f1\\nIntroduction ..................................................................................................... 2\\nData Representation ...................................................................................... 4\\nTables of Data ........................................................................................................ 4\\nLoading Data ......................................................................................................... 5\\nExercise 1.01: Loading a Dataset from\\nthe UCI Machine Learning Repository ................................................................ 7 Data Preprocessing ....................................................................................... 10\\nExercise 1.02: Cleaning the Data ....................................................................... 12\\nAppropriate Representation of the Data ......................................................... 22\\nExercise 1.03: Appropriate Representation of the Data ................................ 23 Life Cycle of Model Creation ........................................................................ 26\\nMachine Learning Libraries ............................................................................... 26 scikit-learn ..................................................................................................... 27\\nKeras ............................................................................................................... 29\\nAdvantages of Keras...................................................................................... 30\\nDisadvantages of Keras................................................................................. 30\\nMore than Building Models ............................................................................... 31 Model Training .............................................................................................. 32\\nClassifiers and Regression Models ................................................................... 32\\nClassification Tasks ............................................................................................. 34\\nRegression Tasks ................................................................................................. 35\\nTraining Datasets and Test Datasets ................................................................ 35\\nModel Evaluation Metrics .................................................................................. 36 Exercise 1.04: Creating a Simple Model ........................................................... 38 Model Tuning ................................................................................................. 42\\nBaseline Models .................................................................................................. 42\\nExercise 1.05: Determining a Baseline Model ................................................. 42\\nRegularization ..................................................................................................... 44\\nCross-Validation .................................................................................................. 45\\nActivity 1.01: Adding Regularization to the Model .......................................... 46 Summary ........................................................................................................ 48 Chapter 2: Machine Learning versus Deep Learning\\u202f\\t\\u202f51\\nIntroduction ................................................................................................... 52\\nAdvantages of ANNs over Traditional Machine Learning Algorithms .......... 54\\nAdvantages of Traditional Machine Learning Algorithms over ANNs .......... 56\\nHierarchical Data Representation .................................................................... 56 Linear Transformations ............................................................................... 58\\nScalars, Vectors, Matrices, and Tensors ........................................................... 58\\nTensor Addition ................................................................................................... 59\\nExercise 2.01: Performing Various Operations\\nwith Vectors, Matrices, and Tensors ................................................................ 60\\nReshaping ............................................................................................................ 63\\nMatrix Transposition .......................................................................................... 64\\nExercise 2.02: Matrix Reshaping and Transposition ....................................... 65\\nMatrix Multiplication .......................................................................................... 68\\nExercise 2.03: Matrix Multiplication ................................................................. 70\\nExercise 2.04: Tensor Multiplication ................................................................. 71 Introduction to Keras ................................................................................... 73\\nLayer Types .......................................................................................................... 74\\nActivation Functions ........................................................................................... 76\\nModel Fitting ........................................................................................................ 77 Activity 2.01: Creating a Logistic Regression Model Using Keras .................. 79 Summary ........................................................................................................ 80 Chapter 3: Deep Learning with Keras\\u202f\\t\\u202f83\\nIntroduction ................................................................................................... 84\\nBuilding Your First Neural Network ........................................................... 84\\nLogistic Regression to a Deep Neural Network .............................................. 85\\nActivation Functions ........................................................................................... 88\\nForward Propagation for Making Predictions ................................................. 90\\nLoss Function ....................................................................................................... 92\\nBackpropagation for Computing Derivatives of Loss Function .................... 93\\nGradient Descent for Learning Parameters .................................................... 94\\nExercise 3.01: Neural Network Implementation with Keras ......................... 97\\nActivity 3.01: Building a Single-Layer Neural Network\\nfor Performing Binary Classification ............................................................. 103 Model Evaluation ........................................................................................ 105\\nEvaluating a Trained Model with Keras ........................................................ 106\\nSplitting Data into Training and Test Sets .................................................... 107\\nUnderfitting and Overfitting ........................................................................... 109\\nEarly Stopping .................................................................................................. 114\\nActivity 3.02: Advanced Fibrosis Diagnosis with Neural Networks ........... 115 Summary ...................................................................................................... 118 Chapter 4: Evaluating Your Model\\nwith CrossâValidation Using Keras Wrappers\\u202f\\t\\u202f121\\nIntroduction ................................................................................................. 122\\nCross-Validation .......................................................................................... 122\\nDrawbacks of Splitting a Dataset Only Once ................................................ 123\\nK-Fold Cross-Validation ................................................................................... 125 Leave-One-Out Cross-Validation ........................................................'"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "doc[0][\"text\"][100:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /home/elena/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "processor2 = PreProcessor(clean_empty_lines=True,\n",
    "                         clean_whitespace=True,\n",
    "                         clean_header_footer=True,\n",
    "                         split_by=\"sentence\",\n",
    "                         split_length = 260,\n",
    "                         split_respect_sentence_boundary=True)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = processor2.process(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(list, 14, dict, dict_keys(['text', 'meta']), 53981, 30844)"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "type(sent), len(sent), type(sent[0]), sent[0].keys(), len(sent[0][\"text\"]), len(sent[9][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'_split_id': 2}"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "sent[2][\"meta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /home/elena/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "processor3 = PreProcessor(clean_empty_lines=True,\n",
    "                         clean_whitespace=True,\n",
    "                         clean_header_footer=True,\n",
    "                         split_by=\"word\",\n",
    "                         split_length = 260,\n",
    "                         split_respect_sentence_boundary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/01/2020 16:57:20 - WARNING - haystack.preprocessor.preprocessor -   A sentence found with word count higher than the split length.\n"
     ]
    }
   ],
   "source": [
    "word=processor3.process(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(list, 329, dict_keys(['text', 'meta']), {'_split_id': 0})"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "type(word), len(word), word[0].keys(), word[0][\"meta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_store.faiss import FAISSDocumentStore\n",
    "\n",
    "document_store = FAISSDocumentStore()\n",
    "document_store.delete_all_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.write_documents(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/01/2020 17:01:11 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "12/01/2020 17:01:18 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n"
     ]
    }
   ],
   "source": [
    "from haystack.retriever.dense import DensePassageRetriever\n",
    "retriever = DensePassageRetriever(document_store=document_store,\n",
    "                                  query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "                                  passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "                                  max_seq_len_query=64,\n",
    "                                  max_seq_len_passage=256,\n",
    "                                  batch_size=16,\n",
    "                                  use_gpu=False,\n",
    "                                  embed_title=True,\n",
    "                                  use_fast_tokenizers=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "essage: Truncation error: Specified max length is too low to respect the various constraints\n",
      "12/01/2020 17:01:23 - ERROR - farm.data_handler.processor -   Could not create sample(s) from this dict: \n",
      " {'passages': [{'title': '', 'text': \"Additionally, the upper bound value here is 1258, which is the index or count of\\nrows (or records) in the training set:\\nX_train = []\\ny_train = []\\nfor i in range(60, 1258):\\nX_train, y_train = np.array(X_train), np.array(y_train)\\n\\n406 | Appendix\\n6.Reshape the data to add an extra dimension to the end of X_train using NumPy's\\nreshape function:\\n\\n7.Import the following libraries to build the RNN:\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense, LSTM, Dropout\\n\\n8.Set the seed and initiate the sequential model, as follows:\\nseed = 1\\nnp.random.seed(seed)\\nrandom.set_seed(seed)\\nmodel = Sequential()\\n\\n9.Add an LSTM layer to the network with 50 units, set the return_sequences\\nargument to True, and set the input_shape argument to (X_train.shape[1],\\n1).Add three additional LSTM layers, each with 50 units, and set the return_\\nsequences argument to True for the first two.Add a final output layer of size 1:\\nmodel.add(LSTM(units = 50, return_sequences = True, input_shape = (X_\\n# Adding a second LSTM layer\\nmodel.add(LSTM(units = 50, return_sequences = True))\\n# Adding a third LSTM layer\\nmodel.add(LSTM(units = 50, return_sequences = True))\\n# Adding a fourth LSTM layer\\nmodel.add(LSTM(units = 50))\\n# Adding the output layer\\nmodel.add(Dense(units = 1))\\n\\n10.Compile the network with an adam optimizer and use Mean Squared Error for\\nthe loss.Fit the model to the training data for 100 epochs with a batch size of 32:\\n# Compiling the RNN\\nmodel.compile(optimizer = 'adam', loss = 'mean_squared_error')\\n# Fitting the RNN to the Training set\\nmodel.fit(X_train, y_train, epochs = 100, batch_size = 32)\\n\\nChapter 9: Sequential Modeling with Recurrent Neural Networks | 407\\n11.Load and process the test data (which is treated as actual data here) and select the\\ncolumn representing the value of Open stock data:\\ndataset_testing = pd.read_csv('../AMZN_test.csv')\\nactual_stock_price = dataset_testing[['Open']].values\\nactual_stock_price\\n\\n12.\", 'label': 'positive', 'external_id': '59188e5f-1343-4445-b518-7c0783f4e217'}]}\n",
      "12/01/2020 17:01:23 - ERROR - farm.data_handler.processor -   Error message: Truncation error: Specified max length is too low to respect the various constraints\n",
      "12/01/2020 17:01:23 - ERROR - farm.data_handler.processor -   Could not create sample(s) from this dict: \n",
      " {'passages': [{'title': '', 'text': \"Concatenate the data since we will need 60 previous instances to get the stock\\nprice for each day.Therefore, we will need both the training and test data:\\ntotal_data = pd.concat((dataset_training['Open'], dataset_\\ntesting['Open']), axis = 0)\\n\\n13.Reshape and scale the input to prepare the test data.Note that we are predicting\\nthe January monthly trend, which has 21 financial days, so in order to prepare the\\ntest set, we take the lower bound value as 60 and the upper bound value as 81.This\\nensures that the difference of 21 is maintained:\\ninputs = total_data[len(total_data) - len(dataset_testing) - 60:].values\\ninputs = inputs.reshape(-1,1)\\ninputs = sc.transform(inputs)\\nX_test = []\\nfor i in range(60, 81):\\nX_test = np.array(X_test)\\npredicted_stock_price = model.predict(X_test)\\npredicted_stock_price = sc.inverse_transform(predicted_stock_price)\\n\\n14.Visualize the results by plotting the actual stock price and plotting the predicted\\nstock price:\\n# Visualizing the results\\nplt.plot(actual_stock_price, color = 'green', label = 'Real Amazon\\nStock Price',ls='--')\\nplt.plot(predicted_stock_price, color = 'red', label = 'Predicted\\nAmazon Stock Price',ls='-')\\nplt.title('Predicted Stock Price')\\nplt.xlabel('Time in days')\\nplt.ylabel('Real Stock Price')\\nplt.legend()\\nplt.show()\\n\\nPlease note that your results may differ slightly from the actual stock price\\nof Amazon.408 | Appendix\\nExpected output:\\n\\nFigure 9.25: Real versus predicted stock prices\\n\\nAs shown in the preceding plot, the trends of the predicted and real prices are\\npretty much the same; the line has the same peaks and troughs.This is possible\\nbecause of LSTM's ability to remember sequenced data.A traditional feedforward\\nneural network would not have been able to forecast this result.This is the true\\npower of LSTM and RNNs.Activity 9.02: Predicting Amazon's Stock Price with Added Regularization\\nIn this activity, we will examine the stock price of Amazon over the last 5 years, from\\nJanuary 1, 2014, to December 31, 2018.\", 'label': 'positive', 'external_id': '2c88c6ac-0f42-48df-8142-b2381a29646e'}]}\n",
      "12/01/2020 17:01:23 - ERROR - farm.data_handler.processor -   Error message: Truncation error: Specified max length is too low to respect the various constraints\n",
      "12/01/2020 17:01:23 - ERROR - farm.data_handler.processor -   Could not create sample(s) from this dict: \n",
      " {'passages': [{'title': '', 'text': \"In doing so, we will try to predict and forecast\\nthe company's future trend for January 2019 using RNNs and an LSTM.We have the\\nactual values for January 2019, so we will be able to compare our predictions with the\\nactual values later.Initially, we predicted the trend of Amazon's stock price using an\\nLSTM with 50 units (or neurons).In this activity, we will also add dropout regularization\\nand compare the results with Activity 9.01, Predicting the Trend of Amazon's Stock Price\\nUsing an LSTM with 50 Units (Neurons).Follow these steps to complete this activity:\\n1.Import the required libraries:\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\nfrom tensorflow import random\\n\\nChapter 9: Sequential Modeling with Recurrent Neural Networks | 409\\n2.Import the dataset using the pandas read_csv function and look at the first five\\nrows of the dataset using the head method:\\ndataset_training = pd.read_csv('../AMZN_train.csv')\\ndataset_training.head()\\n\\n3.We are going to make our prediction using the Open stock price; therefore, select\\nthe Open stock price column from the dataset and print the values:\\ntraining_data = dataset_training[['Open']].values\\ntraining_data\\n\\nThe preceding code produces the following output:\\n...,\\n\\n4.Then, perform feature scaling by normalizing the data using MinMaxScaler\\nand setting the range of the features so that they have a minimum value of 0 and\\na maximum value of one.Use the fit_transform method of the scaler on the\\ntraining data:\\nfrom sklearn.preprocessing import MinMaxScaler\\nsc = MinMaxScaler(feature_range = (0, 1))\\ntraining_data_scaled = sc.fit_transform(training_data)\\ntraining_data_scaled\\n\\nThe preceding code produces the following output:\\n...,\\n\\n410 | Appendix\\n5.Create the data to get 60 timestamps from the current instance.\", 'label': 'positive', 'external_id': '6e583de2-a772-4c54-b6e9-df5aad79e3b5'}]}\n",
      "12/01/2020 17:01:23 - ERROR - farm.data_handler.processor -   Error message: Truncation error: Specified max length is too low to respect the various constraints\n",
      "12/01/2020 17:01:23 - ERROR - farm.data_handler.processor -   Could not create sample(s) from this dict: \n",
      " {'passages': [{'title': '', 'text': \"We chose 60 here\\nas it will give us a sufficient number of previous instances in order to understand\\nthe trend; technically, this can be any number, but 60 is the optimal value.Additionally, the upper bound value here is 1258, which is the index or count of\\nrows (or records) in the training set:\\nX_train = []\\ny_train = []\\nfor i in range(60, 1258):\\nX_train, y_train = np.array(X_train), np.array(y_train)\\n\\n6.Reshape the data to add an extra dimension to the end of X_train using NumPy's\\nreshape function:\\n\\n7.Import the following Keras libraries to build the RNN:\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense, LSTM, Dropout\\n\\n8.Set the seed and initiate the sequential model, as follows:\\nseed = 1\\nnp.random.seed(seed)\\nrandom.set_seed(seed)\\nmodel = Sequential()\\n\\n9.Add an LSTM layer to the network with 50 units, set the return_sequences\\nargument to True, and set the input_shape argument to (X_train.shape[1],\\n1).Add dropout to the model with rate=0.2.Add three additional LSTM layers,\\neach with 50 units, and set the return_sequences argument to True for the first\\ntwo.After each LSTM layer, add a dropout with rate=0.2.Add a final output layer\\nof size 1:\\nmodel.add(LSTM(units = 50, return_sequences = True, input_shape = (X_\\n# Adding a second LSTM layer and some Dropout regularization\\nmodel.add(LSTM(units = 50, return_sequences = True))\\n\\nChapter 9: Sequential Modeling with Recurrent Neural Networks | 411\\n# Adding a third LSTM layer and some Dropout regularization\\nmodel.add(LSTM(units = 50, return_sequences = True))\\n# Adding a fourth LSTM layer and some Dropout regularization\\nmodel.add(LSTM(units = 50))\\n# Adding the output layer\\nmodel.add(Dense(units = 1))\\n\\n10.Compile the network with an adam optimizer and use Mean Squared Error for\\nthe loss.\", 'label': 'positive', 'external_id': '97400fd3-3243-47c6-8c30-b00d52d669ab'}]}\n",
      "12/01/2020 17:01:23 - ERROR - farm.data_handler.processor -   Error message: Truncation error: Specified max length is too low to respect the various constraints\n",
      "12/01/2020 17:01:23 - ERROR - farm.data_handler.processor -   Could not create sample(s) from this dict: \n",
      " {'passages': [{'title': '', 'text': \"Fit the model to the training data for 100 epochs with a batch size of 32:\\n# Compiling the RNN\\nmodel.compile(optimizer = 'adam', loss = 'mean_squared_error')\\n# Fitting the RNN to the Training set\\nmodel.fit(X_train, y_train, epochs = 100, batch_size = 32)\\n\\n11.Load and process the test data (which is treated as actual data here) and select the\\ncolumn representing the value of Open stock data:\\ndataset_testing = pd.read_csv('../AMZN_test.csv')\\nactual_stock_price = dataset_testing[['Open']].values\\nactual_stock_price\\n\\n12.Concatenate the data since we will need 60 previous instances to get the stock\\nprice for each day.Therefore, we will need both the training and test data:\\ntotal_data = pd.concat((dataset_training['Open'], dataset_\\ntesting['Open']), axis = 0)\\n\\n13.Reshape and scale the input to prepare the test data.Note that we are predicting\\nthe January monthly trend, which has 21 financial days, so in order to prepare the\\ntest set, we take the lower bound value as 60 and the upper bound value as 81.This\\nensures that the difference of 21 is maintained:\\ninputs\\nvalues\\ninputs\\ninputs\\nX_test\\n\\n= total_data[len(total_data) - len(dataset_testing) - 60:].= sc.transform(inputs)\\n= []\\n\\n412 | Appendix\\nfor i in range(60, 81):\\nX_test = np.array(X_test)\\npredicted_stock_price = model.predict(X_test)\\npredicted_stock_price = sc.inverse_transform(predicted_stock_price)\\n\\n14.Visualize the results by plotting the actual stock price and plotting the predicted\\nstock price:\\n# Visualizing the results\\nplt.plot(actual_stock_price, color = 'green', label = 'Real Amazon\\nStock Price',ls='--')\\nplt.plot(predicted_stock_price, color = 'red', label = 'Predicted\\nAmazon Stock Price',ls='-')\\nplt.title('Predicted Stock Price')\\nplt.xlabel('Time in days')\\nplt.ylabel('Real Stock Price')\\nplt.legend()\\nplt.show()\\n\\nPlease note that your results may differ slightly to the actual stock price.\", 'label': 'positive', 'external_id': 'df8b4124-9b32-4b0d-b1b8-3b47180cb688'}]}\n",
      "12/01/2020 17:01:23 - ERROR - farm.data_handler.processor -   Error message: Truncation error: Specified max length is too low to respect the various constraints\n",
      "12/01/2020 17:01:23 - ERROR - farm.data_handler.processor -   Could not create sample(s) from this dict: \n",
      " {'passages': [{'title': '', 'text': \"Expected output:\\n\\nFigure 9.26: Real versus predicted stock prices\\n\\nChapter 9: Sequential Modeling with Recurrent Neural Networks | 413\\nIn the following figure, the first plot displays the predicted output of the model with\\nregularization from Activity 9.02, and the second displays the predicted output without\\nregularization from Activity 9.01.As you can see, adding dropout regularization does not\\nfit the data as accurately.So, in this case, it is better not to use regularization, or to use\\ndropout regularization with a lower dropout rate:\\n\\nFigure 9.27: Comparing the results of Activity 9.01 and Activity 9.02\\n\\nActivity 9.03: Predicting the Trend of Amazon's Stock Price Using an LSTM\\nwith an Increasing Number of LSTM Neurons (100 Units)\\nIn this activity, we will examine the stock price of Amazon over the last 5 years, from\\nJanuary 1, 2014, to December 31, 2018.We will try to predict and forecast the company's\\nfuture trend for January 2019 using RNNs with four LSTM layers, each with 100 units.We\\nhave the actual values for January 2019, so we will be able to compare our predictions\\nwith the actual values later.You can also compare the output difference with Activity\\n9.01, Predicting the Trend of Amazon's Stock Price Using an LSTM with 50 Units\\n(Neurons).Follow these steps to complete this activity:\\n1.Import the required libraries:\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\nfrom tensorflow import random\\n\\n2.Import the dataset using the pandas read_csv function and look at the first five\\nrows of the dataset using the head method:\\ndataset_training = pd.read_csv('../AMZN_train.csv')\\ndataset_training.head()\\n\\n414 | Appendix\\n3.\", 'label': 'positive', 'external_id': '789b8eb9-a88b-48a4-a0db-7f9a970df1b2'}]}\n",
      "12/01/2020 17:01:23 - ERROR - farm.data_handler.processor -   Error message: Truncation error: Specified max length is too low to respect the various constraints\n",
      "12/01/2020 17:01:23 - ERROR - farm.data_handler.processor -   Could not create sample(s) from this dict: \n",
      " {'passages': [{'title': '', 'text': \"We are going to make our prediction using the Open stock price; therefore, select\\nthe Open stock price column from the dataset and print the values:\\ntraining_data = dataset_training[['Open']].values\\ntraining_data\\n\\n4.Then, perform feature scaling by normalizing the data using MinMaxScaler and\\nsetting the range of the features so that they have a minimum value of zero and\\na maximum value of one.Use the fit_transform method of the scaler on the\\ntraining data:\\nfrom sklearn.preprocessing import MinMaxScaler\\nsc = MinMaxScaler(feature_range = (0, 1))\\ntraining_data_scaled = sc.fit_transform(training_data)\\ntraining_data_scaled\\n\\n5.Create the data to get 60 timestamps from the current instance.We chose 60 here\\nas it will give us a sufficient number of previous instances in order to understand\\nthe trend; technically, this can be any number, but 60 is the optimal value.Additionally, the upper bound value here is 1258, which is the index or count of\\nrows (or records) in the training set:\\nX_train = []\\ny_train = []\\nfor i in range(60, 1258):\\nX_train, y_train = np.array(X_train), np.array(y_train)\\n\\n6.Reshape the data to add an extra dimension to the end of X_train using NumPy's\\nreshape function:\\n\\n7.Import the following Keras libraries to build the RNN:\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense, LSTM, Dropout\\n\\n8.Set the seed and initiate the sequential model:\\nseed = 1\\nnp.random.seed(seed)\\nrandom.set_seed(seed)\\nmodel = Sequential()\\n\\nChapter 9: Sequential Modeling with Recurrent Neural Networks | 415\\n9.Add an LSTM layer to the network with 100 units, set the return_sequences\\nargument to True, and set the input_shape argument to (X_train.shape[1],\\n1).Add three additional LSTM layers, each with 100 units, and set the return_\\nsequences argument to True for the first two.\", 'label': 'positive', 'external_id': '35189814-81d7-460d-a891-fdc0cb3a7df5'}]}\n",
      "12/01/2020 17:01:23 - ERROR - farm.data_handler.processor -   Error message: Truncation error: Specified max length is too low to respect the various constraints\n",
      "12/01/2020 17:01:23 - ERROR - farm.data_handler.processor -   Could not create sample(s) from this dict: \n",
      " {'passages': [{'title': '', 'text': \"Add a final output layer of size 1:\\nmodel.add(LSTM(units = 100, return_sequences = True, input_shape = (X_\\n# Adding a second LSTM layer\\nmodel.add(LSTM(units = 100, return_sequences = True))\\n# Adding a third LSTM layer\\nmodel.add(LSTM(units = 100, return_sequences = True))\\n# Adding a fourth LSTM layer\\nmodel.add(LSTM(units = 100))\\n# Adding the output layer\\nmodel.add(Dense(units = 1))\\n\\n10.Compile the network with an adam optimizer and use Mean Squared Error for\\nthe loss.Fit the model to the training data for 100 epochs with a batch size of 32:\\n# Compiling the RNN\\nmodel.compile(optimizer = 'adam', loss = 'mean_squared_error')\\n# Fitting the RNN to the Training set\\nmodel.fit(X_train, y_train, epochs = 100, batch_size = 32)\\n\\n11.Load and process the test data (which is treated as actual data here) and select the\\ncolumn representing the value of open stock data:\\ndataset_testing = pd.read_csv('../AMZN_test.csv')\\nactual_stock_price = dataset_testing[['Open']].values\\nactual_stock_price\\n\\n12.Concatenate the data since we will need 60 previous instances to get the stock\\nprice for each day.Therefore, we will need both the training and test data:\\ntotal_data = pd.concat((dataset_training['Open'], dataset_\\ntesting['Open']), axis = 0)\\n\\n416 | Appendix\\n13.Reshape and scale the input to prepare the test data.Note that we are predicting\\nthe January monthly trend, which has 21 financial days, so in order to prepare the\\ntest set, we take the lower bound value as 60 and the upper bound value as 81.This\\nensures that the difference of 21 is maintained:\\ninputs = total_data[len(total_data) - len(dataset_testing) - 60:].values\\ninputs = inputs.reshape(-1,1)\\ninputs = sc.transform(inputs)\\nX_test = []\\nfor i in range(60, 81):\\nX_test = np.array(X_test)\\npredicted_stock_price = model.predict(X_test)\\npredicted_stock_price = sc.inverse_transform(predicted_stock_price)\\n\\n14.\", 'label': 'positive', 'external_id': '58c637f1-d02e-4428-9cbd-e7d4be14c409'}]}\n",
      "12/01/2020 17:01:23 - ERROR - farm.data_handler.processor -   Error message: Truncation error: Specified max length is too low to respect the various constraints\n",
      "12/01/2020 17:01:23 - ERROR - farm.data_handler.processor -   Could not create sample(s) from this dict: \n",
      " {'passages': [{'title': '', 'text': \"Visualize the results by plotting the actual stock price and plotting the predicted\\nstock price:\\nplt.plot(actual_stock_price, color = 'green', label = 'Actual Amazon\\nStock Price',ls='--')\\nplt.plot(predicted_stock_price, color = 'red', label = 'Predicted\\nAmazon Stock Price',ls='-')\\nplt.title('Predicted Stock Price')\\nplt.xlabel('Time in days')\\nplt.ylabel('Real Stock Price')\\nplt.legend()\\nplt.show()\\n\\nPlease note that your results may differ slightly from the actual stock price.Chapter 9: Sequential Modeling with Recurrent Neural Networks | 417\\nExpected output:\\n\\nFigure 9.28: Real versus predicted stock prices\\n\\nSo, if we compare the results of the LSTM with 50 units (from Activity 9.01, Predicting\\nthe Trend of Amazon's Stock Price Using an LSTM with 50 Units (Neurons)) and the LSTM\\nwith 100 units in this activity, we get trends with 100 units.Also, note that when we run\\nthe LSTM with 100 units, it takes more computational time than the LSTM with 50 units.A trade-off needs to be considered in such cases:\\n\\nFigure 9.29: Comparing the real versus predicted stock price with 50 and 100 units\\n\\n>\\nIndex\\n\\nAbout\\nAll major keywords used in this book are captured alphabetically in this section.Each one is\\naccompanied by the page number of where they appear.A\\n\\nB\\n\\nC\\n\\nD\\n\\nE\\n\\nF\\n\\nG\\n\\nI\\n\\nL\\n\\nM\\n\\nO\\n\\nP\\n\\nR\\n\\nS\\n\\nT\\n\\nU\\n\\nV\\n\\nW\\n\\nX\\n\\nY\\n\\nZ\", 'label': 'positive', 'external_id': 'a1ca968c-763a-4034-948e-fec44ff3a62b'}]}\n",
      "12/01/2020 17:01:23 - ERROR - farm.data_handler.processor -   Error message: Truncation error: Specified max length is too low to respect the various constraints\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-a042bbe71db2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdocument_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretriever\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/neurocode/alexa-for-docs/.venv/lib/python3.8/site-packages/haystack/document_store/faiss.py\u001b[0m in \u001b[0;36mupdate_embeddings\u001b[0;34m(self, retriever, index)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Updating embeddings for {len(documents)} docs...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_passages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/neurocode/alexa-for-docs/.venv/lib/python3.8/site-packages/haystack/retriever/dense.py\u001b[0m in \u001b[0;36membed_passages\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \"external_id\": d.id}]\n\u001b[1;32m    201\u001b[0m         } for d in docs]\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpassage_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"passages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/neurocode/alexa-for-docs/.venv/lib/python3.8/site-packages/haystack/retriever/dense.py\u001b[0m in \u001b[0;36m_get_predictions\u001b[0;34m(self, dicts, tokenizer)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mof\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m\"passages\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"query\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \"\"\"\n\u001b[0;32m--> 153\u001b[0;31m         dataset, tensor_names, baskets = self.processor.dataset_from_dicts(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0mdicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_baskets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         )\n",
      "\u001b[0;32m~/Projects/neurocode/alexa-for-docs/.venv/lib/python3.8/site-packages/farm/data_handler/processor.py\u001b[0m in \u001b[0;36mdataset_from_dicts\u001b[0;34m(self, dicts, indices, return_baskets)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_samples_in_baskets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_featurize_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/neurocode/alexa-for-docs/.venv/lib/python3.8/site-packages/farm/data_handler/processor.py\u001b[0m in \u001b[0;36m_featurize_samples\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_featurize_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbasket\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaskets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbasket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                     \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_to_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " | 360M/496M [01:10<00:49, 2.77MB/s]\u001b[A\n",
      "Downloading:  73%|ââââââââ  | 360M/496M [01:10<00:46, 2.91MB/s]\u001b[A\n",
      "Downloading:  73%|ââââââââ  | 361M/496M [01:10<00:44, 3.03MB/s]\u001b[A\n",
      "Downloading:  73%|ââââââââ  | 361M/496M [01:10<00:42, 3.19MB/s]\u001b[A\n",
      "Downloading:  73%|ââââââââ  | 361M/496M [01:10<00:40, 3.31MB/s]\u001b[A\n",
      "Downloading:  73%|ââââââââ  | 362M/496M [01:10<00:37, 3.56MB/s]\u001b[A\n",
      "Downloading:  73%|ââââââââ  | 362M/496M [01:10<00:34, 3.86MB/s]\u001b[A\n",
      "Downloading:  73%|ââââââââ  | 363M/496M [01:11<00:34, 3.83MB/s]\u001b[A\n",
      "Downloading:  73%|ââââââââ  | 363M/496M [01:11<00:31, 4.16MB/s]\u001b[A\n",
      "Downloading:  73%|ââââââââ  | 364M/496M [01:11<00:30, 4.37MB/s]\u001b[A\n",
      "Downloading:  73%|ââââââââ  | 364M/496M [01:11<00:27, 4.72MB/s]\u001b[A\n",
      "Downloading:  74%|ââââââââ  | 365M/496M [01:11<00:28, 4.66MB/s]\u001b[A\n",
      "Downloading:  74%|ââââââââ  | 365M/496M [01:11<00:26, 4.95MB/s]\u001b[A\n",
      "Downloading:  74%|ââââââââ  | 366M/496M [01:11<00:26, 4.97MB/s]\u001b[A\n",
      "Downloading:  74%|ââââââââ  | 367M/496M [01:11<00:26, 4.83MB/s]\u001b[A\n",
      "Downloading:  74%|ââââââââ  | 367M/496M [01:11<00:24, 5.32MB/s]\u001b[A\n",
      "Downloading:  74%|ââââââââ  | 368M/496M [01:11<00:23, 5.46MB/s]\u001b[A\n",
      "Downloading:  74%|ââââââââ  | 368M/496M [01:12<00:22, 5.75MB/s]\u001b[A\n",
      "Downloading:  74%|ââââââââ  | 369M/496M [01:12<00:21, 6.01MB/s]\u001b[A\n",
      "Downloading:  75%|ââââââââ  | 370M/496M [01:12<00:20, 6.03MB/s]\u001b[A\n",
      "Downloading:  75%|ââââââââ  | 370M/496M [01:12<00:27, 4.61MB/s]\u001b[A\n",
      "Downloading:  75%|ââââââââ  | 372M/496M [01:12<00:22, 5.63MB/s]\u001b[A\n",
      "Downloading:  75%|ââââââââ  | 372M/496M [01:12<00:21, 5.73MB/s]\u001b[A\n",
      "Downloading:  75%|ââââââââ  | 373M/496M [01:12<00:21, 5.84MB/s]\u001b[A\n",
      "Downloading:  75%|ââââââââ  | 374M/496M [01:12<00:20, 5.91MB/s]\u001b[A\n",
      "Downloading:  75%|ââââââââ  | 374M/496M [01:13<00:21, 5.81MB/s]\u001b[A\n",
      "Downloading:  76%|ââââââââ  | 375M/496M [01:13<00:22, 5.42MB/s]\u001b[A\n",
      "Downloading:  76%|ââââââââ  | 376M/496M [01:13<00:20, 5.81MB/s]\u001b[A\n",
      "Downloading:  76%|ââââââââ  | 376M/496M [01:13<00:23, 5.20MB/s]\u001b[A\n",
      "Downloading:  76%|ââââââââ  | 377M/496M [01:13<00:25, 4.66MB/s]\u001b[A\n",
      "Downloading:  76%|ââââââââ  | 377M/496M [01:13<00:29, 4.10MB/s]\u001b[A\n",
      "Downloading:  76%|ââââââââ  | 378M/496M [01:13<00:29, 4.01MB/s]\u001b[A\n",
      "Downloading:  76%|ââââââââ  | 378M/496M [01:13<00:28, 4.22MB/s]\u001b[A\n",
      "Downloading:  76%|ââââââââ  | 379M/496M [01:14<00:29, 4.03MB/s]\u001b[A\n",
      "Downloading:  76%|ââââââââ  | 379M/496M [01:14<00:27, 4.21MB/s]\u001b[A\n",
      "Downloading:  76%|ââââââââ  | 380M/496M [01:14<00:26, 4.40MB/s]\u001b[A\n",
      "Downloading:  77%|ââââââââ  | 380M/496M [01:14<00:26, 4.38MB/s]\u001b[A\n",
      "Downloading:  77%|ââââââââ  | 381M/496M [01:14<00:25, 4.60MB/s]\u001b[A\n",
      "Downloading:  77%|ââââââââ  | 381M/496M [01:14<00:23, 4.89MB/s]\u001b[A\n",
      "Downloading:  77%|ââââââââ  | 382M/496M [01:14<00:23, 4.96MB/s]\u001b[A\n",
      "Downloading:  77%|ââââââââ  | 382M/496M [01:14<00:22, 5.14MB/s]\u001b[A\n",
      "Downloading:  77%|ââââââââ  | 383M/496M [01:14<00:22, 5.13MB/s]\u001b[A\n",
      "Downloading:  77%|ââââââââ  | 383M/496M [01:14<00:20, 5.40MB/s]\u001b[A\n",
      "Downloading:  77%|ââââââââ  | 384M/496M [01:15<00:21, 5.25MB/s]\u001b[A\n",
      "Downloading:  77%|ââââââââ  | 385M/496M [01:15<00:22, 5.05MB/s]\u001b[A\n",
      "Downloading:  78%|ââââââââ  | 385M/496M [01:15<00:21, 5.09MB/s]\u001b[A\n",
      "Downloading:  78%|ââââââââ  | 386M/496M [01:15<00:21, 5.18MB/s]\u001b[A\n",
      "Downloading:  78%|ââââââââ  | 386M/496M [01:15<00:21, 5.19MB/s]\u001b[A\n",
      "Downloading:  78%|ââââââââ  | 387M/496M [01:15<00:21, 5.14MB/s]\u001b[A\n",
      "Downloading:  78%|ââââââââ  | 387M/496M [01:15<00:20, 5.28MB/s]\u001b[A\n",
      "Downloading:  78%|ââââââââ  | 388M/496M [01:15<00:22, 4.90MB/s]\u001b[A\n",
      "Downloading:  78%|ââââââââ  | 388M/496M [01:15<00:22, 4.89MB/s]\u001b[A\n",
      "Downloading:  78%|ââââââââ  | 389M/496M [01:16<00:20, 5.18MB/s]\u001b[A\n",
      "Downloading:  78%|ââââââââ  | 390M/496M [01:16<00:19, 5.39MB/s]\u001b[A\n",
      "Downloading:  79%|ââââââââ  | 390M/496M [01:16<00:19, 5.45MB/s]\u001b[A\n",
      "Downloading:  79%|ââââââââ  | 391M/496M [01:16<00:19, 5.44MB/s]\u001b[A\n",
      "Downloading:  79%|ââââââââ  | 391M/496M [01:16<00:18, 5.65MB/s]\u001b[A\n",
      "Downloading:  79%|ââââââââ  | 392M/496M [01:16<00:19, 5.48MB/s]\u001b[A\n",
      "Downloading:  79%|ââââââââ  | 393M/496M [01:16<00:19, 5.46MB/s]\u001b[A\n",
      "Downloading:  79%|ââââââââ  | 393M/496M [01:16<00:18, 5.60MB/s]\u001b[A\n",
      "Downloading:  79%|ââââââââ  | 394M/496M [01:16<00:19, 5.14MB/s]\u001b[A\n",
      "Downloading:  79%|ââââââââ  | 394M/496M [01:17<00:21, 4.86MB/s]\u001b[A\n",
      "Downloading:  80%|ââââââââ  | 395M/496M [01:17<00:22, 4.58MB/s]\u001b[A\n",
      "Downloading:  80%|ââââââââ  | 395M/496M [01:17<00:23, 4.33MB/s]\u001b[A\n",
      "Downloading:  80%|ââââââââ  | 396M/496M [01:17<00:22, 4.56MB/s]\u001b[A\n",
      "Downloading:  80%|ââââââââ  | 396M/496M [01:17<00:22, 4.53MB/s]\u001b[A\n",
      "Downloading:  80%|ââââââââ  | 397M/496M [01:17<00:21, 4.66MB/s]\u001b[A\n",
      "Downloading:  80%|ââââââââ  | 397M/496M [01:17<00:21, 4.71MB/s]\u001b[A\n",
      "Downloading:  80%|ââââââââ  | 398M/496M [01:17<00:20, 4.73MB/s]\u001b[A\n",
      "Downloading:  80%|ââââââââ  | 398M/496M [01:17<00:21, 4.67MB/s]\u001b[A\n",
      "Downloading:  80%|ââââââââ  | 399M/496M [01:18<00:19, 5.04MB/s]\u001b[A\n",
      "Downloading:  80%|ââââââââ  | 399M/496M [01:18<00:18, 5.13MB/s]\u001b[A\n",
      "Downloading:  81%|ââââââââ  | 400M/496M [01:18<00:18, 5.13MB/s]\u001b[A\n",
      "Downloading:  81%|ââââââââ  | 400M/496M [01:18<00:17, 5.41MB/s]\u001b[A\n",
      "Downloading:  81%|ââââââââ  | 401M/496M [01:18<00:18, 5.20MB/s]\u001b[A\n",
      "Downloading:  81%|ââââââââ  | 402M/496M [01:18<00:18, 5.07MB/s]\u001b[A\n",
      "Downloading:  81%|ââââââââ  | 402M/496M [01:18<00:18, 4.99MB/s]\u001b[A\n",
      "Downloading:  81%|ââââââââ  | 403M/496M [01:18<00:19, 4.79MB/s]\u001b[A\n",
      "Downloading:  81%|ââââââââ  | 403M/496M [01:18<00:19, 4.86MB/s]\u001b[A\n",
      "Downloading:  81%|âââââââââ | 404M/496M [01:18<00:18, 5.12MB/s]\u001b[A\n",
      "Downloading:  81%|âââââââââ | 404M/496M [01:19<00:17, 5.24MB/s]\u001b[A\n",
      "Downloading:  82%|âââââââââ | 405M/496M [01:19<00:17, 5.13MB/s]\u001b[A\n",
      "Downloading:  82%|âââââââââ | 405M/496M [01:19<00:18, 5.04MB/s]\u001b[A\n",
      "Downloading:  82%|âââââââââ | 406M/496M [01:19<00:20, 4.40MB/s]\u001b[A\n",
      "Downloading:  82%|âââââââââ | 406M/496M [01:19<00:20, 4.49MB/s]\u001b[A\n",
      "Downloading:  82%|âââââââââ | 407M/496M [01:19<00:18, 4.77MB/s]\u001b[A\n",
      "Downloading:  82%|âââââââââ | 408M/496M [01:19<00:17, 4.98MB/s]\u001b[A\n",
      "Downloading:  82%|âââââââââ | 408M/496M [01:19<00:16, 5.32MB/s]\u001b[A\n",
      "Downloading:  82%|âââââââââ | 409M/496M [01:19<00:17, 5.07MB/s]\u001b[A\n",
      "Downloading:  82%|âââââââââ | 409M/496M [01:20<00:17, 5.01MB/s]\u001b[A\n",
      "Downloading:  83%|âââââââââ | 410M/496M [01:20<00:17, 4.87MB/s]\u001b[A\n",
      "Downloading:  83%|âââââââââ | 410M/496M [01:20<00:17, 4.99MB/s]\u001b[A\n",
      "Downloading:  83%|âââââââââ | 411M/496M [01:20<00:16, 5.12MB/s]\u001b[A\n",
      "Downloading:  83%|âââââââââ | 411M/496M [01:20<00:17, 5.00MB/s]\u001b[A\n",
      "Downloading:  83%|âââââââââ | 412M/496M [01:20<00:17, 4.91MB/s]\u001b[A\n",
      "Downloading:  83%|âââââââââ | 412M/496M [01:20<00:16, 5.09MB/s]\u001b[A\n",
      "Downloading:  83%|âââââââââ | 413M/496M [01:20<00:17, 4.89MB/s]\u001b[A\n",
      "Downloading:  83%|âââââââââ | 413M/496M [01:21<00:26, 3.09MB/s]\u001b[A\n",
      "Downloading:  83%|âââââââââ | 414M/496M [01:21<00:23, 3.55MB/s]\u001b[A\n",
      "Downloading:  84%|âââââââââ | 415M/496M [01:21<00:20, 3.98MB/s]\u001b[A\n",
      "Downloading:  84%|âââââââââ | 415M/496M [01:21<00:18, 4.34MB/s]\u001b[A\n",
      "Downloading:  84%|âââââââââ | 416M/496M [01:21<00:18, 4.32MB/s]\u001b[A\n",
      "Downloading:  84%|âââââââââ | 416M/496M [01:21<00:18, 4.39MB/s]\u001b[A\n",
      "Downloading:  84%|âââââââââ | 417M/496M [01:21<00:16, 4.82MB/s]\u001b[A\n",
      "Downloading:  84%|âââââââââ | 417M/496M [01:21<00:16, 4.87MB/s]\u001b[A\n",
      "Downloading:  84%|âââââââââ | 418M/496M [01:21<00:15, 5.15MB/s]\u001b[A\n",
      "Downloading:  84%|âââââââââ | 418M/496M [01:22<00:15, 5.19MB/s]\u001b[A\n",
      "Downloading:  84%|âââââââââ | 419M/496M [01:22<00:16, 4.82MB/s]\u001b[A\n",
      "Downloading:  85%|âââââââââ | 420M/496M [01:22<00:15, 4.99MB/s]\u001b[A\n",
      "Downloading:  85%|âââââââââ | 420M/496M [01:22<00:14, 5.34MB/s]\u001b[A\n",
      "Downloading:  85%|âââââââââ | 421M/496M [01:22<00:13, 5.53MB/s]\u001b[A\n",
      "Downloading:  85%|âââââââââ | 421M/496M [01:22<00:13, 5.50MB/s]\u001b[A\n",
      "Downloading:  85%|âââââââââ | 422M/496M [01:22<00:13, 5.46MB/s]\u001b[A\n",
      "Downloading:  85%|âââââââââ | 423M/496M [01:22<00:13, 5.39MB/s]\u001b[A\n",
      "Downloading:  85%|âââââââââ | 423M/496M [01:22<00:13, 5.35MB/s]\u001b[A\n",
      "Downloading:  85%|âââââââââ | 424M/496M [01:23<00:14, 5.00MB/s]\u001b[A\n",
      "Downloading:  85%|âââââââââ | 424M/496M [01:23<00:15, 4.78MB/s]\u001b[A\n",
      "Downloading:  86%|âââââââââ | 425M/496M [01:23<00:15, 4.72MB/s]\u001b[A\n",
      "Downloading:  86%|âââââââââ | 425M/496M [01:23<00:15, 4.47MB/s]\u001b[A\n",
      "Downloading:  86%|âââââââââ | 426M/496M [01:23<00:16, 4.29MB/s]\u001b[A\n",
      "Downloading:  86%|âââââââââ | 426M/496M [01:23<00:16, 4.34MB/s]\u001b[A\n",
      "Downloading:  86%|âââââââââ | 427M/496M [01:23<00:15, 4.61MB/s]\u001b[A\n",
      "Downloading:  86%|âââââââââ | 427M/496M [01:23<00:15, 4.56MB/s]\u001b[A\n",
      "Downloading:  86%|âââââââââ | 428M/496M [01:23<00:14, 4.77MB/s]\u001b[A\n",
      "Downloading:  86%|âââââââââ | 428M/496M [01:24<00:14, 4.87MB/s]\u001b[A\n",
      "Downloading:  86%|âââââââââ | 429M/496M [01:24<00:13, 5.15MB/s]\u001b[A\n",
      "Downloading:  86%|âââââââââ | 429M/496M [01:24<00:12, 5.43MB/s]\u001b[A\n",
      "Downloading:  87%|âââââââââ | 430M/496M [01:24<00:12, 5.22MB/s]\u001b[A\n",
      "Downloading:  87%|âââââââââ | 431M/496M [01:24<00:11, 5.55MB/s]\u001b[A\n",
      "Downloading:  87%|âââââââââ | 431M/496M [01:24<00:11, 5.83MB/s]\u001b[A\n",
      "Downloading:  87%|âââââââââ | 432M/496M [01:24<00:11, 5.84MB/s]\u001b[A\n",
      "Downloading:  87%|âââââââââ | 432M/496M [01:24<00:11, 5.72MB/s]\u001b[A\n",
      "Downloading:  87%|âââââââââ | 433M/496M [01:24<00:11, 5.60MB/s]\u001b[A\n",
      "Downloading:  87%|âââââââââ | 434M/496M [01:25<00:12, 5.18MB/s]\u001b[A\n",
      "Downloading:  87%|âââââââââ | 434M/496M [01:25<00:11, 5.26MB/s]\u001b[A\n",
      "Downloading:  88%|âââââââââ | 435M/496M [01:25<00:11, 5.57MB/s]\u001b[A\n",
      "Downloading:  88%|âââââââââ | 435M/496M [01:25<00:10, 5.61MB/s]\u001b[A\n",
      "Downloading:  88%|âââââââââ | 436M/496M [01:25<00:10, 5.56MB/s]\u001b[A\n",
      "Downloading:  88%|âââââââââ | 436M/496M [01:25<00:11, 5.30MB/s]\u001b[A\n",
      "Downloading:  88%|âââââââââ | 437M/496M [01:25<00:11, 5.26MB/s]\u001b[A\n",
      "Downloading:  88%|âââââââââ | 437M/496M [01:25<00:11, 4.98MB/s]\u001b[A\n",
      "Downloading:  88%|âââââââââ | 438M/496M [01:25<00:11, 4.97MB/s]\u001b[A\n",
      "Downloading:  88%|âââââââââ | 439M/496M [01:25<00:11, 5.07MB/s]\u001b[A\n",
      "Downloading:  88%|âââââââââ | 439M/496M [01:26<00:11, 5.05MB/s]\u001b[A\n",
      "Downloading:  89%|âââââââââ | 440M/496M [01:26<00:12, 4.69MB/s]\u001b[A\n",
      "Downloading:  89%|âââââââââ | 440M/496M [01:26<00:11, 4.82MB/s]\u001b[A\n",
      "Downloading:  89%|âââââââââ | 441M/496M [01:26<00:11, 4.78MB/s]\u001b[A\n",
      "Downloading:  89%|âââââââââ | 441M/496M [01:26<00:11, 4.80MB/s]\u001b[A\n",
      "Downloading:  89%|âââââââââ | 442M/496M [01:26<00:11, 4.80MB/s]\u001b[A\n",
      "Downloading:  89%|âââââââââ | 442M/496M [01:26<00:10, 5.00MB/s]\u001b[A\n",
      "Downloading:  89%|âââââââââ | 443M/496M [01:26<00:10, 5.06MB/s]\u001b[A\n",
      "Downloading:  89%|âââââââââ | 443M/496M [01:26<00:10, 5.28MB/s]\u001b[A\n",
      "Downloading:  89%|âââââââââ | 444M/496M [01:27<00:09, 5.46MB/s]\u001b[A\n",
      "Downloading:  90%|âââââââââ | 444M/496M [01:27<00:10, 5.07MB/s]\u001b[A\n",
      "Downloading:  90%|âââââââââ | 445M/496M [01:27<00:10, 4.81MB/s]\u001b[A\n",
      "Downloading:  90%|âââââââââ | 445M/496M [01:27<00:11, 4.60MB/s]\u001b[A\n",
      "Downloading:  90%|âââââââââ | 446M/496M [01:27<00:10, 4.71MB/s]\u001b[A\n",
      "Downloading:  90%|âââââââââ | 446M/496M [01:27<00:10, 4.72MB/s]\u001b[A\n",
      "Downloading:  90%|âââââââââ | 447M/496M [01:27<00:09, 4.96MB/s]\u001b[A\n",
      "Downloading:  90%|âââââââââ | 448M/496M [01:27<00:10, 4.57MB/s]\u001b[A\n",
      "Downloading:  90%|âââââââââ | 448M/496M [01:27<00:09, 4.83MB/s]\u001b[A\n",
      "Downloading:  90%|âââââââââ | 449M/496M [01:28<00:09, 5.24MB/s]\u001b[A\n",
      "Downloading:  91%|âââââââââ | 449M/496M [01:28<00:08, 5.49MB/s]\u001b[A\n",
      "Downloading:  91%|âââââââââ | 450M/496M [01:28<00:08, 5.46MB/s]\u001b[A\n",
      "Downloading:  91%|âââââââââ | 451M/496M [01:28<00:08, 5.55MB/s]\u001b[A\n",
      "Downloading:  91%|âââââââââ | 451M/496M [01:28<00:08, 5.52MB/s]\u001b[A\n",
      "Downloading:  91%|âââââââââ | 452M/496M [01:28<00:08, 5.23MB/s]\u001b[A\n",
      "Downloading:  91%|âââââââââ | 452M/496M [01:28<00:08, 5.13MB/s]\u001b[A\n",
      "Downloading:  91%|âââââââââ | 453M/496M [01:28<00:08, 5.35MB/s]\u001b[A\n",
      "Downloading:  91%|ââââââââââ| 453M/496M [01:28<00:08, 5.27MB/s]\u001b[A\n",
      "Downloading:  91%|ââââââââââ| 454M/496M [01:28<00:07, 5.56MB/s]\u001b[A\n",
      "Downloading:  92%|ââââââââââ| 455M/496M [01:29<00:07, 5.31MB/s]\u001b[A\n",
      "Downloading:  92%|ââââââââââ| 455M/496M [01:29<00:07, 5.63MB/s]\u001b[A\n",
      "Downloading:  92%|ââââââââââ| 456M/496M [01:29<00:07, 5.40MB/s]\u001b[A\n",
      "Downloading:  92%|ââââââââââ| 456M/496M [01:29<00:07, 5.51MB/s]\u001b[A\n",
      "Downloading:  92%|ââââââââââ| 457M/496M [01:29<00:07, 5.56MB/s]\u001b[A\n",
      "Downloading:  92%|ââââââââââ| 458M/496M [01:29<00:06, 5.61MB/s]\u001b[A\n",
      "Downloading:  92%|ââââââââââ| 458M/496M [01:29<00:06, 5.75MB/s]\u001b[A\n",
      "Downloading:  92%|ââââââââââ| 459M/496M [01:29<00:06, 5.46MB/s]\u001b[A\n",
      "Downloading:  93%|ââââââââââ| 459M/496M [01:29<00:07, 4.96MB/s]\u001b[A\n",
      "Downloading:  93%|ââââââââââ| 460M/496M [01:30<00:07, 4.91MB/s]\u001b[A\n",
      "Downloading:  93%|ââââââââââ| 461M/496M [01:30<00:06, 5.29MB/s]\u001b[A\n",
      "Downloading:  93%|ââââââââââ| 461M/496M [01:30<00:06, 5.69MB/s]\u001b[A\n",
      "Downloading:  93%|ââââââââââ| 462M/496M [01:30<00:06, 5.67MB/s]\u001b[A\n",
      "Downloading:  93%|ââââââââââ| 462M/496M [01:30<00:05, 5.81MB/s]\u001b[A\n",
      "Downloading:  93%|ââââââââââ| 463M/496M [01:30<00:05, 5.72MB/s]\u001b[A\n",
      "Downloading:  93%|ââââââââââ| 464M/496M [01:30<00:05, 5.64MB/s]\u001b[A\n",
      "Downloading:  94%|ââââââââââ| 464M/496M [01:30<00:05, 5.65MB/s]\u001b[A\n",
      "Downloading:  94%|ââââââââââ| 465M/496M [01:30<00:05, 5.85MB/s]\u001b[A\n",
      "Downloading:  94%|ââââââââââ| 465M/496M [01:31<00:05, 5.82MB/s]\u001b[A\n",
      "Downloading:  94%|ââââââââââ| 466M/496M [01:31<00:04, 6.08MB/s]\u001b[A\n",
      "Downloading:  94%|ââââââââââ| 467M/496M [01:31<00:07, 3.70MB/s]\u001b[A\n",
      "Downloading:  94%|ââââââââââ| 467M/496M [01:31<00:07, 4.12MB/s]\u001b[A\n",
      "Downloading:  94%|ââââââââââ| 468M/496M [01:31<00:06, 4.54MB/s]\u001b[A\n",
      "Downloading:  94%|ââââââââââ| 469M/496M [01:31<00:05, 4.83MB/s]\u001b[A\n",
      "Downloading:  95%|ââââââââââ| 469M/496M [01:31<00:05, 5.28MB/s]\u001b[A\n",
      "Downloading:  95%|ââââââââââ| 470M/496M [01:31<00:04, 5.40MB/s]\u001b[A\n",
      "Downloading:  95%|ââââââââââ| 470M/496M [01:32<00:04, 5.32MB/s]\u001b[A\n",
      "Downloading:  95%|ââââââââââ| 471M/496M [01:32<00:04, 5.32MB/s]\u001b[A\n",
      "Downloading:  95%|ââââââââââ| 472M/496M [01:32<00:04, 5.84MB/s]\u001b[A\n",
      "Downloading:  95%|ââââââââââ| 472M/496M [01:32<00:04, 5.66MB/s]\u001b[A\n",
      "Downloading:  95%|ââââââââââ| 473M/496M [01:32<00:04, 5.66MB/s]\u001b[A\n",
      "Downloading:  95%|ââââââââââ| 474M/496M [01:32<00:03, 5.99MB/s]\u001b[A\n",
      "Downloading:  96%|ââââââââââ| 474M/496M [01:32<00:03, 5.85MB/s]\u001b[A\n",
      "Downloading:  96%|ââââââââââ| 475M/496M [01:32<00:03, 5.99MB/s]\u001b[A\n",
      "Downloading:  96%|ââââââââââ| 475M/496M [01:32<00:03, 5.81MB/s]\u001b[A\n",
      "Downloading:  96%|ââââââââââ| 476M/496M [01:33<00:03, 5.82MB/s]\u001b[A\n",
      "Downloading:  96%|ââââââââââ| 477M/496M [01:33<00:03, 5.77MB/s]\u001b[A\n",
      "Downloading:  96%|ââââââââââ| 477M/496M [01:33<00:03, 5.88MB/s]\u001b[A\n",
      "Downloading:  96%|ââââââââââ| 478M/496M [01:33<00:03, 6.07MB/s]\u001b[A\n",
      "Downloading:  96%|ââââââââââ| 479M/496M [01:33<00:03, 5.54MB/s]\u001b[A\n",
      "Downloading:  97%|ââââââââââ| 479M/496M [01:33<00:02, 5.83MB/s]\u001b[A\n",
      "Downloading:  97%|ââââââââââ| 480M/496M [01:33<00:02, 6.00MB/s]\u001b[A\n",
      "Downloading:  97%|ââââââââââ| 480M/496M [01:33<00:02, 5.93MB/s]\u001b[A\n",
      "Downloading:  97%|ââââââââââ| 481M/496M [01:33<00:02, 5.93MB/s]\u001b[A\n",
      "Downloading:  97%|ââââââââââ| 482M/496M [01:33<00:02, 6.08MB/s]\u001b[A\n",
      "Downloading:  97%|ââââââââââ| 482M/496M [01:34<00:02, 5.73MB/s]\u001b[A\n",
      "Downloading:  97%|ââââââââââ| 483M/496M [01:34<00:02, 5.73MB/s]\u001b[A\n",
      "Downloading:  97%|ââââââââââ| 484M/496M [01:34<00:02, 5.69MB/s]\u001b[A\n",
      "Downloading:  98%|ââââââââââ| 484M/496M [01:34<00:02, 5.46MB/s]\u001b[A\n",
      "Downloading:  98%|ââââââââââ| 485M/496M [01:34<00:02, 5.67MB/s]\u001b[A\n",
      "Downloading:  98%|ââââââââââ| 485M/496M [01:34<00:01, 5.62MB/s]\u001b[A\n",
      "Downloading:  98%|ââââââââââ| 486M/496M [01:34<00:01, 5.95MB/s]\u001b[A\n",
      "Downloading:  98%|ââââââââââ| 487M/496M [01:34<00:01, 6.12MB/s]\u001b[A\n",
      "Downloading:  98%|ââââââââââ| 487M/496M [01:34<00:01, 6.15MB/s]\u001b[A\n",
      "Downloading:  98%|ââââââââââ| 488M/496M [01:35<00:01, 5.93MB/s]\u001b[A\n",
      "Downloading:  98%|ââââââââââ| 489M/496M [01:35<00:01, 5.86MB/s]\u001b[A\n",
      "Downloading:  99%|ââââââââââ| 489M/496M [01:35<00:01, 5.88MB/s]\u001b[A\n",
      "Downloading:  99%|ââââââââââ| 490M/496M [01:35<00:01, 5.82MB/s]\u001b[A\n",
      "Downloading:  99%|ââââââââââ| 490M/496M [01:35<00:01, 5.83MB/s]\u001b[A\n",
      "Downloading:  99%|ââââââââââ| 491M/496M [01:35<00:00, 5.92MB/s]\u001b[A\n",
      "Downloading:  99%|ââââââââââ| 492M/496M [01:35<00:00, 5.88MB/s]\u001b[A\n",
      "Downloading:  99%|ââââââââââ| 492M/496M [01:35<00:00, 5.97MB/s]\u001b[A\n",
      "Downloading:  99%|ââââââââââ| 493M/496M [01:35<00:00, 6.10MB/s]\u001b[A\n",
      "Downloading:  99%|ââââââââââ| 493M/496M [01:35<00:00, 5.85MB/s]\u001b[A\n",
      "Downloading: 100%|ââââââââââ| 494M/496M [01:36<00:00, 5.67MB/s]\u001b[A\n",
      "Downloading: 100%|ââââââââââ| 495M/496M [01:36<00:00, 5.76MB/s]\u001b[A\n",
      "Downloading: 100%|ââââââââââ| 495M/496M [01:36<00:00, 5.50MB/s]\u001b[A\n",
      "Downloading: 100%|ââââââââââ| 496M/496M [01:36<00:00, 5.15MB/s]\n",
      "12/01/2020 16:42:37 - INFO - filelock -   Lock 140079209962704 released on /home/elena/.cache/torch/transformers/8c0c8b6371111ac5fbc176aefcf9dbe129db7be654c569b8375dd3712fc4dc67.a851909c96149f062acca04d647da88d0dcd3a52cd5a8c7169e89fc6e5971c7b.lock\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "12/01/2020 16:42:39 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "12/01/2020 16:42:45 - INFO - filelock -   Lock 140079221176016 acquired on /home/elena/.cache/torch/transformers/1e3af82648d7190d959a9d76d727ef629b1ca51b3da6ad04039122453cb56307.6a4061e8fc00057d21d80413635a86fdcf55b6e7594ad9e25257d2f99a02f4be.lock\n",
      "\n",
      "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading:   6%|â         | 56.3k/899k [00:00<00:02, 282kB/s]\u001b[A\n",
      "Downloading:  12%|ââ        | 109k/899k [00:00<00:02, 323kB/s] \u001b[A\n",
      "Downloading:  28%|âââ       | 248k/899k [00:00<00:01, 416kB/s]\u001b[A\n",
      "Downloading: 100%|ââââââââââ| 899k/899k [00:00<00:00, 1.52MB/s]\n",
      "12/01/2020 16:42:46 - INFO - filelock -   Lock 140079221176016 released on /home/elena/.cache/torch/transformers/1e3af82648d7190d959a9d76d727ef629b1ca51b3da6ad04039122453cb56307.6a4061e8fc00057d21d80413635a86fdcf55b6e7594ad9e25257d2f99a02f4be.lock\n",
      "12/01/2020 16:42:46 - INFO - filelock -   Lock 140079221176160 acquired on /home/elena/.cache/torch/transformers/b901c69e8e7da4a24c635ad81d016d274f174261f4f5c144e43f4b00e242c3b0.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
      "\n",
      "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading:   2%|â         | 9.22k/456k [00:00<00:08, 54.5kB/s]\u001b[A\n",
      "Downloading:  10%|â         | 44.0k/456k [00:00<00:05, 72.7kB/s]\u001b[A\n",
      "Downloading:  25%|âââ       | 114k/456k [00:00<00:03, 99.2kB/s] \u001b[A\n",
      "Downloading: 100%|ââââââââââ| 456k/456k [00:00<00:00, 884kB/s]\n",
      "12/01/2020 16:42:47 - INFO - filelock -   Lock 140079221176160 released on /home/elena/.cache/torch/transformers/b901c69e8e7da4a24c635ad81d016d274f174261f4f5c144e43f4b00e242c3b0.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
      "12/01/2020 16:42:49 - INFO - filelock -   Lock 140079221722992 acquired on /home/elena/.cache/torch/transformers/2d9b03b59a8af464bf4238025a3cf0e5a340b9d0ba77400011e23c130b452510.6e217123a3ada61145de1f20b1443a1ec9aac93492a4bd1ce6a695935f0fd97a.lock\n",
      "\n",
      "Downloading: 100%|ââââââââââ| 772/772 [00:00<00:00, 164kB/s]\n",
      "12/01/2020 16:42:49 - INFO - filelock -   Lock 140079221722992 released on /home/elena/.cache/torch/transformers/2d9b03b59a8af464bf4238025a3cf0e5a340b9d0ba77400011e23c130b452510.6e217123a3ada61145de1f20b1443a1ec9aac93492a4bd1ce6a695935f0fd97a.lock\n",
      "12/01/2020 16:42:50 - INFO - filelock -   Lock 140079221175104 acquired on /home/elena/.cache/torch/transformers/507984f2e28c7dfed5db9a20acd68beb969c7f2833abc9e582e967fa0291f3dc.ec06af3e1b426682955dab3bd553eaf178b6eafac9079fc133925e0e2654213e.lock\n",
      "\n",
      "Downloading: 100%|ââââââââââ| 79.0/79.0 [00:00<00:00, 19.1kB/s]\n",
      "12/01/2020 16:42:50 - INFO - filelock -   Lock 140079221175104 released on /home/elena/.cache/torch/transformers/507984f2e28c7dfed5db9a20acd68beb969c7f2833abc9e582e967fa0291f3dc.ec06af3e1b426682955dab3bd553eaf178b6eafac9079fc133925e0e2654213e.lock\n",
      "12/01/2020 16:42:51 - INFO - farm.utils -   device: cpu n_gpu: 0, distributed training: False, automatic mixed precision training: None\n",
      "12/01/2020 16:42:51 - INFO - farm.infer -   Got ya 3 parallel workers to do inference ...\n",
      "12/01/2020 16:42:51 - INFO - farm.infer -    0    0    0 \n",
      "12/01/2020 16:42:51 - INFO - farm.infer -   /w\\  /w\\  /w\\\n",
      "12/01/2020 16:42:51 - INFO - farm.infer -   /'\\  / \\  /'\\\n",
      "12/01/2020 16:42:51 - INFO - farm.infer -       \n"
     ]
    }
   ],
   "source": [
    "from haystack.reader.farm import FARMReader\n",
    "farm_reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Finder\n",
    "\n",
    "finder = Finder(farm_reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:00<00:00,  3.59 Batches/s]\n",
      "12/01/2020 17:01:37 - INFO - haystack.finder -   Got 0 candidates from retriever\n",
      "12/01/2020 17:01:37 - INFO - haystack.finder -   Retriever did not return any documents. Skipping reader ...\n"
     ]
    }
   ],
   "source": [
    "prediction = finder.get_answers(question=\"layer\", top_k_retriever=1, top_k_reader=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.utils import print_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print_answers(prediction, details=\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/01/2020 17:04:40 - INFO - elasticsearch -   PUT http://localhost:9200/document [status:200 request:0.434s]\n",
      "12/01/2020 17:04:40 - INFO - elasticsearch -   PUT http://localhost:9200/label [status:200 request:0.196s]\n"
     ]
    }
   ],
   "source": [
    "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
    "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/01/2020 17:05:14 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:0.863s]\n"
     ]
    }
   ],
   "source": [
    "document_store.write_documents(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.retriever.sparse import ElasticsearchRetriever\n",
    "retriever = ElasticsearchRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = Finder(farm_reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/01/2020 17:06:10 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.205s]\n",
      "12/01/2020 17:06:10 - INFO - haystack.finder -   Got 10 candidates from retriever\n",
      "12/01/2020 17:06:10 - INFO - haystack.finder -   Reader is looking for detailed answer in 16574 chars ...\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:01<00:00,  1.32s/ Batches]\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:00<00:00,  1.14 Batches/s]\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:00<00:00,  1.12 Batches/s]\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:00<00:00,  1.11 Batches/s]\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:01<00:00,  1.07s/ Batches]\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:00<00:00,  1.19 Batches/s]\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:02<00:00,  2.28s/ Batches]\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:01<00:00,  1.03s/ Batches]\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:00<00:00,  1.05 Batches/s]\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:01<00:00,  1.99s/ Batches]\n"
     ]
    }
   ],
   "source": [
    "prediction = finder.get_answers(question=\"What is RNN?\", top_k_retriever=10, top_k_reader=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[   {   'answer': 'Recurrent Neural Networks',\n        'context': 'rthermore, we will learn\\n'\n                   'how sequential modeling is related to Recurrent Neural '\n                   'Networks (RNN).We will\\n'\n                   'learn about the vanishing gradient problem in d',\n        'score': 16.642990112304688},\n    {   'answer': 'Recurrent Neural Networks',\n        'context': ' chapter, you will\\n'\n                   'be able to build sequential models, explain Recurrent '\n                   'Neural Networks (RNNs),\\n'\n                   'describe the vanishing gradient problem, and implemen',\n        'score': 15.48896312713623},\n    {   'answer': 'Recurrent Neural Networks',\n        'context': ' however, here, the data and information also flow in '\n                   'cycles:\\n'\n                   '\\n'\n                   'Recurrent Neural Networks (RNNs) | 285\\n'\n                   '\\n'\n                   'Figure 9.6: An RNN\\n'\n                   '\\n'\n                   'Here, the defining property',\n        'score': 13.990405082702637},\n    {   'answer': 'Recurrent Neural Networks',\n        'context': 'ook at one such example in the next section when we study '\n                   'RNNs.Recurrent Neural Networks (RNNs)\\n'\n                   'RNNs are a class of neural networks that are built on ',\n        'score': 12.01612663269043},\n    {   'answer': 'we can have multiple outputs over multiple instances of '\n                  'time',\n        'context': 's, so we need to use RNNs instead.In an RNN, we can have '\n                   'multiple outputs over multiple instances of time.The '\n                   'following\\n'\n                   'diagram is a pictorial represe',\n        'score': 11.332517623901367}]\n"
     ]
    }
   ],
   "source": [
    "print_answers(prediction, details=\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/01/2020 17:07:35 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.031s]\n",
      "12/01/2020 17:07:35 - INFO - haystack.finder -   Got 10 candidates from retriever\n",
      "12/01/2020 17:07:35 - INFO - haystack.finder -   Reader is looking for detailed answer in 15810 chars ...\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:01<00:00,  1.33s/ Batches]\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:00<00:00,  1.09 Batches/s]\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:00<00:00,  1.08 Batches/s]\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:01<00:00,  1.33s/ Batches]\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:00<00:00,  1.16 Batches/s]\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:00<00:00,  1.06 Batches/s]\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:00<00:00,  1.02 Batches/s]\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:00<00:00,  1.04 Batches/s]\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:00<00:00,  1.15 Batches/s]\n",
      "Inferencing Samples: 100%|ââââââââââ| 1/1 [00:00<00:00,  1.19 Batches/s][   {   'answer': 'user-defined layer',\n",
      "        'context': 'tially, what we will do is\\n'\n",
      "                   'replace the last layer of VGG16 with a user-defined '\n",
      "                   'layer.Before we begin, ensure you have downloaded the '\n",
      "                   'image datasets fr',\n",
      "        'score': 10.711793899536133},\n",
      "    {   'answer': 'single hidden layer',\n",
      "        'context': 'will stick\\n'\n",
      "                   'to the simplest case, which is a neural network with a '\n",
      "                   'single hidden layer.You will learn\\n'\n",
      "                   'how to define a model in Keras, choose the hyperp',\n",
      "        'score': 7.02977180480957},\n",
      "    {   'answer': 'first\\nhidden layer',\n",
      "        'context': 'However, add a dropout regularization of rate=0.2 to the '\n",
      "                   'first\\n'\n",
      "                   'hidden layer and rate=0.1 to the remaining layers of your '\n",
      "                   'model and repeat the\\n'\n",
      "                   'compilat',\n",
      "        'score': 6.401031017303467},\n",
      "    {   'answer': 'hidden layers',\n",
      "        'context': 'ed in prior\\n'\n",
      "                   'chapters), data passes sequentially through the network '\n",
      "                   'from the input layer, and\\n'\n",
      "                   'through the hidden layers (if any), to the output layer.',\n",
      "        'score': 4.30322265625},\n",
      "    {   'answer': 'hidden layer',\n",
      "        'context': ' represent the output layer, the middle dots (in blue) '\n",
      "                   'represent the\\n'\n",
      "                   'hidden layer, and the bottom dots (in green) represent the '\n",
      "                   'input layer:\\n'\n",
      "                   '\\n'\n",
      "                   'Figure: ',\n",
      "        'score': 3.142728090286255}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_answers(finder.get_answers(question=\"What is a layer?\", top_k_retriever=10, top_k_reader=5), details=\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}