{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_index = \"evaluation_docs\"\n",
    "label_index = \"evaluation_labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"../data/nq/nq_dev_subset_v2.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/03/2020 12:43:53 - INFO - faiss -   Loading faiss with AVX2 support.\n",
      "12/03/2020 12:43:53 - INFO - faiss -   Loading faiss.\n"
     ]
    }
   ],
   "source": [
    "from haystack.preprocessor.utils import eval_data_from_file\n",
    "docs, labels = eval_data_from_file(filename=filename) # return: (List of Documents, List of Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(list, 50, haystack.schema.Document)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "type(docs), len(docs), type(docs[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(list, 96, haystack.schema.Label)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "type(labels), len(labels), type(labels[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_store.faiss import FAISSDocumentStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
    "document_ela=ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\",\n",
    "                                            create_index=False, embedding_field=\"emb\",\n",
    "                                            embedding_dim=768, excluded_meta_data=[\"emb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/03/2020 12:44:03 - INFO - elasticsearch -   HEAD http://localhost:9200/evaluation_docs [status:200 request:0.011s]\n",
      "12/03/2020 12:44:03 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:0.451s]\n"
     ]
    }
   ],
   "source": [
    "document_ela.write_documents(docs, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/03/2020 12:44:09 - INFO - elasticsearch -   HEAD http://localhost:9200/evaluation_labels [status:200 request:0.003s]\n",
      "12/03/2020 12:44:10 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:0.938s]\n"
     ]
    }
   ],
   "source": [
    "document_ela.write_labels(labels, index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.retriever.sparse import ElasticsearchRetriever\n",
    "retriever = ElasticsearchRetriever(document_store=document_ela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_labels/_search?scroll=5m&size=1000 [status:200 request:0.005s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.003s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   DELETE http://localhost:9200/_search/scroll [status:200 request:0.003s]\n",
      "12/03/2020 12:46:10 - INFO - haystack.retriever.base -   Performing eval queries...\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.019s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.020s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.026s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.042s]\n",
      "  7%|▋         | 4/54 [00:00<00:01, 31.55it/s]12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.016s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.041s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.015s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.024s]\n",
      " 15%|█▍        | 8/54 [00:00<00:01, 31.85it/s]12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.028s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.024s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.029s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.023s]\n",
      " 22%|██▏       | 12/54 [00:00<00:01, 31.87it/s]12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.030s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.011s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.033s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.023s]\n",
      " 30%|██▉       | 16/54 [00:00<00:01, 32.65it/s]12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.031s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.026s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.022s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.028s]\n",
      " 37%|███▋      | 20/54 [00:00<00:01, 32.56it/s]12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.028s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.020s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.014s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.025s]\n",
      " 44%|████▍     | 24/54 [00:00<00:00, 34.11it/s]12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.030s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.019s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.026s]\n",
      "12/03/2020 12:46:10 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.012s]\n",
      " 52%|█████▏    | 28/54 [00:00<00:00, 35.37it/s]12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.026s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.030s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.026s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.028s]\n",
      " 59%|█████▉    | 32/54 [00:00<00:00, 33.99it/s]12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.022s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.024s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.034s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.030s]\n",
      " 67%|██████▋   | 36/54 [00:01<00:00, 32.91it/s]12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.029s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.020s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.024s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.015s]\n",
      " 74%|███████▍  | 40/54 [00:01<00:00, 34.18it/s]12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.018s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.016s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.022s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.015s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.012s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.022s]\n",
      " 85%|████████▌ | 46/54 [00:01<00:00, 37.54it/s]12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.032s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.022s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.028s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.014s]\n",
      " 93%|█████████▎| 50/54 [00:01<00:00, 35.96it/s]12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.020s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.030s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.042s]\n",
      "12/03/2020 12:46:11 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.024s]\n",
      "100%|██████████| 54/54 [00:01<00:00, 34.32it/s]\n",
      "12/03/2020 12:46:11 - INFO - haystack.retriever.base -   For 54 out of 54 questions (100.00%), the answer was in the top-20 candidate passages selected by the retriever.\n",
      "Retriever Recall: 1.0\n",
      "Retriever Mean Avg Precision: 0.9312469937469937\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own\n",
    "retriever_eval_results = retriever.eval(top_k=20, label_index=label_index, doc_index=doc_index)\n",
    "## Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "## among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "## Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = FAISSDocumentStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.write_documents(docs, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.write_labels(labels, index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/03/2020 12:49:44 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "12/03/2020 12:49:51 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n"
     ]
    }
   ],
   "source": [
    "from haystack.retriever.dense import DensePassageRetriever\n",
    "dpr = DensePassageRetriever(document_store=document_store,\n",
    "                                  query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "                                  passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "                                  max_seq_len_query=64,\n",
    "                                  max_seq_len_passage=256,\n",
    "                                  batch_size=16,\n",
    "                                  use_gpu=False,\n",
    "                                  embed_title=True,\n",
    "                                  use_fast_tokenizers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/03/2020 12:50:31 - INFO - haystack.retriever.base -   Performing eval queries...\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.11 Batches/s]\n",
      "  2%|▏         | 1/54 [00:00<00:11,  4.54it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.94 Batches/s]\n",
      "  4%|▎         | 2/54 [00:00<00:10,  4.82it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.16 Batches/s]\n",
      "  6%|▌         | 3/54 [00:00<00:10,  4.82it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.42 Batches/s]\n",
      "  7%|▋         | 4/54 [00:00<00:09,  5.08it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.05 Batches/s]\n",
      "  9%|▉         | 5/54 [00:00<00:09,  5.00it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.14 Batches/s]\n",
      " 11%|█         | 6/54 [00:01<00:09,  4.96it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.97 Batches/s]\n",
      " 13%|█▎        | 7/54 [00:01<00:09,  5.12it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.43 Batches/s]\n",
      " 15%|█▍        | 8/54 [00:01<00:09,  5.09it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.93 Batches/s]\n",
      " 17%|█▋        | 9/54 [00:01<00:09,  4.93it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.02 Batches/s]\n",
      " 19%|█▊        | 10/54 [00:01<00:09,  4.89it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.15 Batches/s]\n",
      " 20%|██        | 11/54 [00:02<00:08,  4.86it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.36 Batches/s]\n",
      " 22%|██▏       | 12/54 [00:02<00:08,  5.08it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.11 Batches/s]\n",
      " 24%|██▍       | 13/54 [00:02<00:08,  4.99it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.27 Batches/s]\n",
      " 26%|██▌       | 14/54 [00:02<00:07,  5.23it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.99 Batches/s]\n",
      " 28%|██▊       | 15/54 [00:02<00:07,  5.26it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.02 Batches/s]\n",
      " 30%|██▉       | 16/54 [00:03<00:07,  5.35it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.06 Batches/s]\n",
      " 31%|███▏      | 17/54 [00:03<00:06,  5.44it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.05 Batches/s]\n",
      " 33%|███▎      | 18/54 [00:03<00:06,  5.45it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.36 Batches/s]\n",
      " 35%|███▌      | 19/54 [00:03<00:06,  5.56it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.92 Batches/s]\n",
      " 37%|███▋      | 20/54 [00:03<00:06,  5.56it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.42 Batches/s]\n",
      " 39%|███▉      | 21/54 [00:04<00:06,  5.02it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.21 Batches/s]\n",
      " 41%|████      | 22/54 [00:04<00:06,  5.22it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.70 Batches/s]\n",
      " 43%|████▎     | 23/54 [00:04<00:06,  4.93it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.25 Batches/s]\n",
      " 44%|████▍     | 24/54 [00:04<00:05,  5.17it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.13 Batches/s]\n",
      " 46%|████▋     | 25/54 [00:04<00:05,  5.34it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.18 Batches/s]\n",
      " 48%|████▊     | 26/54 [00:05<00:05,  5.40it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.47 Batches/s]\n",
      " 50%|█████     | 27/54 [00:05<00:05,  4.90it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.27 Batches/s]\n",
      " 52%|█████▏    | 28/54 [00:05<00:05,  5.13it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.24 Batches/s]\n",
      " 54%|█████▎    | 29/54 [00:05<00:04,  5.26it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.13 Batches/s]\n",
      " 56%|█████▌    | 30/54 [00:05<00:04,  5.12it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.20 Batches/s]\n",
      " 57%|█████▋    | 31/54 [00:06<00:04,  5.06it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.23 Batches/s]\n",
      " 59%|█████▉    | 32/54 [00:06<00:04,  5.26it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.01 Batches/s]\n",
      " 61%|██████    | 33/54 [00:06<00:03,  5.34it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.08 Batches/s]\n",
      " 63%|██████▎   | 34/54 [00:06<00:03,  5.42it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.06 Batches/s]\n",
      " 65%|██████▍   | 35/54 [00:06<00:03,  5.46it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.24 Batches/s]\n",
      " 67%|██████▋   | 36/54 [00:06<00:03,  5.49it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.22 Batches/s]\n",
      " 69%|██████▊   | 37/54 [00:07<00:03,  5.29it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.88 Batches/s]\n",
      " 70%|███████   | 38/54 [00:07<00:03,  5.06it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.48 Batches/s]\n",
      " 72%|███████▏  | 39/54 [00:07<00:03,  4.72it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.16 Batches/s]\n",
      " 74%|███████▍  | 40/54 [00:07<00:02,  4.74it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.92 Batches/s]\n",
      " 76%|███████▌  | 41/54 [00:07<00:02,  4.96it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.03 Batches/s]\n",
      " 78%|███████▊  | 42/54 [00:08<00:02,  4.87it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.98 Batches/s]\n",
      " 80%|███████▉  | 43/54 [00:08<00:02,  4.84it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.02 Batches/s]\n",
      " 81%|████████▏ | 44/54 [00:08<00:02,  4.83it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.64 Batches/s]\n",
      " 83%|████████▎ | 45/54 [00:08<00:01,  4.90it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.88 Batches/s]\n",
      " 85%|████████▌ | 46/54 [00:08<00:01,  5.04it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.96 Batches/s]\n",
      " 87%|████████▋ | 47/54 [00:09<00:01,  5.20it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.04 Batches/s]\n",
      " 89%|████████▉ | 48/54 [00:09<00:01,  5.04it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.11 Batches/s]\n",
      " 91%|█████████ | 49/54 [00:09<00:01,  4.92it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.95 Batches/s]\n",
      " 93%|█████████▎| 50/54 [00:09<00:00,  4.86it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.91 Batches/s]\n",
      " 94%|█████████▍| 51/54 [00:10<00:00,  4.78it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.92 Batches/s]\n",
      " 96%|█████████▋| 52/54 [00:10<00:00,  4.35it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.59 Batches/s]\n",
      " 98%|█████████▊| 53/54 [00:10<00:00,  4.59it/s]\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]\u001b[A\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.93 Batches/s]\n",
      "100%|██████████| 54/54 [00:10<00:00,  5.04it/s]\n",
      "12/03/2020 12:50:41 - INFO - haystack.retriever.base -   For 0 out of 54 questions (0.00%), the answer was in the top-20 candidate passages selected by the retriever.\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own\n",
    "dpr_eval_results = dpr.eval(top_k=20, label_index=label_index, doc_index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Retriever Recall: 0.0\nRetriever Mean Avg Precision: 0.0\n"
     ]
    }
   ],
   "source": [
    "## Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "## among the correct documents\n",
    "print(\"Retriever Recall:\", dpr_eval_results[\"recall\"])\n",
    "## Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", dpr_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/03/2020 12:54:46 - WARNING - haystack.document_store.faiss -   Calling DocumentStore.update_embeddings() on an empty index\n"
     ]
    }
   ],
   "source": [
    "document_store.update_embeddings(dpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}