{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit ('.venv')",
   "metadata": {
    "interpreter": {
     "hash": "5bdca235408bc63495fd8719d073449338626e85bb6ce08bacdb45b63101d775"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 13:45:54 - INFO - faiss -   Loading faiss with AVX2 support.\n",
      "12/02/2020 13:45:54 - INFO - faiss -   Loading faiss.\n",
      "12/02/2020 13:45:55 - INFO - farm.utils -   device: cpu n_gpu: 0, distributed training: False, automatic mixed precision training: None\n",
      "12/02/2020 13:45:55 - INFO - farm.infer -   Could not find `deepset/roberta-base-squad2` locally. Try to download from model hub ...\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "12/02/2020 13:45:59 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "12/02/2020 13:46:08 - INFO - farm.utils -   device: cpu n_gpu: 0, distributed training: False, automatic mixed precision training: None\n",
      "12/02/2020 13:46:09 - INFO - farm.infer -   Got ya 3 parallel workers to do inference ...\n",
      "12/02/2020 13:46:09 - INFO - farm.infer -    0    0    0 \n",
      "12/02/2020 13:46:09 - INFO - farm.infer -   /w\\  /w\\  /w\\\n",
      "12/02/2020 13:46:09 - INFO - farm.infer -   /'\\  / \\  /'\\\n",
      "12/02/2020 13:46:09 - INFO - farm.infer -       \n"
     ]
    }
   ],
   "source": [
    "from haystack.reader.farm import FARMReader\n",
    "farm_reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 13:46:16 - INFO - elasticsearch -   HEAD http://localhost:9200/document [status:200 request:0.004s]\n",
      "12/02/2020 13:46:16 - INFO - elasticsearch -   GET http://localhost:9200/document [status:200 request:0.002s]\n",
      "12/02/2020 13:46:16 - INFO - elasticsearch -   PUT http://localhost:9200/document/_mapping [status:200 request:0.017s]\n",
      "12/02/2020 13:46:16 - INFO - elasticsearch -   HEAD http://localhost:9200/label [status:200 request:0.002s]\n"
     ]
    }
   ],
   "source": [
    "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
    "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.retriever.sparse import ElasticsearchRetriever\n",
    "retriever = ElasticsearchRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 13:46:43 - INFO - haystack.preprocessor.utils -   Converting /home/elena/Downloads/data/9781839217579-THE_DEEP_LEARNING_WITH_KERAS_WORKSHOP_SECOND_EDITION.pdf\n"
     ]
    }
   ],
   "source": [
    "from haystack.preprocessor.utils import convert_files_to_dicts\n",
    "dicts=convert_files_to_dicts(\"./book/\", split_paragraphs=True) # no cleaning function applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 13:47:08 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:0.124s]\n",
      "12/02/2020 13:47:09 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.020s]\n",
      "12/02/2020 13:47:10 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.079s]\n"
     ]
    }
   ],
   "source": [
    "document_store.write_documents(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ElasticsearchRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.utils import print_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = Finder(farm_reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 13:48:04 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.011s]\n",
      "12/02/2020 13:48:04 - INFO - haystack.finder -   Got 10 candidates from retriever\n",
      "12/02/2020 13:48:04 - INFO - haystack.finder -   Reader is looking for detailed answer in 8846 chars ...\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.17 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.11 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.90 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.87 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.11 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.75 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "prediction = finder.get_answers(question=\"What is RNN?\", top_k_retriever=10, top_k_reader=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[   {   'answer': 'Recurrent Neural Networks',\n        'context': 'rthermore, we will learn\\n'\n                   'how sequential modeling is related to Recurrent Neural '\n                   'Networks (RNN). We will\\n'\n                   'learn about the vanishing gradient problem in ',\n        'score': 15.890447616577148},\n    {   'answer': 'Recurrent Neural Networks',\n        'context': 'rthermore, we will learn\\n'\n                   'how sequential modeling is related to Recurrent Neural '\n                   'Networks (RNN). We will\\n'\n                   'learn about the vanishing gradient problem in ',\n        'score': 15.890447616577148},\n    {   'answer': 'Recurrent Neural Networks',\n        'context': 'Recurrent Neural Networks (RNNs)\\n'\n                   'RNNs are a class of neural networks that are built on the '\n                   'concept of sequential\\n'\n                   'memory. Unlike traditional neural net',\n        'score': 11.025992393493652}]\n"
     ]
    }
   ],
   "source": [
    "print_answers(prediction, details=\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 13:48:20 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.014s]\n",
      "12/02/2020 13:48:20 - INFO - haystack.finder -   Got 10 candidates from retriever\n",
      "12/02/2020 13:48:20 - INFO - haystack.finder -   Reader is looking for detailed answer in 9749 chars ...\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.10s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.51 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.16 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.23 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.16 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.00 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.86 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.15 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.17 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.14 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "prediction = finder.get_answers(question=\"What is a layer?\", top_k_retriever=10, top_k_reader=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[   {   'answer': 'one hidden layer',\n        'context': 'ogistic\\n'\n                   'regression involves a very simple neural network with only '\n                   'one hidden layer and only\\n'\n                   'one node in its hidden layer.\\n'\n                   'An overview of the logistic',\n        'score': 6.236577987670898},\n    {   'answer': 'one hidden layer',\n        'context': 'ogistic\\n'\n                   'regression involves a very simple neural network with only '\n                   'one hidden layer and only\\n'\n                   'one node in its hidden layer.\\n'\n                   'An overview of the logistic',\n        'score': 6.236577987670898},\n    {   'answer': 'pooling layer',\n        'context': 'e feature map derived from the convolution layer is passed '\n                   'through a pooling layer\\n'\n                   'to further reduce the image, all while preserving the most '\n                   'relevant',\n        'score': 5.443607330322266}]\n"
     ]
    }
   ],
   "source": [
    "print_answers(prediction, details=\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 13:48:35 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.042s]\n",
      "12/02/2020 13:48:35 - INFO - haystack.finder -   Got 10 candidates from retriever\n",
      "12/02/2020 13:48:35 - INFO - haystack.finder -   Reader is looking for detailed answer in 10276 chars ...\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.78 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.19 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.39 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.47 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.46 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.56s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.91 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.09 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.02s/ Batches]\n"
     ]
    }
   ],
   "source": [
    "prediction = finder.get_answers(question=\"What is deep learning?\", top_k_retriever=10, top_k_reader=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[   {   'answer': 'lowest bias and the lowest variance',\n        'context': 'ta analysis, the most desirable model is the one\\n'\n                   'with the lowest bias and the lowest variance.As shown in '\n                   'the preceding plot, the\\n'\n                   'region labeled in th',\n        'score': 2.6615817546844482},\n    {   'answer': 'standard gradient descent algorithm',\n        'context': '| Deep Learning with Keras\\n'\n                   'What we discussed here was the standard gradient descent '\n                   'algorithm, which computes\\n'\n                   'the loss and the derivatives using the e',\n        'score': 1.9924461841583252},\n    {   'answer': 'standard gradient descent algorithm',\n        'context': '| Deep Learning with Keras\\n'\n                   'What we discussed here was the standard gradient descent '\n                   'algorithm, which computes\\n'\n                   'the loss and the derivatives using the e',\n        'score': 1.9924461841583252}]\n"
     ]
    }
   ],
   "source": [
    "print_answers(prediction, details=\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 13:48:52 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.013s]\n",
      "12/02/2020 13:48:52 - INFO - haystack.finder -   Got 10 candidates from retriever\n",
      "12/02/2020 13:48:52 - INFO - haystack.finder -   Reader is looking for detailed answer in 9875 chars ...\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.01 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.29 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.14 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.18 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.14 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.16 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.14 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.12 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.02 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.37 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "prediction = finder.get_answers(question=\"What is logistic regression?\", top_k_retriever=10, top_k_reader=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[   {   'answer': 'classification tasks',\n        'context': 'at other algorithms can\\n'\n                   'perform, such as logistic regression for classification '\n                   'tasks, linear\\n'\n                   'regression for regression problems, and k-means for clus',\n        'score': 13.997730255126953},\n    {   'answer': 'classification tasks',\n        'context': 'at other algorithms can\\n'\n                   'perform, such as logistic regression for classification '\n                   'tasks, linear\\n'\n                   'regression for regression problems, and k-means for clus',\n        'score': 13.997730255126953},\n    {   'answer': 'classification tasks',\n        'context': 'at other algorithms can\\n'\n                   'perform, such as logistic regression for classification '\n                   'tasks, linear\\n'\n                   'regression for regression problems, and k-means for clus',\n        'score': 13.873347282409668}]\n"
     ]
    }
   ],
   "source": [
    "print_answers(prediction, details=\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 13:55:18 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.016s]\n",
      "12/02/2020 13:55:18 - INFO - haystack.finder -   Got 10 candidates from retriever\n",
      "12/02/2020 13:55:18 - INFO - haystack.finder -   Reader is looking for detailed answer in 5751 chars ...\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.11s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.15 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.01 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.05 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.31s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.04 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.19 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.22 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.20 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.28 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "prediction = finder.get_answers(question=\"What is early stopping?\", top_k_retriever=10, top_k_reader=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[   {   'answer': 'patience=0',\n        'context': 'Figure 5.10: Plot of training error and validation error '\n                   'while training the model\\n'\n                   'with early stopping (patience=0)',\n        'score': 11.892475128173828},\n    {   'answer': 'patience=0',\n        'context': 'Figure 5.10: Plot of training error and validation error '\n                   'while training the model\\n'\n                   'with early stopping (patience=0)',\n        'score': 11.892475128173828},\n    {   'answer': 'forcing the Keras model to stop the training when a desired '\n                  'metric—for example,\\n'\n                  'the test error rate—is not improving anymore',\n        'context': '. This\\n'\n                   'means forcing the Keras model to stop the training when a '\n                   'desired metric—for example,\\n'\n                   'the test error rate—is not improving anymore. In order to',\n        'score': 10.376293182373047}]\n"
     ]
    }
   ],
   "source": [
    "print_answers(prediction, details=\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 13:55:42 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.015s]\n",
      "12/02/2020 13:55:42 - INFO - haystack.finder -   Got 10 candidates from retriever\n",
      "12/02/2020 13:55:42 - INFO - haystack.finder -   Reader is looking for detailed answer in 9829 chars ...\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.60s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.14 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.99 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.32s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.24s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.24 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.23 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.27s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.22 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "prediction = finder.get_answers(question=\"What is early stopping used for?\", top_k_retriever=10, top_k_reader=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[   {   'answer': 'monitor the desired metric',\n        'context': 'mber of epochs to give the early stopping method some\\n'\n                   'time to monitor the desired metric for longer before '\n                   'stopping the training process:\\n'\n                   'es_callback ',\n        'score': 10.788822174072266},\n    {   'answer': 'monitor the desired metric',\n        'context': 'mber of epochs to give the early stopping method some\\n'\n                   'time to monitor the desired metric for longer before '\n                   'stopping the training process:\\n'\n                   'es_callback ',\n        'score': 10.788822174072266},\n    {   'answer': 'forcing the Keras model to stop the training when a desired '\n                  'metric—for example,\\n'\n                  'the test error rate—is not improving anymore',\n        'context': '. This\\n'\n                   'means forcing the Keras model to stop the training when a '\n                   'desired metric—for example,\\n'\n                   'the test error rate—is not improving anymore. In order to',\n        'score': 8.451149940490723}]\n"
     ]
    }
   ],
   "source": [
    "print_answers(prediction, details=\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 13:56:31 - INFO - haystack.preprocessor.utils -   Found data stored in `../data/nq`. Delete this first if you really want to fetch new data.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# EVALUATING\n",
    "\n",
    "\n",
    "\n",
    "from haystack.preprocessor.utils import fetch_archive_from_http\n",
    "\n",
    "# Download evaluation data, which is a subset of Natural Questions development set containing 50 documents\n",
    "doc_dir = \"../data/nq\"\n",
    "s3_url = \"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/nq_dev_subset_v2.json.zip\"\n",
    "fetch_archive_from_http(url=s3_url, output_dir=doc_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure these indices do not collide with existing ones, the indices will be wiped clean before data is inserted\n",
    "doc_index = \"evaluation_docs\"\n",
    "label_index = \"evaluation_labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 13:56:54 - INFO - elasticsearch -   POST http://localhost:9200/document/_delete_by_query [status:200 request:0.349s]\n"
     ]
    }
   ],
   "source": [
    "document_store.delete_all_documents(index='document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\",\n",
    "                                            create_index=False, embedding_field=\"emb\",\n",
    "                                            embedding_dim=768, excluded_meta_data=[\"emb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 13:57:27 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_delete_by_query [status:404 request:0.005s]\n",
      "12/02/2020 13:57:28 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_labels/_delete_by_query [status:404 request:0.008s]\n",
      "12/02/2020 13:57:29 - INFO - elasticsearch -   PUT http://localhost:9200/evaluation_docs [status:200 request:0.254s]\n",
      "12/02/2020 13:57:31 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.161s]\n",
      "12/02/2020 13:57:31 - INFO - elasticsearch -   PUT http://localhost:9200/evaluation_labels [status:200 request:0.385s]\n",
      "12/02/2020 13:57:32 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:0.658s]\n"
     ]
    }
   ],
   "source": [
    "# Add evaluation data to Elasticsearch Document Store\n",
    "# We first delete the custom tutorial indices to not have duplicate elements\n",
    "document_store.delete_all_documents(index=doc_index)\n",
    "document_store.delete_all_documents(index=label_index)\n",
    "document_store.add_eval_data(filename=\"../data/nq/nq_dev_subset_v2.json\", doc_index=doc_index, label_index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ElasticsearchRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = Finder(farm_reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 13:58:53 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_labels/_search?scroll=5m&size=1000 [status:200 request:0.023s]\n",
      "12/02/2020 13:58:53 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.005s]\n",
      "12/02/2020 13:58:53 - INFO - elasticsearch -   DELETE http://localhost:9200/_search/scroll [status:200 request:0.004s]\n",
      "12/02/2020 13:58:53 - INFO - haystack.retriever.base -   Performing eval queries...\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]12/02/2020 13:58:53 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.101s]\n",
      "  2%|▏         | 1/54 [00:00<00:05,  9.30it/s]12/02/2020 13:58:53 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.071s]\n",
      "12/02/2020 13:58:53 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.045s]\n",
      "  6%|▌         | 3/54 [00:00<00:04, 10.32it/s]12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.038s]\n",
      "12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.025s]\n",
      "12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.029s]\n",
      " 11%|█         | 6/54 [00:00<00:03, 12.69it/s]12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.027s]\n",
      "12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.026s]\n",
      "12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.028s]\n",
      "12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.025s]\n",
      " 19%|█▊        | 10/54 [00:00<00:02, 15.51it/s]12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.026s]\n",
      "12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.035s]\n",
      "12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.036s]\n",
      " 24%|██▍       | 13/54 [00:00<00:02, 17.68it/s]12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.024s]\n",
      "12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.023s]\n",
      "12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.031s]\n",
      "12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.035s]\n",
      " 31%|███▏      | 17/54 [00:00<00:01, 20.23it/s]12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.036s]\n",
      "12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.036s]\n",
      "12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.030s]\n",
      " 37%|███▋      | 20/54 [00:00<00:01, 21.26it/s]12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.035s]\n",
      "12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.035s]\n",
      "12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.026s]\n",
      " 43%|████▎     | 23/54 [00:00<00:01, 22.74it/s]12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.031s]\n",
      "12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.030s]\n",
      "12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.026s]\n",
      "12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.025s]\n",
      " 50%|█████     | 27/54 [00:01<00:01, 24.60it/s]12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.024s]\n",
      "12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.030s]\n",
      "12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.035s]\n",
      " 56%|█████▌    | 30/54 [00:01<00:00, 25.67it/s]12/02/2020 13:58:54 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.041s]\n",
      "12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.029s]\n",
      "12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.017s]\n",
      " 61%|██████    | 33/54 [00:01<00:00, 26.26it/s]12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.024s]\n",
      "12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.022s]\n",
      "12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.035s]\n",
      " 67%|██████▋   | 36/54 [00:01<00:00, 27.28it/s]12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.033s]\n",
      "12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.025s]\n",
      "12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.023s]\n",
      " 72%|███████▏  | 39/54 [00:01<00:00, 27.74it/s]12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.023s]\n",
      "12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.020s]\n",
      "12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.017s]\n",
      "12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.025s]\n",
      " 80%|███████▉  | 43/54 [00:01<00:00, 29.93it/s]12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.027s]\n",
      "12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.017s]\n",
      "12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.020s]\n",
      "12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.060s]\n",
      " 87%|████████▋ | 47/54 [00:01<00:00, 29.41it/s]12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.026s]\n",
      "12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.024s]\n",
      "12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.025s]\n",
      "12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.030s]\n",
      " 94%|█████████▍| 51/54 [00:01<00:00, 30.03it/s]12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.027s]\n",
      "12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.027s]\n",
      "12/02/2020 13:58:55 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.023s]\n",
      "100%|██████████| 54/54 [00:01<00:00, 27.19it/s]\n",
      "12/02/2020 13:58:55 - INFO - haystack.retriever.base -   For 54 out of 54 questions (100.00%), the answer was in the top-20 candidate passages selected by the retriever.\n",
      "Retriever Recall: 1.0\n",
      "Retriever Mean Avg Precision: 0.9367283950617283\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own\n",
    "retriever_eval_results = retriever.eval(top_k=20, label_index=label_index, doc_index=doc_index)\n",
    "## Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "## among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "## Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 14:02:54 - INFO - farm.utils -   device: cpu n_gpu: 0, distributed training: False, automatic mixed precision training: None\n"
     ]
    }
   ],
   "source": [
    "from farm.utils import initialize_device_settings\n",
    "\n",
    "device, n_gpu = initialize_device_settings(use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 14:02:57 - INFO - haystack.reader.farm -   Performing Evaluation using top_k_per_candidate = 3 \n",
      "and consequently, QuestionAnsweringPredictionHead.n_best = 4. \n",
      "This deviates from FARM's default where QuestionAnsweringPredictionHead.n_best = 5\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_labels/_search?scroll=5m&size=1000 [status:200 request:0.017s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.011s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   DELETE http://localhost:9200/_search/scroll [status:200 request:0.004s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search?scroll=5m&size=1000 [status:200 request:0.027s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.005s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   DELETE http://localhost:9200/_search/scroll [status:200 request:0.002s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.006s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.005s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.011s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.008s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.005s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.006s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.005s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.009s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.006s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.005s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.005s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.009s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.005s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.005s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.010s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.006s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.007s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.007s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.007s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.005s]\n",
      "12/02/2020 14:02:57 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:02:58 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.006s]\n",
      "12/02/2020 14:02:58 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:02:58 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.010s]\n",
      "12/02/2020 14:02:58 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.005s]\n",
      "12/02/2020 14:02:58 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:02:58 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.005s]\n",
      "12/02/2020 14:02:58 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.006s]\n",
      "12/02/2020 14:02:58 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:02:58 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:02:58 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:02:58 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.006s]\n",
      "12/02/2020 14:02:58 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.008s]\n",
      "12/02/2020 14:02:58 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:02:58 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:02:58 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.009s]\n",
      "12/02/2020 14:02:58 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.007s]\n",
      "12/02/2020 14:02:58 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:02:58 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.007s]\n",
      "12/02/2020 14:02:58 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.005s]\n",
      "Evaluating: 100%|██████████| 73/73 [31:10<00:00, 25.63s/it]Reader Top-N-Accuracy: 0.6111111111111112\n",
      "Reader Exact Match: 0.2777777777777778\n",
      "Reader F1-Score: 0.30750487329434695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Reader on its own\n",
    "reader_eval_results = farm_reader.eval(document_store=document_store, device=device, label_index=label_index, doc_index=doc_index)\n",
    "# Evaluation of Reader can also be done directly on a SQuAD-formatted file without passing the data to Elasticsearch\n",
    "#reader_eval_results = reader.eval_on_file(\"../data/nq\", \"nq_dev_subset_v2.json\", device=device)\n",
    "\n",
    "## Reader Top-N-Accuracy is the proportion of predicted answers that match with their corresponding correct answer\n",
    "print(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n",
    "## Reader Exact Match is the proportion of questions where the predicted answer is exactly the same as the correct answer\n",
    "print(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n",
    "## Reader F1-Score is the average overlap between the predicted answers and the correct answers\n",
    "print(\"Reader F1-Score:\", reader_eval_results[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_labels/_search?scroll=5m&size=1000 [status:200 request:0.023s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.003s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   DELETE http://localhost:9200/_search/scroll [status:200 request:0.002s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.005s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.008s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.005s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.006s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.018s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.006s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.008s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.015s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.007s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.007s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.009s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.006s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.006s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.009s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.010s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.009s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.011s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.008s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.006s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.007s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.005s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.005s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.012s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.009s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.009s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.012s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.012s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.011s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.013s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.011s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.010s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.007s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.007s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.007s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.007s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.005s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.006s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.006s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.005s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.011s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.013s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.008s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.005s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.004s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.008s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.015s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.006s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.008s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.008s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.010s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.012s]\n",
      "12/02/2020 14:38:33 - INFO - elasticsearch -   POST http://localhost:9200/evaluation_docs/_search [status:200 request:0.006s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:08<00:00,  8.04s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:06<00:00,  6.89s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:34<00:00, 17.14s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.19s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:22<00:00, 22.87s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:21<00:00, 21.82s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:30<00:00, 15.00s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:26<00:00, 26.77s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:50<00:00, 16.85s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:16<00:00, 16.26s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:14<00:00, 14.62s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:45<00:00, 22.81s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:37<00:00, 18.99s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:31<00:00, 15.58s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:23<00:00, 23.12s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:47<00:00, 23.54s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:29<00:00, 14.82s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:30<00:00, 15.39s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:18<00:00, 18.71s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 5/5 [01:58<00:00, 23.67s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:17<00:00, 17.22s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:38<00:00, 38.69s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:46<00:00, 23.01s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 4/4 [02:45<00:00, 41.30s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:26<00:00, 26.95s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:40<00:00, 40.28s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:35<00:00, 35.82s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:24<00:00, 24.52s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:12<00:00, 12.95s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:14<00:00, 14.88s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:31<00:00, 31.84s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 9/9 [05:09<00:00, 34.35s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:06<00:00,  6.82s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [01:09<00:00, 34.76s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:12<00:00, 12.89s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:34<00:00, 34.08s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:05<00:00,  5.57s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:16<00:00, 16.77s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:46<00:00, 23.04s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:38<00:00, 38.55s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:12<00:00, 12.47s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:08<00:00,  8.67s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [01:39<00:00, 33.12s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.83s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [01:12<00:00, 36.34s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:06<00:00,  6.37s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:17<00:00, 17.98s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:26<00:00, 13.47s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:28<00:00, 14.15s/ Batches]\n",
      "12/02/2020 15:10:36 - INFO - haystack.finder -   34.0 out of 54 questions were correctly answered 62.96%).\n",
      "12/02/2020 15:10:36 - INFO - haystack.finder -   5.0 questions could not be answered due to the retriever.\n",
      "12/02/2020 15:10:36 - INFO - haystack.finder -   15.0 questions could not be answered due to the reader.\n",
      "\n",
      "___Retriever Metrics in Finder___\n",
      "Retriever Recall            : 0.907\n",
      "Retriever Mean Avg Precision: 0.907\n",
      "Retriever Mean Reciprocal Rank: 0.907\n",
      "\n",
      "___Reader Metrics in Finder___\n",
      "Top-k accuracy\n",
      "Reader Top-1 accuracy             : 0.327\n",
      "Reader Top-1 accuracy (has answer): 0.115\n",
      "Reader Top-k accuracy             : 0.694\n",
      "Reader Top-k accuracy (has answer): 0.423\n",
      "Exact Match\n",
      "Reader Top-1 EM                   : 0.265\n",
      "Reader Top-1 EM (has answer)      : 0.000\n",
      "Reader Top-k EM                   : 0.571\n",
      "Reader Top-k EM (has answer)      : 0.192\n",
      "F1 score\n",
      "Reader Top-1 F1                   : 0.295\n",
      "Reader Top-1 F1 (has answer)      : 0.057\n",
      "Reader Top-k F1                   : 0.646\n",
      "Reader Top-k F1 (has answer)      : 0.332\n",
      "No Answer\n",
      "Reader Top-1 no-answer accuracy   : 0.565\n",
      "Reader Top-k no-answer accuracy   : 1.000\n",
      "\n",
      "___Time Measurements___\n",
      "Total retrieve time           : 0.592\n",
      "Avg retrieve time per question: 0.011\n",
      "Total reader timer            : 1922.705\n",
      "Avg read time per question    : 39.239\n",
      "Total Finder time             : 1923.338\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE Finder\n",
    "\n",
    "finder_eval_results = finder.eval(top_k_retriever=1, top_k_reader=10, label_index=label_index, doc_index=doc_index)\n",
    "finder.print_eval_results(finder_eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}