{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit ('.venv')",
   "metadata": {
    "interpreter": {
     "hash": "5bdca235408bc63495fd8719d073449338626e85bb6ce08bacdb45b63101d775"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 10:42:35 - INFO - faiss -   Loading faiss with AVX2 support.\n",
      "12/02/2020 10:42:35 - INFO - faiss -   Loading faiss.\n"
     ]
    }
   ],
   "source": [
    "from haystack.preprocessor.utils import convert_files_to_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 10:42:46 - INFO - haystack.preprocessor.utils -   Converting /home/elena/Downloads/data/9781839217579-THE_DEEP_LEARNING_WITH_KERAS_WORKSHOP_SECOND_EDITION.pdf\n"
     ]
    }
   ],
   "source": [
    "dicts=convert_files_to_dicts(\"/home/elena/Downloads/data/\", split_paragraphs=True) # no cleaning function applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(list, 1418, dict, dict_keys(['text', 'meta']))"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "type(dicts), len(dicts), type(dicts[0]), dicts[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'text': '\\x0cThe Deep Learning\\nwith Keras Workshop\\nSecond Edition', 'meta': {'name': '9781839217579-THE_DEEP_LEARNING_WITH_KERAS_WORKSHOP_SECOND_EDITION.pdf'}}\n"
     ]
    }
   ],
   "source": [
    "print(dicts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_store.faiss import FAISSDocumentStore\n",
    "\n",
    "document_store = FAISSDocumentStore()\n",
    "document_store.delete_all_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.write_documents(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 10:43:56 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "12/02/2020 10:44:05 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n"
     ]
    }
   ],
   "source": [
    "from haystack.retriever.dense import DensePassageRetriever\n",
    "retriever = DensePassageRetriever(document_store=document_store,\n",
    "                                  query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "                                  passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "                                  max_seq_len_query=64,\n",
    "                                  max_seq_len_passage=256,\n",
    "                                  batch_size=16,\n",
    "                                  use_gpu=False,\n",
    "                                  embed_title=True,\n",
    "                                  use_fast_tokenizers=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 10:44:17 - INFO - haystack.document_store.faiss -   Updating embeddings for 1418 docs...\n",
      "Inferencing Samples: 100%|██████████| 89/89 [11:43<00:00,  7.90s/ Batches]\n",
      "12/02/2020 10:56:03 - INFO - haystack.document_store.faiss -   Indexing embeddings and updating vectors_ids...\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.76it/s]\n"
     ]
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "12/02/2020 10:56:28 - INFO - farm.utils -   device: cpu n_gpu: 0, distributed training: False, automatic mixed precision training: None\n",
      "12/02/2020 10:56:28 - INFO - farm.infer -   Could not find `deepset/roberta-base-squad2` locally. Try to download from model hub ...\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "12/02/2020 10:56:33 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "12/02/2020 10:56:42 - INFO - farm.utils -   device: cpu n_gpu: 0, distributed training: False, automatic mixed precision training: None\n",
      "12/02/2020 10:56:42 - INFO - farm.infer -   Got ya 3 parallel workers to do inference ...\n",
      "12/02/2020 10:56:42 - INFO - farm.infer -    0    0    0 \n",
      "12/02/2020 10:56:42 - INFO - farm.infer -   /w\\  /w\\  /w\\\n",
      "12/02/2020 10:56:42 - INFO - farm.infer -   /'\\  / \\  /'\\\n",
      "12/02/2020 10:56:42 - INFO - farm.infer -       \n"
     ]
    }
   ],
   "source": [
    "from haystack.reader.farm import FARMReader\n",
    "farm_reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = Finder(farm_reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.07 Batches/s]\n",
      "12/02/2020 10:57:08 - INFO - haystack.finder -   Got 10 candidates from retriever\n",
      "12/02/2020 10:57:08 - INFO - haystack.finder -   Reader is looking for detailed answer in 3458 chars ...\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.01 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.40 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.21 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.34 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.36 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.11 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.49 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.10 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.25 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.87 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "prediction = finder.get_answers(question=\"What is RNN?\", top_k_retriever=10, top_k_reader=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.utils import print_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[   {   'answer': 'the hidden layer not only gives the\\n'\n                  'output, but it also feeds back the information of the '\n                  'output into itself',\n        'context': 'y of the RNN is that the hidden layer not only gives the\\n'\n                   'output, but it also feeds back the information of the '\n                   'output into itself. Before taking a\\n'\n                   'dee',\n        'score': 12.397671699523926},\n    {   'answer': 'Recurrent Neural Networks',\n        'context': 'Recurrent Neural Networks (RNNs)\\n'\n                   'RNNs are a class of neural networks that are built on the '\n                   'concept of sequential\\n'\n                   'memory. Unlike traditional neural net',\n        'score': 11.025992393493652},\n    {   'answer': 'Long Short-Term Memory',\n        'context': 'Long Short-Term Memory (LSTM)\\n'\n                   'LSTMs are RNNs whose main objective is to overcome the '\n                   'shortcomings of the vanishing\\n'\n                   'gradient and exploding gradient pro',\n        'score': 4.55922269821167},\n    {   'answer': 'Sequential Modeling with Recurrent Neural Networks',\n        'context': 'Figure 9.12: A simple RNN model\\n'\n                   '\\x0c'\n                   '290 | Sequential Modeling with Recurrent Neural Networks\\n'\n                   'The LSTM architecture is similar to simple RNNs, but their '\n                   'r',\n        'score': 2.116891622543335},\n    {   'answer': 'RNNs',\n        'context': 'o predict and\\n'\n                   \"forecast the company's future trend for January 2019 using \"\n                   'RNNs. We have the actual\\n'\n                   'values for January 2019, so we will be able to compa',\n        'score': -1.6894484758377075}]\n"
     ]
    }
   ],
   "source": [
    "print_answers(prediction, details=\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.17 Batches/s]\n",
      "12/02/2020 10:58:09 - INFO - haystack.finder -   Got 10 candidates from retriever\n",
      "12/02/2020 10:58:09 - INFO - haystack.finder -   Reader is looking for detailed answer in 5180 chars ...\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.75 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.28 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.45 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.18s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.29 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.20 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.01 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.44 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.32 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.42 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "prediction = finder.get_answers(question=\"What is a layer?\", top_k_retriever=10, top_k_reader=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[   {   'answer': 'Dense layer',\n        'context': 'ras. For now, we will use only the simplest type of\\n'\n                   'layer, called the Dense layer. A Dense layer is equivalent '\n                   'to the fully connected\\n'\n                   'layers that we h',\n        'score': 10.62425708770752},\n    {   'answer': 'a\\ncomposition of nodes',\n        'context': 'ers is part of the Keras core API. A layer can be thought '\n                   'of as a\\n'\n                   'composition of nodes, and at each node, a set of '\n                   'computations happen. In Keras, all ',\n        'score': 10.560615539550781},\n    {   'answer': 'convolutional',\n        'context': 'd: it has a four-dimensional input shape (None, 224, 224,\\n'\n                   '3) and it has three convolutional layers.\\n'\n                   'The last four layers of the output are as follows:',\n        'score': 9.095014572143555},\n    {   'answer': 'W1',\n        'context': 'st hidden layer. First, the input matrix, X, is the matrix '\n                   'multiplied by the\\n'\n                   'weight matrix for layer 1, W1, and the bias, b1, is '\n                   'added:\\n'\n                   'z1 = X*W1 + b1',\n        'score': 8.24875259399414},\n    {   'answer': 'Dense',\n        'context': '6. Add the first Dense layer of the ANN. Here, 128 is the '\n                   'output of the number of\\n'\n                   'nodes. As a good practice, 128 is good to get started. '\n                   'activation is',\n        'score': 7.852076530456543}]\n"
     ]
    }
   ],
   "source": [
    "print_answers(prediction, details=\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}