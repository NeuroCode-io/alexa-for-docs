{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "from config import config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = config.ENDPOINT\n",
    "api_version=\"?api-version=2019-05-06\"\n",
    "#api_version = '?api-version=2019-05-06'\n",
    "headers = {'Content-Type': config.CONTENT_TYPE,\n",
    "        'api-key': config.API_KEY }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_Url(endpoint, resource, resource_name, api_version, searchstring):\n",
    "    if resource_name:\n",
    "        \n",
    "        if searchstring:\n",
    "            return  endpoint + resource + \"/\" + resource_name + api_version + searchstring \n",
    "        else:\n",
    "            return endpoint + resource + \"/\" + resource_name + api_version\n",
    "    else:\n",
    "        return endpoint + resource + api_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'@odata.context': 'https://alexa-for-docs.search.windows.net/$metadata#indexes',\n 'value': []}\n"
     ]
    }
   ],
   "source": [
    "url = construct_Url(endpoint=endpoint, resource=\"indexes\", resource_name=None, api_version=api_version, searchstring=None)\n",
    "response  = requests.get(url, headers=headers)\n",
    "index_list = response.json()\n",
    "pprint(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.file_converter.pdf import PDFToTextConverter\n",
    "converter = PDFToTextConverter(remove_numeric_tables=True, valid_languages=[\"en\"])\n",
    "doc = converter.convert(file_path=\"./book/9781839217579-THE_DEEP_LEARNING_WITH_KERAS_WORKSHOP_SECOND_EDITION.pdf\", meta=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(dict_keys(['text', 'meta']), dict)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "doc.keys(), type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_text=doc[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\x0cThe Deep Learning\\nwith Keras Workshop\\nSecond Edition\\n\\nAn Interactive Approach to Understanding\\nDeep Learning with Keras\\n\\nMatthew Moocarme\\nMahla Abdolahnejad\\nRitesh Bhagwat\\n\\x0cThe Deep Learning with Keras Workshop\\nSecond Edition\\nCopyright © 2020 Packt Publishing\\nAll rights reserved. No part of this book may be reproduced, stored in a retrieval system,\\nor transmitted in any form or by any means, without the prior written permission of the\\npublisher, except in the case of brief quotations embedded in critical articles or reviews.\\nEvery effort has been made in the preparation of this book to ensure the accuracy of\\nthe information presented. However, the information contained in this book is sold\\nwithout warranty, either express or implied. Neither the authors, nor Packt Publishing,\\nand its dealers and distributors will be held liable for any damages caused or alleged to\\nbe caused directly or indirectly by this book.\\nPackt Publishing has endeavored to provide trademark information about all '"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "doc_text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "579763"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "len(doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the index definition, including the fields that define each search document. Fields have a name type, and attributes that determine how you can use the field. \n",
    "\n",
    "index_schema = {\n",
    "    \"name\":\"mlbook\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"book_name\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"key\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"content\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"key\": False,\n",
    "            \"searchable\": True,\n",
    "            \"retrievable\": True,\n",
    "            \"analyzer\": \"en.microsoft\"           \n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'@odata.context': 'https://alexa-for-docs.search.windows.net/$metadata#indexes/$entity',\n '@odata.etag': '\"0x8D89AE5F9702D51\"',\n 'analyzers': [],\n 'charFilters': [],\n 'corsOptions': None,\n 'defaultScoringProfile': None,\n 'encryptionKey': None,\n 'fields': [{'analyzer': None,\n             'facetable': True,\n             'filterable': True,\n             'indexAnalyzer': None,\n             'key': True,\n             'name': 'book_name',\n             'retrievable': True,\n             'searchAnalyzer': None,\n             'searchable': True,\n             'sortable': True,\n             'synonymMaps': [],\n             'type': 'Edm.String'},\n            {'analyzer': 'en.microsoft',\n             'facetable': True,\n             'filterable': True,\n             'indexAnalyzer': None,\n             'key': False,\n             'name': 'content',\n             'retrievable': True,\n             'searchAnalyzer': None,\n             'searchable': True,\n             'sortable': True,\n             'synonymMaps': [],\n             'type': 'Edm.String'}],\n 'name': 'mlbook',\n 'scoringProfiles': [],\n 'suggesters': [],\n 'tokenFilters': [],\n 'tokenizers': []}\n"
     ]
    }
   ],
   "source": [
    "# Formulate the request. This POST request targets the indexes collection of your search service and creates an index based on the index schema you provided in the previous cell.\n",
    "url = construct_Url(endpoint=endpoint, resource=\"indexes\", resource_name=None, api_version=api_version, searchstring=None)\n",
    "response  = requests.post(url, headers=headers, json=index_schema)\n",
    "index = response.json()\n",
    "pprint(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, provide ddocuments that conform to the index schema. Specify an upload action for each document.\n",
    "# we have only one document containing the text of the book\n",
    "\n",
    "# The max length for UTF-8 encoded terms is 32.766 bytes. \n",
    "# len(doc_text[32766:]) =  546997\n",
    "\n",
    "\n",
    "document = {\n",
    "    \"value\": [\n",
    "    { \"@search.action\": \"upload\",\n",
    "    \"book_name\": \"THE_DEEP_LEARNING_WITH_KERAS_WORKSHOP_SECOND_EDITION\",\n",
    "    \"content\": doc_text[:10000]\n",
    "    },\n",
    "    { \"@search.action\": \"upload\",\n",
    "    \"book_name\": \"THE_DEEP_LEARNING_WITH_KERAS_WORKSHOP_SECOND_EDITION\",\n",
    "    \"content\": doc_text[10000:20000]\n",
    "    },\n",
    "    { \"@search.action\": \"upload\",\n",
    "    \"book_name\": \"THE_DEEP_LEARNING_WITH_KERAS_WORKSHOP_SECOND_EDITION\",\n",
    "    \"content\": doc_text[20000:30000]\n",
    "    },\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'@odata.context': \"https://alexa-for-docs.search.windows.net/indexes('mlbook')/$metadata#Collection(Microsoft.Azure.Search.V2019_05_06.IndexResult)\",\n 'value': [{'errorMessage': None,\n            'key': 'THE_DEEP_LEARNING_WITH_KERAS_WORKSHOP_SECOND_EDITION',\n            'status': True,\n            'statusCode': 201},\n           {'errorMessage': None,\n            'key': 'THE_DEEP_LEARNING_WITH_KERAS_WORKSHOP_SECOND_EDITION',\n            'status': True,\n            'statusCode': 200},\n           {'errorMessage': None,\n            'key': 'THE_DEEP_LEARNING_WITH_KERAS_WORKSHOP_SECOND_EDITION',\n            'status': True,\n            'statusCode': 200}]}\n"
     ]
    }
   ],
   "source": [
    "url = construct_Url(endpoint=endpoint, resource=\"indexes\", resource_name=\"mlbook/docs/index\", api_version=api_version, searchstring=None)\n",
    "response  = requests.post(url, headers=headers, json=document)\n",
    "index_content = response.json()\n",
    "pprint(index_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'@odata.context': \"https://alexa-for-docs.search.windows.net/indexes('mlbook')/$metadata#docs(*)\",\n 'value': [{'@search.score': 0.119144924,\n            'book_name': 'THE_DEEP_LEARNING_WITH_KERAS_WORKSHOP_SECOND_EDITION',\n            'content': '............... 298\\n'\n                       '\\x0c'\n                       \"Exercise 9.02: Predicting the Trend of Alphabet's \"\n                       'Stock Price\\n'\n                       'Using an LSTM with 100 units '\n                       '........................................................................ '\n                       '300\\n'\n                       \"Activity 9.02: Predicting Amazon's Stock Price\\n\"\n                       'with Added Regularization '\n                       '............................................................................. '\n                       '304\\n'\n                       \"Activity 9.03: Predicting the Trend of Amazon's Stock \"\n                       'Price Using\\n'\n                       'an LSTM with an Increasing Number of LSTM Neurons (100 '\n                       'Units) .......... 306\\n'\n                       '\\n'\n                       'Summary '\n                       '...................................................................................................... '\n                       '308\\n'\n                       '\\n'\n                       '\\x0c'\n                       '\\x0c'\n                       '\\x0c'\n                       '>\\n'\n                       '\\n'\n                       'Preface\\n'\n                       '\\n'\n                       'About\\n'\n                       'This section briefly introduces this book and the '\n                       'software requirements you need in order to\\n'\n                       'complete all of the included activities and '\n                       'exercises.\\n'\n                       '\\x0c'\n                       'ii | Preface\\n'\n                       '\\n'\n                       'About the Book\\n'\n                       'You already know that you want to learn Keras, and a '\n                       'smarter way to learn is to learn\\n'\n                       'by doing. The Deep Learning with Keras Workshop '\n                       'focuses on building up your practical\\n'\n                       'skills so that you can develop artificial intelligence '\n                       'applications or build machine\\n'\n                       \"learning models with Keras. You'll learn from real \"\n                       'examples that lead to real results.\\n'\n                       'Throughout The Deep Learning with Keras Workshop, '\n                       \"you'll take an engaging\\n\"\n                       \"step‑by‑step approach to understand Keras. You won't \"\n                       'have to sit through any\\n'\n                       \"unnecessary theory. If you're short on time, you can \"\n                       'jump into a single exercise each\\n'\n                       'day or spend an entire weekend tinkering with your own '\n                       \"neural neyworks. It's your\\n\"\n                       \"choice. Learning on your terms, you'll build up and \"\n                       'reinforce key skills in a way that\\n'\n                       'feels rewarding.\\n'\n                       'Every physical print copy of The Deep Learning with '\n                       'Keras Workshop unlocks access to\\n'\n                       'the interactive edition. With videos detailing all '\n                       \"exercises and activities, you'll always\\n\"\n                       'have a guided solution. You can also benchmark '\n                       'yourself against assessments, track\\n'\n                       \"progress, and receive content updates. You'll even \"\n                       'earn a secure credential that you\\n'\n                       \"can share and verify online upon completion. It's a \"\n                       \"premium learning experience that's\\n\"\n                       'included with your print copy. To redeem, follow the '\n                       'instructions located at the start of\\n'\n                       'your data science book.\\n'\n                       'Fast-paced and direct, The Deep Learning with Keras '\n                       'Workshop is the ideal\\n'\n                       'companion for those who are just getting started with '\n                       \"Keras. You'll build and iterate\\n\"\n                       'on your code like a software developer, learning along '\n                       'the way. This process means\\n'\n                       \"that you'll find that your new skills stick, embedded \"\n                       'as best practice—a solid foundation\\n'\n                       'for the years ahead.\\n'\n                       '\\n'\n                       'Audience\\n'\n                       'Our goal at Packt is to help you be successful, in '\n                       'whatever it is that you choose to do.\\n'\n                       'The Deep Learning with Keras Workshop is an ideal '\n                       'tutorial for the programmer who is\\n'\n                       'getting started with Keras and deep learning. Pick up '\n                       'a Workshop today and let Packt\\n'\n                       'help you develop skills that will stick with you for '\n                       'life.\\n'\n                       '\\n'\n                       'About the Chapters\\n'\n                       'Chapter 1, Introduction to Machine Learning with '\n                       'Keras, will introduce you to the\\n'\n                       'fundamental concepts of machine learning by using the '\n                       'scikit-learn package. You will\\n'\n                       'learn how to present data for model building, then '\n                       'train a logistic regression model\\n'\n                       'using a real-world dataset.\\n'\n                       '\\x0c'\n                       'About the Book | iii\\n'\n                       'Chapter 2, Machine Learning versus Deep Learning, will '\n                       'present the difference between\\n'\n                       'traditional machine learning algorithms and deep '\n                       'learning algorithms. You will learn\\n'\n                       'the linear transformations necessary for building '\n                       'neural networks and build your first\\n'\n                       'neural network with the Keras library.\\n'\n                       'Chapter 3, Deep Learning with Keras, will extend your '\n                       'knowledge of neural network\\n'\n                       'building. You will learn how to build multi-layer '\n                       'neural networks and recognize when\\n'\n                       'your model is underfitting or overfitting to the '\n                       'training data.\\n'\n                       'Chapter 4, Evaluating Your Model with Cross-Validation '\n                       'Using Keras Wrappers, will teach\\n'\n                       'you how to use Keras wrappers with scikit-learn to '\n                       'incorporate Keras models into\\n'\n                       'a scikit-learn workflow. You will apply '\n                       'cross-validation to evaluate your models and use\\n'\n                       'this technique to choose the optimal hyperparameters.\\n'\n                       'Chapter 5, Improving Model Accuracy, will introduce '\n                       'various regularization techniques\\n'\n                       'to prevent your models from overfitting the training '\n                       'data. You will learn different\\n'\n                       'methods to search for the optimal hyperparameters that '\n                       'result in the highest\\n'\n                       'model accuracy.\\n'\n                       'Chapter 6, Model Evaluation, will demonstrate a '\n                       'variety of methods to evaluate your\\n'\n                       'models. Beyond accuracy, you will learn about more '\n                       'model evaluation metrics including\\n'\n                       'sensitivity, specificity, precision, false positive '\n                       'rate, ROC curves, and AUC scores to\\n'\n                       'understand how well your models perform.\\n'\n                       'Chapter 7, Computer Vision with Convolutional Neural '\n                       'Networks, will introduce you to\\n'\n                       'building image classifiers with convolutional neural '\n                       'networks. You will learn about all\\n'\n                       'the components that comprise the architecture of '\n                       'convolutional neural networks and\\n'\n                       'then build image processing applications to classify '\n                       'images.\\n'\n                       'Chapter 8, Transfer Learning and Pre-Trained Models, '\n                       'will introduce you to the concept\\n'\n                       'of transferring the learning from one model to solve '\n                       'for other applications. You will\\n'\n                       'achieve this by using different pre-trained models and '\n                       'modifying them slightly to fit\\n'\n                       'different applications.\\n'\n                       'Chapter 9, Sequential Modeling with Recurrent Neural '\n                       'Networks, will teach you how to\\n'\n                       'build models with sequential data. You will learn the '\n                       'architecture of recurrent neural\\n'\n                       'networks and how to train them to predict the '\n                       'succeeding values from sequential data.\\n'\n                       'You will test your knowledge by predicting the future '\n                       'values of various stock prices.\\n'\n                       '\\x0c'\n                       'iv | Preface\\n'\n                       '\\n'\n                       'Conventions\\n'\n                       'Code words in text, database table names, folder '\n                       'names, filenames, file extensions, path\\n'\n                       'names, dummy URLs, user input, and Twitter handles are '\n                       'shown as follows:\\n'\n                       '\"sklearn has a class called train_test_split, which '\n                       'provides the functionality for\\n'\n                       'splitting data.\"\\n'\n                       'Words that you see on the screen, for example, in '\n                       'menus or dialog boxes, also appear in\\n'\n                       'the same format.\\n'\n                       'A block of code is set as follows:\\n'\n                       '# import libraries\\n'\n                       'import pandas as pd\\n'\n                       'from sklearn.model_selection import train_test_split\\n'\n                       '\\n'\n                       'New terms and important words are shown like this:\\n'\n                       '\"A dictionary contains multiple elements, like a list, '\n                       'but each element is organized\\n'\n                       'as a key-value pair.\"\\n'\n                       '\\n'\n                       'Before You Begin\\n'\n                       'Each great journey begins with a humble step. Our '\n                       'upcoming adventure with Applied\\n'\n                       'Deep Learning with Keras, is no exception. Before we '\n                       'can do awesome things with\\n'\n                       'Keras library, we need to be prepared with a '\n                       'productive environment. In this short\\n'\n                       'section, we shall see how to do that.\\n'\n                       '\\n'\n                       'Installing Python\\n'\n                       'Installing Python on Windows:\\n'\n                       'To install Python on Windows, do the following:\\n'\n                       '1.\\n'\n                       '\\n'\n                       'Find your desired version of Python on the official '\n                       'installation page at\\n'\n                       'https://packt.live/37AxDz4.\\n'\n                       '\\n'\n                       '2. Ensure you select Python 3.7 from the download '\n                       'page.\\n'\n                       '3. Ensure that you install the correct architecture '\n                       'for your computer system; that is;\\n'\n                       'either 32-bit or 64-bit. You can find out this '\n                       'information in the System Properties\\n'\n                       'window of your OS.\\n'\n                       '4. After you download the installer, simply '\n                       'double-click on the file and follow the\\n'\n                       'user‑friendly prompts onscreen.\\n'\n                       '\\x0c'\n                       'About the Book | v\\n'\n                       'Installing Python on Linux:\\n'\n                       'To install Python on Linux, you have a couple of good '\n                       'options:\\n'\n                       '1.\\n'\n                       '\\n'\n                       'Open Comand Prompt and verify that p\\\\Python 3 is not '\n                       'already installed\\n'\n                       'by running python3 –version.\\n'\n                       '\\n'\n                       '2. To install Python 3, run this:\\n'\n                       'sudo apt-get update\\n'\n                       'sudo apt-get install python3.7\\n'\n                       '\\n'\n                       '3. If you encounter problems, there are numerous '\n                       'sources online that can help you\\n'\n                       'troubleshoot the issue.\\n'\n                       '4. Install Anaconda Linux by downloading the installer '\n                       'from\\n'\n                       'https://packt.live/2OYAmMw and following the '\n                       'instructions.\\n'\n                       'Installing Python on macOS:\\n'\n                       'Similar to Linux, you have a couple of methods for '\n                       'installing Python on a Mac. To install\\n'\n                       'Python on macOS, do the following:\\n'\n                       '1.\\n'\n                       '\\n'\n                       'Open the Terminal for Mac by pressing CMD + Spacebar, '\n                       'type terminal in the\\n'\n                       'open search box, and hit Enter.\\n'\n                       '\\n'\n                       '2. Install Xcode through the command line by running '\n                       'xcode-select –install.\\n'\n                       '3. The easiest way to install Python 3 is using '\n                       'Homebrew, which is installed through\\n'\n                       'the command line by running ruby -e \"$(curl -fsSL '\n                       'https://raw.\\n'\n                       'githubusercontent.com/Homebrew/install/master/install)\".\\n'\n                       '4. Add Homebrew to your $PATH environment variable. '\n                       'Open your profile in the\\n'\n                       'command line by running sudo nano ~/.profile and '\n                       'inserting export\\n'\n                       'PATH=\"/usr/local/opt/python/libexec/bin:$PATH\" at the '\n                       'bottom.\\n'\n                       '5. The final step is to install Python. In the command '\n                       'line, run brew\\n'\n                       'install python.\\n'\n                       '\\n'\n                       '6. Again, you can also install Python via the Anaconda '\n                       'installer available from\\n'\n                       'https://packt.live/2OZwwm2.\\n'\n                       '\\x0c'\n                       'vi | Preface\\n'\n                       '\\n'\n                       'Installing the Code Bundle\\n'\n                       'Download the code files from GitHub at '\n                       'https://packt.live/2OL5E9t. Refer to these\\n'\n                       'code files for the complete code bundle.\\n'\n                       'The high-quality color images used in book can be '\n                       'found at https://packt.live/2u9Tno4.\\n'\n                       'If you have any issues or questions about '\n                       'installation, please email us\\n'\n                       'at workshops@packt.com.\\n'\n                       '\\x0c'\n                       '\\x0c'\n                       '\\x0c'\n                       '\\n'\n                       'Introduction to\\n'\n                       'Machine Learning\\n'\n                       'with Keras\\n'\n                       'Overview\\n'\n                       'This chapter introduces machine learning with Python. '\n                       'We will use\\n'\n                       'real-life datasets to demonstrate the basics of '\n                       'machine learning, which include\\n'\n                       'preprocessing data for machine learning models and '\n                       'building a classification\\n'\n                       'model using the logistic regression model with '\n                       'scikit-learn. We will then advance\\n'\n                       'our model-building skills by incorporating '\n                       'regularization into our models and\\n'\n                       'evaluating their performance with model evaluation '\n                       'metrics. By the end of this\\n'\n                       'chapter, you will be able to confidently create models '\n                       'to solve classification tasks\\n'\n                       'using the scikit-learn library in Python and evaluate '\n                       'the performance of those\\n'\n                       'models effectively.\\n'\n                       '\\x0c'\n                       '2 | Introduction to Machine Learning with Keras\\n'\n                       '\\n'\n                       'Introduction\\n'\n                       'Machine learning is the science of utilizing machines '\n                       'to emulate human tasks and to\\n'\n                       'have the machine improve its performance of that task '\n                       'over time. By feeding machines\\n'\n                       'data in the form of observations of real-world events, '\n                       'they can develop patterns and\\n'\n                       'relationships that will optimize an objective '\n                       'function, such as the accuracy of a binary\\n'\n                       'classification task or the error in a regression '\n                       'task.\\n'\n                       'In g'}]}\n"
     ]
    }
   ],
   "source": [
    "searchstring = '&search=layer'\n",
    "url = construct_Url(endpoint=endpoint, resource=\"indexes\", resource_name=\"mlbook/docs\", api_version=api_version, searchstring=searchstring)\n",
    "\n",
    "\n",
    "response  = requests.get(url, headers=headers, json=searchstring)\n",
    "query = response.json()\n",
    "pprint(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ". Reshape the data to add an extra dimension to the '\n",
      "                       \"end of X_train using NumPy's\\n\"\n",
      "                       'reshape function:\\n'\n",
      "                       '\\n'\n",
      "                       '7. Import the following Keras libraries to build the '\n",
      "                       'RNN:\\n'\n",
      "                       'from keras.models import Sequential\\n'\n",
      "                       'from keras.layers import Dense, LSTM, Dropout\\n'\n",
      "                       '\\n'\n",
      "                       '8. Set the seed and initiate the sequential model, as '\n",
      "                       'follows:\\n'\n",
      "                       'seed = 1\\n'\n",
      "                       'np.random.seed(seed)\\n'\n",
      "                       'random.set_seed(seed)\\n'\n",
      "                       'model = Sequential()\\n'\n",
      "                       '\\n'\n",
      "                       '9. Add an LSTM layer to the network with 50 units, set '\n",
      "                       'the return_sequences\\n'\n",
      "                       'argument to True, and set the input_shape argument to '\n",
      "                       '(X_train.shape[1],\\n'\n",
      "                       '1). Add dropout to the model with rate=0.2. Add three '\n",
      "                       'additional LSTM layers,\\n'\n",
      "                       'each with 50 units, and set the return_sequences '\n",
      "                       'argument to True for the first\\n'\n",
      "                       'two. After each LSTM layer, add a dropout with '\n",
      "                       'rate=0.2. Add a final output layer\\n'\n",
      "                       'of size 1:\\n'\n",
      "                       'model.add(LSTM(units = 50, return_sequences = True, '\n",
      "                       'input_shape = (X_\\n'\n",
      "                       '# Adding a second LSTM layer and some Dropout '\n",
      "                       'regularization\\n'\n",
      "                       'model.add(LSTM(units = 50, return_sequences = True))\\n'\n",
      "                       '\\x0c'\n",
      "                       'Chapter 9: Sequential Modeling with Recurrent Neural '\n",
      "                       'Networks | 411\\n'\n",
      "                       '# Adding a third LSTM layer and some Dropout '\n",
      "                       'regularization\\n'\n",
      "                       'model.add(LSTM(units = 50, return_sequences = True))\\n'\n",
      "                       '# Adding a fourth LSTM layer and some Dropout '\n",
      "                       'regularization\\n'\n",
      "                       'model.add(LSTM(units = 50))\\n'\n",
      "                       '# Adding the output layer\\n'\n",
      "                       'model.add(Dense(units = 1))\\n'\n",
      "                       '\\n'\n",
      "                       '10. Compile the network with an adam optimizer and use '\n",
      "                       'Mean Squared Error for\\n'\n",
      "                       'the loss. Fit the model to the training data for 100 '\n",
      "                       'epochs with a batch size of 32:\\n'\n",
      "                       '# Compiling the RNN\\n'\n",
      "                       \"model.compile(optimizer = 'adam', loss = \"\n",
      "                       \"'mean_squared_error')\\n\"\n",
      "                       '# Fitting the RNN to the Training set\\n'\n",
      "                       'model.fit(X_train, y_train, epochs = 100, batch_size = '\n",
      "                       '32)\\n'\n",
      "                       '\\n'\n",
      "                       '11. Load and process the test data (which is treated '\n",
      "                       'as actual data here) and select the\\n'\n",
      "                       'column representing the value of Open stock data:\\n'\n",
      "                       \"dataset_testing = pd.read_csv('../AMZN_test.csv')\\n\"\n",
      "                       \"actual_stock_price = dataset_testing[['Open']].values\\n\"\n",
      "                       'actual_stock_price\\n'\n",
      "                       '\\n'\n",
      "                       '12. Concatenate the data since we will need 60 '\n",
      "                       'previous instances to get the stock\\n'\n",
      "                       'price for each day. Therefore, we will need both the '\n",
      "                       'training and test data:\\n'\n",
      "                       \"total_data = pd.concat((dataset_training['Open'], \"\n",
      "                       'dataset_\\n'\n",
      "                       \"testing['Open']), axis = 0)\\n\"\n",
      "                       '\\n'\n",
      "                       '13. Reshape and scale the input to prepare the test '\n",
      "                       'data. Note that we are predicting\\n'\n",
      "                       'the January monthly trend, which has 21 financial '\n",
      "                       'days, so in order to prepare the\\n'\n",
      "                       'test set, we take the lower bound value as 60 and the '\n",
      "                       'upper bound value as 81. This\\n'\n",
      "                       'ensures that the difference of 21 is maintained:\\n'\n",
      "                       'inputs\\n'\n",
      "                       'values\\n'\n",
      "                       'inputs\\n'\n",
      "                       'inputs\\n'\n",
      "                       'X_test\\n'\n",
      "                       '\\n'\n",
      "                       '= total_data[len(total_data) - len(dataset_testing) - '\n",
      "                       '60:].\\n'\n",
      "                       '= sc.transform(inputs)\\n'\n",
      "                       '= []\\n'\n",
      "                       '\\x0c'\n",
      "                       '412 | Appendix\\n'\n",
      "                       'for i in range(60, 81):\\n'\n",
      "                       'X_test = np.array(X_test)\\n'\n",
      "                       'predicted_stock_price = model.predict(X_test)\\n'\n",
      "                       'predicted_stock_price = '\n",
      "                       'sc.inverse_transform(predicted_stock_price)\\n'\n",
      "                       '\\n'\n",
      "                       '14. Visualize the results by plotting the actual stock '\n",
      "                       'price and plotting the predicted\\n'\n",
      "                       'stock price:\\n'\n",
      "                       '# Visualizing the results\\n'\n",
      "                       \"plt.plot(actual_stock_price, color = 'green', label = \"\n",
      "                       \"'Real Amazon\\n\"\n",
      "                       \"Stock Price',ls='--')\\n\"\n",
      "                       \"plt.plot(predicted_stock_price, color = 'red', label = \"\n",
      "                       \"'Predicted\\n\"\n",
      "                       \"Amazon Stock Price',ls='-')\\n\"\n",
      "                       \"plt.title('Predicted Stock Price')\\n\"\n",
      "                       \"plt.xlabel('Time in days')\\n\"\n",
      "                       \"plt.ylabel('Real Stock Price')\\n\"\n",
      "                       'plt.legend()\\n'\n",
      "                       'plt.show()\\n'\n",
      "                       '\\n'\n",
      "                       'Please note that your results may differ slightly to '\n",
      "                       'the actual stock price.\\n'\n",
      "                       'Expected output:\\n'\n",
      "                       '\\n'\n",
      "                       'Figure 9.26: Real versus predicted stock prices\\n'\n",
      "                       '\\x0c'\n",
      "                       'Chapter 9: Sequential Modeling with Recurrent Neural '\n",
      "                       'Networks | 413\\n'\n",
      "                       'In the following figure, the first plot displays the '\n",
      "                       'predicted output of the model with\\n'\n",
      "                       'regularization from Activity 9.02, and the second '\n",
      "                       'displays the predicted output without\\n'\n",
      "                       'regularization from Activity 9.01. As you can see, '\n",
      "                       'adding dropout regularization does not\\n'\n",
      "                       'fit the data as accurately. So, in this case, it is '\n",
      "                       'better not to use regularization, or to use\\n'\n",
      "                       'dropout regularization with a lower dropout rate:\\n'\n",
      "                       '\\n'\n",
      "                       'Figure 9.27: Comparing the results of Activity 9.01 '\n",
      "                       'and Activity 9.02\\n'\n",
      "                       '\\n'\n",
      "                       \"Activity 9.03: Predicting the Trend of Amazon's Stock \"\n",
      "                       'Price Using an LSTM\\n'\n",
      "                       'with an Increasing Number of LSTM Neurons (100 Units)\\n'\n",
      "                       'In this activity, we will examine the stock price of '\n",
      "                       'Amazon over the last 5 years, from\\n'\n",
      "                       'January 1, 2014, to December 31, 2018. We will try to '\n",
      "                       \"predict and forecast the company's\\n\"\n",
      "                       'future trend for January 2019 using RNNs with four '\n",
      "                       'LSTM layers, each with 100 units. We\\n'\n",
      "                       'have the actual values for January 2019, so we will be '\n",
      "                       'able to compare our predictions\\n'\n",
      "                       'with the actual values later. You can also compare the '\n",
      "                       'output difference with Activity\\n'\n",
      "                       \"9.01, Predicting the Trend of Amazon's Stock Price \"\n",
      "                       'Using an LSTM with 50 Units\\n'\n",
      "                       '(Neurons). Follow these steps to complete this '\n",
      "                       'activity:\\n'\n",
      "                       '1.\\n'\n",
      "                       '\\n'\n",
      "                       'Import the required libraries:\\n'\n",
      "                       'import numpy as np\\n'\n",
      "                       'import matplotlib.pyplot as plt\\n'\n",
      "                       'import pandas as pd\\n'\n",
      "                       'from tensorflow import random\\n'\n",
      "                       '\\n'\n",
      "                       '2. Import the dataset using the pandas read_csv '\n",
      "                       'function and look at the first five\\n'\n",
      "                       'rows of the dataset using the head method:\\n'\n",
      "                       \"dataset_training = pd.read_csv('../AMZN_train.csv')\\n\"\n",
      "                       'dataset_training.head()\\n'\n",
      "                       '\\x0c'\n",
      "                       '414 | Appendix\\n'\n",
      "                       '3. We are going to make our prediction using the Open '\n",
      "                       'stock price; therefore, select\\n'\n",
      "                       'the Open stock price column from the dataset and print '\n",
      "                       'the values:\\n'\n",
      "                       \"training_data = dataset_training[['Open']].values\\n\"\n",
      "                       'training_data\\n'\n",
      "                       '\\n'\n",
      "                       '4. Then, perform feature scaling by normalizing the '\n",
      "                       'data using MinMaxScaler and\\n'\n",
      "                       'setting the range of the features so that they have a '\n",
      "                       'minimum value of zero and\\n'\n",
      "                       'a maximum value of one. Use the fit_transform method '\n",
      "                       'of the scaler on the\\n'\n",
      "                       'training data:\\n'\n",
      "                       'from sklearn.preprocessing import MinMaxScaler\\n'\n",
      "                       'sc = MinMaxScaler(feature_range = (0, 1))\\n'\n",
      "                       'training_data_scaled = '\n",
      "                       'sc.fit_transform(training_data)\\n'\n",
      "                       'training_data_scaled\\n'\n",
      "                       '\\n'\n",
      "                       '5. Create the data to get 60 timestamps from the '\n",
      "                       'current instance. We chose 60 here\\n'\n",
      "                       'as it will give us a sufficient number of previous '\n",
      "                       'instances in order to understand\\n'\n",
      "                       'the trend; technically, this can be any number, but 60 '\n",
      "                       'is the optimal value.\\n'\n",
      "                       'Additionally, the upper bound value here is 1258, '\n",
      "                       'which is the index or count of\\n'\n",
      "                       'rows (or records) in the training set:\\n'\n",
      "                       'X_train = []\\n'\n",
      "                       'y_train = []\\n'\n",
      "                       'for i in range(60, 1258):\\n'\n",
      "                       'X_train, y_train = np.array(X_train), '\n",
      "                       'np.array(y_train)\\n'\n",
      "                       '\\n'\n",
      "                       '6. Reshape the data to add an extra dimension to the '\n",
      "                       \"end of X_train using NumPy's\\n\"\n",
      "                       'reshape function:\\n'\n",
      "                       '\\n'\n",
      "                       '7. Import the following Keras libraries to build the '\n",
      "                       'RNN:\\n'\n",
      "                       'from keras.models import Sequential\\n'\n",
      "                       'from keras.layers import Dense, LSTM, Dropout\\n'\n",
      "                       '\\n'\n",
      "                       '8. Set the seed and initiate the sequential model:\\n'\n",
      "                       'seed = 1\\n'\n",
      "                       'np.random.seed(seed)\\n'\n",
      "                       'random.set_seed(seed)\\n'\n",
      "                       'model = Sequential()\\n'\n",
      "                       '\\x0c'\n",
      "                       'Chapter 9: Sequential Modeling with Recurrent Neural '\n",
      "                       'Networks | 415\\n'\n",
      "                       '9. Add an LSTM layer to the network with 100 units, '\n",
      "                       'set the return_sequences\\n'\n",
      "                       'argument to True, and set the input_shape argument to '\n",
      "                       '(X_train.shape[1],\\n'\n",
      "                       '1). Add three additional LSTM layers, each with 100 '\n",
      "                       'units, and set the return_\\n'\n",
      "                       'sequences argument to True for the first two. Add a '\n",
      "                       'final output layer of size 1:\\n'\n",
      "                       'model.add(LSTM(units = 100, return_sequences = True, '\n",
      "                       'input_shape = (X_\\n'\n",
      "                       '# Adding a second LSTM layer\\n'\n",
      "                       'model.add(LSTM(units = 100, return_sequences = True))\\n'\n",
      "                       '# Adding a third LSTM layer\\n'\n",
      "                       'model.add(LSTM(units = 100, return_sequences = True))\\n'\n",
      "                       '# Adding a fourth LSTM layer\\n'\n",
      "                       'model.add(LSTM(units = 100))\\n'\n",
      "                       '# Adding the output layer\\n'\n",
      "                       'model.add(Dense(units = 1))\\n'\n",
      "                       '\\n'\n",
      "                       '10. Compile the network with an adam optimizer and use '\n",
      "                       'Mean Squared Error for\\n'\n",
      "                       'the loss. Fit the model to the training data for 100 '\n",
      "                       'epochs with a batch size of 32:\\n'\n",
      "                       '# Compiling the RNN\\n'\n",
      "                       \"model.compile(optimizer = 'adam', loss = \"\n",
      "                       \"'mean_squared_error')\\n\"\n",
      "                       '# Fitting the RNN to the Training set\\n'\n",
      "                       'model.fit(X_train, y_train, epochs = 100, batch_size = '\n",
      "                       '32)\\n'\n",
      "                       '\\n'\n",
      "                       '11. Load and process the test data (which is treated '\n",
      "                       'as actual data here) and select the\\n'\n",
      "                       'column representing the value of open stock data:\\n'\n",
      "                       \"dataset_testing = pd.read_csv('../AMZN_test.csv')\\n\"\n",
      "                       \"actual_stock_price = dataset_testing[['Open']].values\\n\"\n",
      "                       'actual_stock_price\\n'\n",
      "                       '\\n'\n",
      "                       '12. Concatenate the data since we will need 60 '\n",
      "                       'previous instances to get the stock\\n'\n",
      "                       'price for each day. Therefore, we will need both the '\n",
      "                       'training and test data:\\n'\n",
      "                       \"total_data = pd.concat((dataset_training['Open'], \"\n",
      "                       'dataset_\\n'\n",
      "                       \"testing['Open']), axis = 0)\\n\"\n",
      "                       '\\x0c'\n",
      "                       '416 | Appendix\\n'\n",
      "                       '13. Reshape and scale the input to prepare the test '\n",
      "                       'data. Note that we are predicting\\n'\n",
      "                       'the January monthly trend, which has 21 financial '\n",
      "                       'days, so in order to prepare the\\n'\n",
      "                       'test set, we take the lower bound value as 60 and the '\n",
      "                       'upper bound value as 81. This\\n'\n",
      "                       'ensures that the difference of 21 is maintained:\\n'\n",
      "                       'inputs = total_data[len(total_data) - '\n",
      "                       'len(dataset_testing) - 60:].\\n'\n",
      "                       'values\\n'\n",
      "                       'inputs = inputs.reshape(-1,1)\\n'\n",
      "                       'inputs = sc.transform(inputs)\\n'\n",
      "                       'X_test = []\\n'\n",
      "                       'for i in range(60, 81):\\n'\n",
      "                       'X_test = np.array(X_test)\\n'\n",
      "                       'predicted_stock_price = model.predict(X_test)\\n'\n",
      "                       'predicted_stock_price = '\n",
      "                       'sc.inverse_transform(predicted_stock_price)\\n'\n",
      "                       '\\n'\n",
      "                       '14. Visualize the results by plotting the actual stock '\n",
      "                       'price and plotting the predicted\\n'\n",
      "                       'stock price:\\n'\n",
      "                       \"plt.plot(actual_stock_price, color = 'green', label = \"\n",
      "                       \"'Actual Amazon\\n\"\n",
      "                       \"Stock Price',ls='--')\\n\"\n",
      "                       \"plt.plot(predicted_stock_price, color = 'red', label = \"\n",
      "                       \"'Predicted\\n\"\n",
      "                       \"Amazon Stock Price',ls='-')\\n\"\n",
      "                       \"plt.title('Predicted Stock Price')\\n\"\n",
      "                       \"plt.xlabel('Time in days')\\n\"\n",
      "                       \"plt.ylabel('Real Stock Price')\\n\"\n",
      "                       'plt.legend()\\n'\n",
      "                       'plt.show()\\n'\n",
      "                       '\\n'\n",
      "                       'Please note that your results may differ slightly from '\n",
      "                       'the actual stock price.\\n'\n",
      "                       '\\x0c'\n",
      "                       'Chapter 9: Sequential Modeling with Recurrent Neural '\n",
      "                       'Networks | 417\\n'\n",
      "                       'Expected output:\\n'\n",
      "                       '\\n'\n",
      "                       'Figure 9.28: Real versus predicted stock prices\\n'\n",
      "                       '\\n'\n",
      "                       'So, if we compare the results of the LSTM with 50 '\n",
      "                       'units (from Activity 9.01, Predicting\\n'\n",
      "                       \"the Trend of Amazon's Stock Price Using an LSTM with \"\n",
      "                       '50 Units (Neurons)) and the LSTM\\n'\n",
      "                       'with 100 units in this activity, we get trends with '\n",
      "                       '100 units. Also, note that when we run\\n'\n",
      "                       'the LSTM with 100 units, it takes more computational '\n",
      "                       'time than the LSTM with 50 units.\\n'\n",
      "                       'A trade-off needs to be considered in such cases:\\n'\n",
      "                       '\\n'\n",
      "                       'Figure 9.29: Comparing the real versus predicted stock '\n",
      "                       'price with 50 and 100 units\\n'\n",
      "                       '\\x0c'\n",
      "                       '\\x0c'\n",
      "                       '>\\n'\n",
      "                       'Index\\n'\n",
      "                       '\\n'\n",
      "                       'About\\n'\n",
      "                       'All major keywords used in this book are captured '\n",
      "                       'alphabetically in this section. Each one is\\n'\n",
      "                       'accompanied by the page number of where they appear.\\n'\n",
      "                       '\\x0c'\n",
      "                       'A\\n'\n",
      "                       '\\n'\n",
      "                       '\\n'\n",
      "                       'B\\n'\n",
      "                       '\\n'\n",
      "                       'C\\n'\n",
      "                       '\\n'\n",
      "                       '\\n'\n",
      "                       'D\\n'\n",
      "                       '\\x0c'\n",
      "                       'E\\n'\n",
      "                       '\\n'\n",
      "                       'F\\n'\n",
      "                       '\\n'\n",
      "                       'G\\n'\n",
      "                       '\\n'\n",
      "                       '\\n'\n",
      "                       'I\\n'\n",
      "                       '\\n'\n",
      "                       'L\\n'\n",
      "                       '\\n'\n",
      "                       'M\\n'\n",
      "                       '\\n'\n",
      "                       'O\\n'\n",
      "                       '\\x0c'\n",
      "                       '\\n'\n",
      "                       'P\\n'\n",
      "                       '\\n'\n",
      "                       'R\\n'\n",
      "                       '\\n'\n",
      "                       'S\\n'\n",
      "                       '\\n'\n",
      "                       '\\n'\n",
      "                       'T\\n'\n",
      "                       '\\n'\n",
      "                       'U\\n'\n",
      "                       '\\n'\n",
      "                       'V\\n'\n",
      "                       '\\n'\n",
      "                       'W\\n'\n",
      "                       '\\n'\n",
      "                       'X\\n'\n",
      "                       '\\n'\n",
      "                       'Y\\n'\n",
      "                       '\\n'\n",
      "                       'Z\\n'\n",
      "                       '\\x0c'\n",
      "                       '\\x0c'}]}\n"
     ]
    }
   ],
   "source": [
    "searchstring = '&search=deep learning'\n",
    "url = construct_Url(endpoint=endpoint, resource=\"indexes\", resource_name=\"mlbook/docs\", api_version=api_version, searchstring=searchstring)\n",
    "\n",
    "\n",
    "response  = requests.get(url, headers=headers, json=searchstring)\n",
    "query = response.json()\n",
    "pprint(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " initiate the sequential model, as '\n",
      "                        'follows:\\n'\n",
      "                        'seed = 1\\n'\n",
      "                        'np.random.seed(seed)\\n'\n",
      "                        'random.set_seed(seed)\\n'\n",
      "                        'model = Sequential()\\n'\n",
      "                        '\\n'\n",
      "                        '9. Add an LSTM layer to the network with 50 units, '\n",
      "                        'set the return_sequences\\n'\n",
      "                        'argument to True, and set the input_shape argument to '\n",
      "                        '(X_train.shape[1],\\n'\n",
      "                        '1). Add dropout to the model with rate=0.2. Add three '\n",
      "                        'additional LSTM layers,\\n'\n",
      "                        'each with 50 units, and set the return_sequences '\n",
      "                        'argument to True for the first\\n'\n",
      "                        'two. After each LSTM layer, add a dropout with '\n",
      "                        'rate=0.2. Add a final output layer\\n'\n",
      "                        'of size 1:\\n'\n",
      "                        'model.add(LSTM(units = 50, return_sequences = True, '\n",
      "                        'input_shape = (X_\\n'\n",
      "                        '# Adding a second LSTM layer and some Dropout '\n",
      "                        'regularization\\n'\n",
      "                        'model.add(LSTM(units = 50, return_sequences = True))\\n'\n",
      "                        '\\x0c'\n",
      "                        'Chapter 9: Sequential Modeling with Recurrent Neural '\n",
      "                        'Networks | 411\\n'\n",
      "                        '# Adding a third LSTM layer and some Dropout '\n",
      "                        'regularization\\n'\n",
      "                        'model.add(LSTM(units = 50, return_sequences = True))\\n'\n",
      "                        '# Adding a fourth LSTM layer and some Dropout '\n",
      "                        'regularization\\n'\n",
      "                        'model.add(LSTM(units = 50))\\n'\n",
      "                        '# Adding the output layer\\n'\n",
      "                        'model.add(Dense(units = 1))\\n'\n",
      "                        '\\n'\n",
      "                        '10. Compile the network with an adam optimizer and '\n",
      "                        'use Mean Squared Error for\\n'\n",
      "                        'the loss. Fit the model to the training data for 100 '\n",
      "                        'epochs with a batch size of 32:\\n'\n",
      "                        '# Compiling the RNN\\n'\n",
      "                        \"model.compile(optimizer = 'adam', loss = \"\n",
      "                        \"'mean_squared_error')\\n\"\n",
      "                        '# Fitting the RNN to the Training set\\n'\n",
      "                        'model.fit(X_train, y_train, epochs = 100, batch_size '\n",
      "                        '= 32)\\n'\n",
      "                        '\\n'\n",
      "                        '11. Load and process the test data (which is treated '\n",
      "                        'as actual data here) and select the\\n'\n",
      "                        'column representing the value of Open stock data:\\n'\n",
      "                        \"dataset_testing = pd.read_csv('../AMZN_test.csv')\\n\"\n",
      "                        'actual_stock_price = '\n",
      "                        \"dataset_testing[['Open']].values\\n\"\n",
      "                        'actual_stock_price\\n'\n",
      "                        '\\n'\n",
      "                        '12. Concatenate the data since we will need 60 '\n",
      "                        'previous instances to get the stock\\n'\n",
      "                        'price for each day. Therefore, we will need both the '\n",
      "                        'training and test data:\\n'\n",
      "                        \"total_data = pd.concat((dataset_training['Open'], \"\n",
      "                        'dataset_\\n'\n",
      "                        \"testing['Open']), axis = 0)\\n\"\n",
      "                        '\\n'\n",
      "                        '13. Reshape and scale the input to prepare the test '\n",
      "                        'data. Note that we are predicting\\n'\n",
      "                        'the January monthly trend, which has 21 financial '\n",
      "                        'days, so in order to prepare the\\n'\n",
      "                        'test set, we take the lower bound value as 60 and the '\n",
      "                        'upper bound value as 81. This\\n'\n",
      "                        'ensures that the difference of 21 is maintained:\\n'\n",
      "                        'inputs\\n'\n",
      "                        'values\\n'\n",
      "                        'inputs\\n'\n",
      "                        'inputs\\n'\n",
      "                        'X_test\\n'\n",
      "                        '\\n'\n",
      "                        '= total_data[len(total_data) - len(dataset_testing) - '\n",
      "                        '60:].\\n'\n",
      "                        '= sc.transform(inputs)\\n'\n",
      "                        '= []\\n'\n",
      "                        '\\x0c'\n",
      "                        '412 | Appendix\\n'\n",
      "                        'for i in range(60, 81):\\n'\n",
      "                        'X_test = np.array(X_test)\\n'\n",
      "                        'predicted_stock_price = model.predict(X_test)\\n'\n",
      "                        'predicted_stock_price = '\n",
      "                        'sc.inverse_transform(predicted_stock_price)\\n'\n",
      "                        '\\n'\n",
      "                        '14. Visualize the results by plotting the actual '\n",
      "                        'stock price and plotting the predicted\\n'\n",
      "                        'stock price:\\n'\n",
      "                        '# Visualizing the results\\n'\n",
      "                        \"plt.plot(actual_stock_price, color = 'green', label = \"\n",
      "                        \"'Real Amazon\\n\"\n",
      "                        \"Stock Price',ls='--')\\n\"\n",
      "                        \"plt.plot(predicted_stock_price, color = 'red', label \"\n",
      "                        \"= 'Predicted\\n\"\n",
      "                        \"Amazon Stock Price',ls='-')\\n\"\n",
      "                        \"plt.title('Predicted Stock Price')\\n\"\n",
      "                        \"plt.xlabel('Time in days')\\n\"\n",
      "                        \"plt.ylabel('Real Stock Price')\\n\"\n",
      "                        'plt.legend()\\n'\n",
      "                        'plt.show()\\n'\n",
      "                        '\\n'\n",
      "                        'Please note that your results may differ slightly to '\n",
      "                        'the actual stock price.\\n'\n",
      "                        'Expected output:\\n'\n",
      "                        '\\n'\n",
      "                        'Figure 9.26: Real versus predicted stock prices\\n'\n",
      "                        '\\x0c'\n",
      "                        'Chapter 9: Sequential Modeling with Recurrent Neural '\n",
      "                        'Networks | 413\\n'\n",
      "                        'In the following figure, the first plot displays the '\n",
      "                        'predicted output of the model with\\n'\n",
      "                        'regularization from Activity 9.02, and the second '\n",
      "                        'displays the predicted output without\\n'\n",
      "                        'regularization from Activity 9.01. As you can see, '\n",
      "                        'adding dropout regularization does not\\n'\n",
      "                        'fit the data as accurately. So, in this case, it is '\n",
      "                        'better not to use regularization, or to use\\n'\n",
      "                        'dropout regularization with a lower dropout rate:\\n'\n",
      "                        '\\n'\n",
      "                        'Figure 9.27: Comparing the results of Activity 9.01 '\n",
      "                        'and Activity 9.02\\n'\n",
      "                        '\\n'\n",
      "                        \"Activity 9.03: Predicting the Trend of Amazon's Stock \"\n",
      "                        'Price Using an LSTM\\n'\n",
      "                        'with an Increasing Number of LSTM Neurons (100 '\n",
      "                        'Units)\\n'\n",
      "                        'In this activity, we will examine the stock price of '\n",
      "                        'Amazon over the last 5 years, from\\n'\n",
      "                        'January 1, 2014, to December 31, 2018. We will try to '\n",
      "                        \"predict and forecast the company's\\n\"\n",
      "                        'future trend for January 2019 using RNNs with four '\n",
      "                        'LSTM layers, each with 100 units. We\\n'\n",
      "                        'have the actual values for January 2019, so we will '\n",
      "                        'be able to compare our predictions\\n'\n",
      "                        'with the actual values later. You can also compare '\n",
      "                        'the output difference with Activity\\n'\n",
      "                        \"9.01, Predicting the Trend of Amazon's Stock Price \"\n",
      "                        'Using an LSTM with 50 Units\\n'\n",
      "                        '(Neurons). Follow these steps to complete this '\n",
      "                        'activity:\\n'\n",
      "                        '1.\\n'\n",
      "                        '\\n'\n",
      "                        'Import the required libraries:\\n'\n",
      "                        'import numpy as np\\n'\n",
      "                        'import matplotlib.pyplot as plt\\n'\n",
      "                        'import pandas as pd\\n'\n",
      "                        'from tensorflow import random\\n'\n",
      "                        '\\n'\n",
      "                        '2. Import the dataset using the pandas read_csv '\n",
      "                        'function and look at the first five\\n'\n",
      "                        'rows of the dataset using the head method:\\n'\n",
      "                        \"dataset_training = pd.read_csv('../AMZN_train.csv')\\n\"\n",
      "                        'dataset_training.head()\\n'\n",
      "                        '\\x0c'\n",
      "                        '414 | Appendix\\n'\n",
      "                        '3. We are going to make our prediction using the Open '\n",
      "                        'stock price; therefore, select\\n'\n",
      "                        'the Open stock price column from the dataset and '\n",
      "                        'print the values:\\n'\n",
      "                        \"training_data = dataset_training[['Open']].values\\n\"\n",
      "                        'training_data\\n'\n",
      "                        '\\n'\n",
      "                        '4. Then, perform feature scaling by normalizing the '\n",
      "                        'data using MinMaxScaler and\\n'\n",
      "                        'setting the range of the features so that they have a '\n",
      "                        'minimum value of zero and\\n'\n",
      "                        'a maximum value of one. Use the fit_transform method '\n",
      "                        'of the scaler on the\\n'\n",
      "                        'training data:\\n'\n",
      "                        'from sklearn.preprocessing import MinMaxScaler\\n'\n",
      "                        'sc = MinMaxScaler(feature_range = (0, 1))\\n'\n",
      "                        'training_data_scaled = '\n",
      "                        'sc.fit_transform(training_data)\\n'\n",
      "                        'training_data_scaled\\n'\n",
      "                        '\\n'\n",
      "                        '5. Create the data to get 60 timestamps from the '\n",
      "                        'current instance. We chose 60 here\\n'\n",
      "                        'as it will give us a sufficient number of previous '\n",
      "                        'instances in order to understand\\n'\n",
      "                        'the trend; technically, this can be any number, but '\n",
      "                        '60 is the optimal value.\\n'\n",
      "                        'Additionally, the upper bound value here is 1258, '\n",
      "                        'which is the index or count of\\n'\n",
      "                        'rows (or records) in the training set:\\n'\n",
      "                        'X_train = []\\n'\n",
      "                        'y_train = []\\n'\n",
      "                        'for i in range(60, 1258):\\n'\n",
      "                        'X_train, y_train = np.array(X_train), '\n",
      "                        'np.array(y_train)\\n'\n",
      "                        '\\n'\n",
      "                        '6. Reshape the data to add an extra dimension to the '\n",
      "                        \"end of X_train using NumPy's\\n\"\n",
      "                        'reshape function:\\n'\n",
      "                        '\\n'\n",
      "                        '7. Import the following Keras libraries to build the '\n",
      "                        'RNN:\\n'\n",
      "                        'from keras.models import Sequential\\n'\n",
      "                        'from keras.layers import Dense, LSTM, Dropout\\n'\n",
      "                        '\\n'\n",
      "                        '8. Set the seed and initiate the sequential model:\\n'\n",
      "                        'seed = 1\\n'\n",
      "                        'np.random.seed(seed)\\n'\n",
      "                        'random.set_seed(seed)\\n'\n",
      "                        'model = Sequential()\\n'\n",
      "                        '\\x0c'\n",
      "                        'Chapter 9: Sequential Modeling with Recurrent Neural '\n",
      "                        'Networks | 415\\n'\n",
      "                        '9. Add an LSTM layer to the network with 100 units, '\n",
      "                        'set the return_sequences\\n'\n",
      "                        'argument to True, and set the input_shape argument to '\n",
      "                        '(X_train.shape[1],\\n'\n",
      "                        '1). Add three additional LSTM layers, each with 100 '\n",
      "                        'units, and set the return_\\n'\n",
      "                        'sequences argument to True for the first two. Add a '\n",
      "                        'final output layer of size 1:\\n'\n",
      "                        'model.add(LSTM(units = 100, return_sequences = True, '\n",
      "                        'input_shape = (X_\\n'\n",
      "                        '# Adding a second LSTM layer\\n'\n",
      "                        'model.add(LSTM(units = 100, return_sequences = '\n",
      "                        'True))\\n'\n",
      "                        '# Adding a third LSTM layer\\n'\n",
      "                        'model.add(LSTM(units = 100, return_sequences = '\n",
      "                        'True))\\n'\n",
      "                        '# Adding a fourth LSTM layer\\n'\n",
      "                        'model.add(LSTM(units = 100))\\n'\n",
      "                        '# Adding the output layer\\n'\n",
      "                        'model.add(Dense(units = 1))\\n'\n",
      "                        '\\n'\n",
      "                        '10. Compile the network with an adam optimizer and '\n",
      "                        'use Mean Squared Error for\\n'\n",
      "                        'the loss. Fit the model to the training data for 100 '\n",
      "                        'epochs with a batch size of 32:\\n'\n",
      "                        '# Compiling the RNN\\n'\n",
      "                        \"model.compile(optimizer = 'adam', loss = \"\n",
      "                        \"'mean_squared_error')\\n\"\n",
      "                        '# Fitting the RNN to the Training set\\n'\n",
      "                        'model.fit(X_train, y_train, epochs = 100, batch_size '\n",
      "                        '= 32)\\n'\n",
      "                        '\\n'\n",
      "                        '11. Load and process the test data (which is treated '\n",
      "                        'as actual data here) and select the\\n'\n",
      "                        'column representing the value of open stock data:\\n'\n",
      "                        \"dataset_testing = pd.read_csv('../AMZN_test.csv')\\n\"\n",
      "                        'actual_stock_price = '\n",
      "                        \"dataset_testing[['Open']].values\\n\"\n",
      "                        'actual_stock_price\\n'\n",
      "                        '\\n'\n",
      "                        '12. Concatenate the data since we will need 60 '\n",
      "                        'previous instances to get the stock\\n'\n",
      "                        'price for each day. Therefore, we will need both the '\n",
      "                        'training and test data:\\n'\n",
      "                        \"total_data = pd.concat((dataset_training['Open'], \"\n",
      "                        'dataset_\\n'\n",
      "                        \"testing['Open']), axis = 0)\\n\"\n",
      "                        '\\x0c'\n",
      "                        '416 | Appendix\\n'\n",
      "                        '13. Reshape and scale the input to prepare the test '\n",
      "                        'data. Note that we are predicting\\n'\n",
      "                        'the January monthly trend, which has 21 financial '\n",
      "                        'days, so in order to prepare the\\n'\n",
      "                        'test set, we take the lower bound value as 60 and the '\n",
      "                        'upper bound value as 81. This\\n'\n",
      "                        'ensures that the difference of 21 is maintained:\\n'\n",
      "                        'inputs = total_data[len(total_data) - '\n",
      "                        'len(dataset_testing) - 60:].\\n'\n",
      "                        'values\\n'\n",
      "                        'inputs = inputs.reshape(-1,1)\\n'\n",
      "                        'inputs = sc.transform(inputs)\\n'\n",
      "                        'X_test = []\\n'\n",
      "                        'for i in range(60, 81):\\n'\n",
      "                        'X_test = np.array(X_test)\\n'\n",
      "                        'predicted_stock_price = model.predict(X_test)\\n'\n",
      "                        'predicted_stock_price = '\n",
      "                        'sc.inverse_transform(predicted_stock_price)\\n'\n",
      "                        '\\n'\n",
      "                        '14. Visualize the results by plotting the actual '\n",
      "                        'stock price and plotting the predicted\\n'\n",
      "                        'stock price:\\n'\n",
      "                        \"plt.plot(actual_stock_price, color = 'green', label = \"\n",
      "                        \"'Actual Amazon\\n\"\n",
      "                        \"Stock Price',ls='--')\\n\"\n",
      "                        \"plt.plot(predicted_stock_price, color = 'red', label \"\n",
      "                        \"= 'Predicted\\n\"\n",
      "                        \"Amazon Stock Price',ls='-')\\n\"\n",
      "                        \"plt.title('Predicted Stock Price')\\n\"\n",
      "                        \"plt.xlabel('Time in days')\\n\"\n",
      "                        \"plt.ylabel('Real Stock Price')\\n\"\n",
      "                        'plt.legend()\\n'\n",
      "                        'plt.show()\\n'\n",
      "                        '\\n'\n",
      "                        'Please note that your results may differ slightly '\n",
      "                        'from the actual stock price.\\n'\n",
      "                        '\\x0c'\n",
      "                        'Chapter 9: Sequential Modeling with Recurrent Neural '\n",
      "                        'Networks | 417\\n'\n",
      "                        'Expected output:\\n'\n",
      "                        '\\n'\n",
      "                        'Figure 9.28: Real versus predicted stock prices\\n'\n",
      "                        '\\n'\n",
      "                        'So, if we compare the results of the LSTM with 50 '\n",
      "                        'units (from Activity 9.01, Predicting\\n'\n",
      "                        \"the Trend of Amazon's Stock Price Using an LSTM with \"\n",
      "                        '50 Units (Neurons)) and the LSTM\\n'\n",
      "                        'with 100 units in this activity, we get trends with '\n",
      "                        '100 units. Also, note that when we run\\n'\n",
      "                        'the LSTM with 100 units, it takes more computational '\n",
      "                        'time than the LSTM with 50 units.\\n'\n",
      "                        'A trade-off needs to be considered in such cases:\\n'\n",
      "                        '\\n'\n",
      "                        'Figure 9.29: Comparing the real versus predicted '\n",
      "                        'stock price with 50 and 100 units\\n'\n",
      "                        '\\x0c'\n",
      "                        '\\x0c'\n",
      "                        '>\\n'\n",
      "                        'Index\\n'\n",
      "                        '\\n'\n",
      "                        'About\\n'\n",
      "                        'All major keywords used in this book are captured '\n",
      "                        'alphabetically in this section. Each one is\\n'\n",
      "                        'accompanied by the page number of where they appear.\\n'\n",
      "                        '\\x0c'\n",
      "                        'A\\n'\n",
      "                        '\\n'\n",
      "                        '\\n'\n",
      "                        'B\\n'\n",
      "                        '\\n'\n",
      "                        'C\\n'\n",
      "                        '\\n'\n",
      "                        '\\n'\n",
      "                        'D\\n'\n",
      "                        '\\x0c'\n",
      "                        'E\\n'\n",
      "                        '\\n'\n",
      "                        'F\\n'\n",
      "                        '\\n'\n",
      "                        'G\\n'\n",
      "                        '\\n'\n",
      "                        '\\n'\n",
      "                        'I\\n'\n",
      "                        '\\n'\n",
      "                        'L\\n'\n",
      "                        '\\n'\n",
      "                        'M\\n'\n",
      "                        '\\n'\n",
      "                        'O\\n'\n",
      "                        '\\x0c'\n",
      "                        '\\n'\n",
      "                        'P\\n'\n",
      "                        '\\n'\n",
      "                        'R\\n'\n",
      "                        '\\n'\n",
      "                        'S\\n'\n",
      "                        '\\n'\n",
      "                        '\\n'\n",
      "                        'T\\n'\n",
      "                        '\\n'\n",
      "                        'U\\n'\n",
      "                        '\\n'\n",
      "                        'V\\n'\n",
      "                        '\\n'\n",
      "                        'W\\n'\n",
      "                        '\\n'\n",
      "                        'X\\n'\n",
      "                        '\\n'\n",
      "                        'Y\\n'\n",
      "                        '\\n'\n",
      "                        'Z\\n'\n",
      "                        '\\x0c'\n",
      "                        '\\x0c']}]}\n"
     ]
    }
   ],
   "source": [
    "searchstring ='&search=layer&$count=false'\n",
    "\n",
    "url = construct_Url(endpoint=endpoint, resource=\"indexes\", resource_name=\"mlbook/docs\", api_version=api_version, searchstring=searchstring)\n",
    "\n",
    "\n",
    "response  = requests.get(url, headers=headers, json=searchstring)\n",
    "query = response.json()\n",
    "pprint(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = endpoint + \"indexes/mlbook\" + api_version\n",
    "response  = requests.delete(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'@odata.context': 'https://alexa-for-docs.search.windows.net/$metadata#indexes/$entity',\n '@odata.etag': '\"0x8D89AA81F13FF75\"',\n 'analyzers': [],\n 'charFilters': [],\n 'corsOptions': None,\n 'defaultScoringProfile': None,\n 'encryptionKey': None,\n 'fields': [{'analyzer': None,\n             'facetable': True,\n             'filterable': True,\n             'indexAnalyzer': None,\n             'key': True,\n             'name': 'book_name',\n             'retrievable': True,\n             'searchAnalyzer': None,\n             'searchable': True,\n             'sortable': True,\n             'synonymMaps': [],\n             'type': 'Edm.String'},\n            {'analyzer': None,\n             'facetable': True,\n             'filterable': True,\n             'indexAnalyzer': None,\n             'key': False,\n             'name': 'content',\n             'retrievable': True,\n             'searchAnalyzer': None,\n             'searchable': True,\n             'sortable': True,\n             'synonymMaps': [],\n             'type': 'Edm.String'}],\n 'name': 'mlbook',\n 'scoringProfiles': [],\n 'suggesters': [],\n 'tokenFilters': [],\n 'tokenizers': []}\n"
     ]
    }
   ],
   "source": [
    "# Formulate the request. This POST request targets the indexes collection of your search service and creates an index based on the index schema you provided in the previous cell.\n",
    "url = construct_Url(endpoint=endpoint, resource=\"indexes\", resource_name=None, api_version=api_version, searchstring=None)\n",
    "response  = requests.post(url, headers=headers, json=index_schema)\n",
    "index = response.json()\n",
    "pprint(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, provide ddocuments that conform to the index schema. Specify an upload action for each document.\n",
    "# we have only one document containing the text of the book\n",
    "document = {\n",
    "    \"value\": [\n",
    "    { \"@search.action\": \"upload\",\n",
    "    \"book_name\": \"THE_DEEP_LEARNING_WITH_KERAS_WORKSHOP_SECOND_EDITION\",\n",
    "    \"content\": 'book/9781839217579-THE_DEEP_LEARNING_WITH_KERAS_WORKSHOP_SECOND_EDITION.pdf'\n",
    "    }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'@odata.context': \"https://alexa-for-docs.search.windows.net/indexes('mlbook')/$metadata#Collection(Microsoft.Azure.Search.V2019_05_06.IndexResult)\",\n 'value': [{'errorMessage': None,\n            'key': 'THE_DEEP_LEARNING_WITH_KERAS_WORKSHOP_SECOND_EDITION',\n            'status': True,\n            'statusCode': 201}]}\n"
     ]
    }
   ],
   "source": [
    "url = construct_Url(endpoint=endpoint, resource=\"indexes\", resource_name=\"mlbook/docs/index\", api_version=api_version, searchstring=None)\n",
    "response  = requests.post(url, headers=headers, json=document)\n",
    "index_content = response.json()\n",
    "pprint(index_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'@odata.context': \"https://alexa-for-docs.search.windows.net/indexes('mlbook')/$metadata#docs(*)\",\n 'value': []}\n"
     ]
    }
   ],
   "source": [
    "searchstring = '&search=layer'\n",
    "url = construct_Url(endpoint=endpoint, resource=\"indexes\", resource_name=\"mlbook/docs\", api_version=api_version, searchstring=searchstring)\n",
    "\n",
    "\n",
    "response  = requests.get(url, headers=headers, json=searchstring)\n",
    "query = response.json()\n",
    "pprint(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no documents where uploaded!\n",
    "url = endpoint + \"indexes/mlbook\" + api_version\n",
    "response  = requests.delete(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}